{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from osgeo import gdal\n",
    "from PIL import Image\n",
    "import os\n",
    "import numpy as np\n",
    "import keras.backend as K\n",
    "import png\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import division, print_function\n",
    "\n",
    "from keras.layers import Input, Conv2D, Conv2DTranspose\n",
    "from keras.layers import MaxPooling2D, Cropping2D, Concatenate\n",
    "from keras.layers import Lambda, Activation, BatchNormalization, Dropout\n",
    "from keras.models import Model\n",
    "from keras import backend as K\n",
    "\n",
    "\n",
    "def downsampling_block(input_tensor, filters, padding='valid',  #下采样部分\n",
    "                       batchnorm=False, dropout=0.0):\n",
    "    _, height, width, _ = K.int_shape(input_tensor)\n",
    "#     assert height % 2 == 0\n",
    "#     assert width % 2 == 0\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(input_tensor)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    return MaxPooling2D(pool_size=(2,2))(x), x   #返回的是池化后的值和dropout后的值，这里dropout后的值用于上采样特征级联\n",
    "\n",
    "def upsampling_block(input_tensor, skip_tensor, filters, padding='valid',\n",
    "                     batchnorm=False, dropout=0.0):    #下采样部分\n",
    "    x = Conv2DTranspose(filters, kernel_size=(2,2), strides=(2,2))(input_tensor)\n",
    "    _, x_height, x_width, _ = K.int_shape(x)\n",
    "    _, s_height, s_width, _ = K.int_shape(skip_tensor)\n",
    "    h_crop = s_height - x_height\n",
    "    w_crop = s_width - x_width\n",
    "    assert h_crop >= 0\n",
    "    assert w_crop >= 0\n",
    "    if h_crop == 0 and w_crop == 0:\n",
    "        y = skip_tensor\n",
    "    else:                       #使级联时像素大小一致\n",
    "        cropping = ((h_crop//2, h_crop - h_crop//2), (w_crop//2, w_crop - w_crop//2))\n",
    "        y = Cropping2D(cropping=cropping)(skip_tensor)\n",
    "\n",
    "    x = Concatenate()([x, y])         #特征级联\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    x = Conv2D(filters, kernel_size=(3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    return x                   #返回dropout后的值\n",
    "\n",
    "def unet(height, width, channels, classes, features=64, depth=4,\n",
    "         temperature=1.0, padding='valid', batchnorm=False, dropout=0.0):  #使用4个深度长的网络就是官网的典型网络\n",
    "    x = Input(shape=(height, width, channels))\n",
    "    inputs = x\n",
    "\n",
    "    skips = []                   #用于存放下采样中，每个深度后，dropout后的值，以供之后级联使用\n",
    "    for i in range(depth):\n",
    "        x, x0 = downsampling_block(x, features, padding,\n",
    "                                   batchnorm, dropout)\n",
    "        skips.append(x0)\n",
    "        features *= 2            #下采样过程中，每个深度往下，特征翻倍，即每次使用翻倍数目的滤波器\n",
    "\n",
    "    x = Conv2D(filters=features, kernel_size=(3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    x = Conv2D(filters=features, kernel_size=(3,3), padding=padding)(x)\n",
    "    x = BatchNormalization()(x) if batchnorm else x\n",
    "    x = Activation('relu')(x)\n",
    "    x = Dropout(dropout)(x) if dropout > 0 else x\n",
    "\n",
    "    for i in reversed(range(depth)):    #下采样过程中，深度从深到浅\n",
    "        features //= 2                  #每个深度往上。特征减少一倍\n",
    "        x = upsampling_block(x, skips[i], features, padding,\n",
    "                             batchnorm, dropout)\n",
    "\n",
    "    x = Conv2D(filters=classes, kernel_size=(1,1))(x)\n",
    "\n",
    "    logits = Lambda(lambda z: z/temperature)(x)      #简单的对x做一个变换\n",
    "    probabilities = Activation('softmax')(logits)    #对输出的两类做softmax，转换为概率。形式如【0.1,0.9],则预测为第二类的概率更大。\n",
    "\n",
    "    return Model(inputs=inputs, outputs=probabilities)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# def unet(img_w, img_h, channels, n_label):\n",
    "#     inputs = Input((img_w, img_h, channels))\n",
    " \n",
    "#     conv1 = Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(inputs)\n",
    "#     conv1 = Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(conv1)\n",
    "#     pool1 = MaxPooling2D(pool_size=(2, 2))(conv1)\n",
    " \n",
    "#     conv2 = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(pool1)\n",
    "#     conv2 = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(conv2)\n",
    "#     pool2 = MaxPooling2D(pool_size=(2, 2))(conv2)\n",
    " \n",
    "#     conv3 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(pool2)\n",
    "#     conv3 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv3)\n",
    "#     pool3 = MaxPooling2D(pool_size=(2, 2))(conv3)\n",
    " \n",
    "#     conv4 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(pool3)\n",
    "#     conv4 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(conv4)\n",
    "#     pool4 = MaxPooling2D(pool_size=(2, 2))(conv4)\n",
    " \n",
    "#     conv5 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(pool4)\n",
    "#     conv5 = Conv2D(128, (3, 3), activation=\"relu\", padding=\"same\")(conv5)\n",
    " \n",
    "#     up6 = Concatenate()([UpSampling2D(size=(2, 2))(conv5), conv4])\n",
    "#     conv6 = Conv2D(64, (3, 3), activation=\"relu\", padding=\"same\")(up6)\n",
    "#     conv6 = Conv2D(63, (3, 3), activation=\"relu\", padding=\"same\")(conv6)\n",
    " \n",
    "#     up7 = Concatenate()([UpSampling2D(size=(2, 2))(conv6), conv3])\n",
    "#     conv7 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(up7)\n",
    "#     conv7 = Conv2D(32, (3, 3), activation=\"relu\", padding=\"same\")(conv7)\n",
    " \n",
    "#     up8 = Concatenate()([UpSampling2D(size=(2, 2))(conv7), conv2])\n",
    "#     conv8 = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(up8)\n",
    "#     conv8 = Conv2D(16, (3, 3), activation=\"relu\", padding=\"same\")(conv8)\n",
    " \n",
    "#     up9 = Concatenate()([UpSampling2D(size=(2, 2))(conv8), conv1])\n",
    "#     conv9 = Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(up9)\n",
    "#     conv9 = Conv2D(8, (3, 3), activation=\"relu\", padding=\"same\")(conv9)\n",
    "\n",
    "# #     conv10 = Conv2D(n_label, (1, 1), activation=\"sigmoid\")(conv9)\n",
    "#     conv10 = Conv2D(n_label, (1, 1), activation=\"softmax\")(conv9)\n",
    " \n",
    "#     model = Model(inputs=inputs, outputs=conv10)\n",
    "#     model.compile(optimizer='Adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "#     return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = unet(768, 768, 3, 4, features=8, depth=4, padding='same', batchnorm=True, dropout=0)\n",
    "model.compile(optimizer='Adam', loss='categorical_crossentropy', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_1 (InputLayer)            (None, 768, 768, 3)  0                                            \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_1 (Conv2D)               (None, 768, 768, 8)  224         input_1[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_1 (BatchNor (None, 768, 768, 8)  32          conv2d_1[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_1 (Activation)       (None, 768, 768, 8)  0           batch_normalization_1[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_2 (Conv2D)               (None, 768, 768, 8)  584         activation_1[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_2 (BatchNor (None, 768, 768, 8)  32          conv2d_2[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_2 (Activation)       (None, 768, 768, 8)  0           batch_normalization_2[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2D)  (None, 384, 384, 8)  0           activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_3 (Conv2D)               (None, 384, 384, 16) 1168        max_pooling2d_1[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_3 (BatchNor (None, 384, 384, 16) 64          conv2d_3[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_3 (Activation)       (None, 384, 384, 16) 0           batch_normalization_3[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_4 (Conv2D)               (None, 384, 384, 16) 2320        activation_3[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_4 (BatchNor (None, 384, 384, 16) 64          conv2d_4[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_4 (Activation)       (None, 384, 384, 16) 0           batch_normalization_4[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_2 (MaxPooling2D)  (None, 192, 192, 16) 0           activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_5 (Conv2D)               (None, 192, 192, 32) 4640        max_pooling2d_2[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_5 (BatchNor (None, 192, 192, 32) 128         conv2d_5[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_5 (Activation)       (None, 192, 192, 32) 0           batch_normalization_5[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_6 (Conv2D)               (None, 192, 192, 32) 9248        activation_5[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_6 (BatchNor (None, 192, 192, 32) 128         conv2d_6[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_6 (Activation)       (None, 192, 192, 32) 0           batch_normalization_6[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_3 (MaxPooling2D)  (None, 96, 96, 32)   0           activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_7 (Conv2D)               (None, 96, 96, 64)   18496       max_pooling2d_3[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_7 (BatchNor (None, 96, 96, 64)   256         conv2d_7[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_7 (Activation)       (None, 96, 96, 64)   0           batch_normalization_7[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_8 (Conv2D)               (None, 96, 96, 64)   36928       activation_7[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_8 (BatchNor (None, 96, 96, 64)   256         conv2d_8[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_8 (Activation)       (None, 96, 96, 64)   0           batch_normalization_8[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "max_pooling2d_4 (MaxPooling2D)  (None, 48, 48, 64)   0           activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_9 (Conv2D)               (None, 48, 48, 128)  73856       max_pooling2d_4[0][0]            \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_9 (BatchNor (None, 48, 48, 128)  512         conv2d_9[0][0]                   \n",
      "__________________________________________________________________________________________________\n",
      "activation_9 (Activation)       (None, 48, 48, 128)  0           batch_normalization_9[0][0]      \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_10 (Conv2D)              (None, 48, 48, 128)  147584      activation_9[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_10 (BatchNo (None, 48, 48, 128)  512         conv2d_10[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_10 (Activation)      (None, 48, 48, 128)  0           batch_normalization_10[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_1 (Conv2DTrans (None, 96, 96, 64)   32832       activation_10[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_1 (Concatenate)     (None, 96, 96, 128)  0           conv2d_transpose_1[0][0]         \n",
      "                                                                 activation_8[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_11 (Conv2D)              (None, 96, 96, 64)   73792       concatenate_1[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_11 (BatchNo (None, 96, 96, 64)   256         conv2d_11[0][0]                  \n",
      "__________________________________________________________________________________________________\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "activation_11 (Activation)      (None, 96, 96, 64)   0           batch_normalization_11[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_12 (Conv2D)              (None, 96, 96, 64)   36928       activation_11[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_12 (BatchNo (None, 96, 96, 64)   256         conv2d_12[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_12 (Activation)      (None, 96, 96, 64)   0           batch_normalization_12[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_2 (Conv2DTrans (None, 192, 192, 32) 8224        activation_12[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_2 (Concatenate)     (None, 192, 192, 64) 0           conv2d_transpose_2[0][0]         \n",
      "                                                                 activation_6[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_13 (Conv2D)              (None, 192, 192, 32) 18464       concatenate_2[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_13 (BatchNo (None, 192, 192, 32) 128         conv2d_13[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_13 (Activation)      (None, 192, 192, 32) 0           batch_normalization_13[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_14 (Conv2D)              (None, 192, 192, 32) 9248        activation_13[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_14 (BatchNo (None, 192, 192, 32) 128         conv2d_14[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_14 (Activation)      (None, 192, 192, 32) 0           batch_normalization_14[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_3 (Conv2DTrans (None, 384, 384, 16) 2064        activation_14[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_3 (Concatenate)     (None, 384, 384, 32) 0           conv2d_transpose_3[0][0]         \n",
      "                                                                 activation_4[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_15 (Conv2D)              (None, 384, 384, 16) 4624        concatenate_3[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_15 (BatchNo (None, 384, 384, 16) 64          conv2d_15[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_15 (Activation)      (None, 384, 384, 16) 0           batch_normalization_15[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_16 (Conv2D)              (None, 384, 384, 16) 2320        activation_15[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_16 (BatchNo (None, 384, 384, 16) 64          conv2d_16[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_16 (Activation)      (None, 384, 384, 16) 0           batch_normalization_16[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_transpose_4 (Conv2DTrans (None, 768, 768, 8)  520         activation_16[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "concatenate_4 (Concatenate)     (None, 768, 768, 16) 0           conv2d_transpose_4[0][0]         \n",
      "                                                                 activation_2[0][0]               \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_17 (Conv2D)              (None, 768, 768, 8)  1160        concatenate_4[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_17 (BatchNo (None, 768, 768, 8)  32          conv2d_17[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_17 (Activation)      (None, 768, 768, 8)  0           batch_normalization_17[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_18 (Conv2D)              (None, 768, 768, 8)  584         activation_17[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "batch_normalization_18 (BatchNo (None, 768, 768, 8)  32          conv2d_18[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_18 (Activation)      (None, 768, 768, 8)  0           batch_normalization_18[0][0]     \n",
      "__________________________________________________________________________________________________\n",
      "conv2d_19 (Conv2D)              (None, 768, 768, 4)  36          activation_18[0][0]              \n",
      "__________________________________________________________________________________________________\n",
      "lambda_1 (Lambda)               (None, 768, 768, 4)  0           conv2d_19[0][0]                  \n",
      "__________________________________________________________________________________________________\n",
      "activation_19 (Activation)      (None, 768, 768, 4)  0           lambda_1[0][0]                   \n",
      "==================================================================================================\n",
      "Total params: 488,788\n",
      "Trainable params: 487,316\n",
      "Non-trainable params: 1,472\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights('unet_epoch17_valloss_0.5152_valacc_0.7979.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "img3path = \"D:/kaggle/nongye/jingwei_round1_test_a_20190619/jingwei_round1_test_a_20190619/image_3.png\"\n",
    "img4path = \"D:/kaggle/nongye/jingwei_round1_test_a_20190619/jingwei_round1_test_a_20190619/image_4.png\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(imgpath, model, output_name='tmp.bmp', blocksize=768, step=768):\n",
    "    \n",
    "    ds = gdal.Open(imgpath)\n",
    "    wx = ds.RasterXSize # 37241\n",
    "    wy = ds.RasterYSize # 19903\n",
    "    od = np.zeros((wy, wx), np.uint8)\n",
    "    \n",
    "    print('-----starting prediction-------')\n",
    "    for cy in tqdm(range(step, wy, step)):\n",
    "        for cx in range(step, wx, step):\n",
    "            im = ds.ReadAsArray(cx-step, cy-step, blocksize, blocksize)[0:3, :, :].transpose(1, 2, 0)\n",
    "            if (im.sum()==0): continue\n",
    "            im =np.expand_dims(im, axis=0)\n",
    "            r = model.predict(im/255, verbose=2)\n",
    "            r = np.argmax(r, -1).reshape(blocksize, blocksize)\n",
    "            od[cy-step:cy-step+blocksize, cx-step:cx-step+blocksize] = r\n",
    "    print('----starting saving result-----')    \n",
    "    w = png.Writer(wx, wy, bitdepth=2,greyscale=True)\n",
    "    of = open('./predict/' +  output_name, 'wb')\n",
    "    w.write_array(of, od.flat)\n",
    "    of.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----starting prediction-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 25/25 [17:00<00:00, 42.91s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----starting saving result-----\n"
     ]
    }
   ],
   "source": [
    "predict(img3path, model, output_name='image_3_predict.png', blocksize=768, step=768)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-----starting prediction-------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████████████████████████████████| 37/37 [16:42<00:00, 20.65s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----starting saving result-----\n"
     ]
    }
   ],
   "source": [
    "predict(img4path, model, output_name='image_4_predict.png', blocksize=768, step=768)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
