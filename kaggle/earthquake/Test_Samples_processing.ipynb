{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm_notebook\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.svm import NuSVR, SVR\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "import xgboost as xgb\n",
    "import time\n",
    "import datetime\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, RepeatedKFold\n",
    "from sklearn.linear_model import LinearRegression\n",
    "import gc\n",
    "import seaborn as sns\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from scipy.signal import hilbert, hann, convolve\n",
    "from scipy import stats\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from itertools import product\n",
    "\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from joblib import Parallel, delayed\n",
    "from hyperopt import fmin, tpe, hp, STATUS_OK, Trials"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv('more_features.csv', dtype={'acoustic_data': np.int16, 'time_to_failure': np.float32})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X.drop('Unnamed: 0', axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('D:/kaggle/earthquake/sample_submission.csv', index_col='seg_id')\n",
    "X_train = pd.DataFrame(columns=X.columns, dtype=np.float64, index=submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    sta = np.cumsum(x**2)\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "    lta = sta.copy()\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "    sta[:length_lta - 1] = 0\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "    return sta / lta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████| 2624/2624 [8:04:15<00:00, 11.02s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 8h 4min 16s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "for idx in tqdm(list(X_train.index)):\n",
    "    file = 'D:/kaggle/earthquake/test/' + idx + '.csv'\n",
    "    segment = pd.read_csv(file)    \n",
    "    xc = pd.Series(segment.acoustic_data.values)\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    X_train.loc[idx, 'mean'] = xc.mean()\n",
    "    X_train.loc[idx, 'std'] =xc.std()\n",
    "    X_train.loc[idx, 'max'] = xc.max()\n",
    "    X_train.loc[idx, 'min'] = xc.min()   \n",
    "    X_train.loc[idx, 'mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X_train.loc[idx, 'mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X_train.loc[idx, 'abs_max'] = np.abs(xc).max()\n",
    "    \n",
    "    X_train.loc[idx, 'mean_first_50000'] = xc[:50000].mean()\n",
    "    X_train.loc[idx, 'mean_last_50000'] = xc[-50000:].mean()\n",
    "    X_train.loc[idx, 'mean_first_10000'] = xc[:10000].mean()\n",
    "    X_train.loc[idx, 'mean_last_10000'] = xc[-10000:].mean()\n",
    "    X_train.loc[idx, 'std_first_50000'] = xc[:50000].std()\n",
    "    X_train.loc[idx, 'std_last_50000'] = xc[-50000:].std()\n",
    "    X_train.loc[idx, 'std_first_10000'] = xc[:10000].std()\n",
    "    X_train.loc[idx, 'std_last_10000'] = xc[-10000:].std()\n",
    "    X_train.loc[idx, 'min_first_50000'] = xc[:50000].min()\n",
    "    X_train.loc[idx, 'min_last_50000'] = xc[-50000:].min()\n",
    "    X_train.loc[idx, 'min_first_10000'] = xc[:10000].min()\n",
    "    X_train.loc[idx, 'min_last_10000'] = xc[-10000:].min()\n",
    "    X_train.loc[idx, 'max_first_50000'] = xc[:50000].max()\n",
    "    X_train.loc[idx, 'max_last_50000'] = xc[-50000:].max()\n",
    "    X_train.loc[idx, 'max_first_10000'] = xc[:10000].max()\n",
    "    X_train.loc[idx, 'max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X_train.loc[idx, 'max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X_train.loc[idx, 'max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X_train.loc[idx, 'count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X_train.loc[idx, 'sum'] = xc.sum()\n",
    "    \n",
    "    X_train.loc[idx, 'mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X_train.loc[idx, 'q95'] = np.quantile(xc, 0.95)\n",
    "    X_train.loc[idx, 'q99'] = np.quantile(xc, 0.99)\n",
    "    X_train.loc[idx, 'q05'] = np.quantile(xc, 0.05)\n",
    "    X_train.loc[idx, 'q01'] = np.quantile(xc, 0.01)\n",
    "    X_train.loc[idx, 'abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X_train.loc[idx, 'abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X_train.loc[idx, 'abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X_train.loc[idx, 'abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X_train.loc[idx, 'trend'] = add_trend_feature(xc)\n",
    "    X_train.loc[idx, 'abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X_train.loc[idx, 'abs_mean'] = np.abs(xc).mean()\n",
    "    X_train.loc[idx, 'abs_std'] = np.abs(xc).std()\n",
    "\n",
    "    X_train.loc[idx, 'mad'] = xc.mad()\n",
    "    X_train.loc[idx, 'kurt'] = xc.kurtosis()\n",
    "    X_train.loc[idx, 'skew'] = xc.skew()\n",
    "    X_train.loc[idx, 'median'] = xc.median()\n",
    "    \n",
    "    X_train.loc[idx, 'Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_50'] = (convolve(xc, hann(50), mode='same')/sum(hann(50))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_150'] = (convolve(xc, hann(150), mode='same')/sum(hann(150))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_1500'] = (convolve(xc, hann(1500), mode='same')/sum(hann(1500))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_15000'] = (convolve(xc, hann(15000), mode='same')/sum(hann(15000))).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta1_mean'] = classic_sta_lta(xc, 500, 10000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta2_mean'] = classic_sta_lta(xc, 5000, 100000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta3_mean'] = classic_sta_lta(xc, 3333, 6666).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta4_mean'] = classic_sta_lta(xc, 10000, 25000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta5_mean'] = classic_sta_lta(xc, 50, 1000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta6_mean'] = classic_sta_lta(xc, 100, 5000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta7_mean'] = classic_sta_lta(xc, 333, 666).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta8_mean'] = classic_sta_lta(xc, 4000, 10000).mean()\n",
    "    \n",
    "    X_train.loc[idx, 'Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_train.loc[idx, 'exp_moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_3000_mean'] = (ewma(xc, span=3000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_30000_mean'] = (ewma(xc, span=30000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_50000_mean'] = (ewma(xc, span=50000).mean()).mean(skipna=True)\n",
    "    \n",
    "    X_train.loc[idx, 'MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X_train.loc[idx,'MA_700MA_BB_high_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] + 2 * X_train.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx,'MA_700MA_BB_low_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] - 2 * X_train.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X_train.loc[idx,'MA_400MA_BB_high_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] + 2 * X_train.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx,'MA_400MA_BB_low_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] - 2 * X_train.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X_train.loc[idx, 'iqr'] = np.subtract(*np.percentile(xc, [25, 75]))\n",
    "    X_train.loc[idx, 'q999'] = np.quantile(xc, 0.999)\n",
    "    X_train.loc[idx, 'q001'] = np.quantile(xc, 0.001)\n",
    "    X_train.loc[idx, 'ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    X_train.loc[idx, 'number_peaks_50p'] = feature_calculators.number_peaks(xc.values, 50)\n",
    "    X_train.loc[idx, 'number_peaks_100p'] = feature_calculators.number_peaks(xc.values, 100)\n",
    "    X_train.loc[idx, 'number_peaks_500p'] = feature_calculators.number_peaks(xc.values, 500)\n",
    "    X_train.loc[idx, 'number_peaks_1000p'] = feature_calculators.number_peaks(xc.values, 1000)\n",
    "    X_train.loc[idx, 'number_peaks_10000p'] = feature_calculators.number_peaks(xc.values, 10000)\n",
    "    X_train.loc[idx, 'autocorrelaion_10'] = feature_calculators.autocorrelation(xc.values, 10)\n",
    "    X_train.loc[idx, 'autocorrelaion_50'] = feature_calculators.autocorrelation(xc.values, 50)\n",
    "    X_train.loc[idx, 'autocorrelaion_100'] = feature_calculators.autocorrelation(xc.values, 100)\n",
    "    X_train.loc[idx, 'autocorrelaion_1000'] = feature_calculators.autocorrelation(xc.values, 1000)\n",
    "    X_train.loc[idx, 'c3_5'] = feature_calculators.c3(xc.values, 5)\n",
    "    X_train.loc[idx, 'c3_10'] = feature_calculators.c3(xc.values, 10)\n",
    "    X_train.loc[idx, 'c3_100'] = feature_calculators.c3(xc.values, 100)\n",
    "    X_train.loc[idx, 'binned_entropy_50'] = feature_calculators.binned_entropy(xc.values, 50)\n",
    "    X_train.loc[idx, 'binned_entropy_80'] = feature_calculators.binned_entropy(xc.values, 80)\n",
    "    X_train.loc[idx, 'binned_entropy_100'] = feature_calculators.binned_entropy(xc.values, 100)\n",
    "    X_train.loc[idx, 'binned_entropy_500'] = feature_calculators.binned_entropy(xc.values, 500)\n",
    "    X_train.loc[idx, 'mean_abs_change'] = feature_calculators.mean_abs_change(xc.values)\n",
    " \n",
    "    # FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X_train.loc[idx, 'Rmean'] = realFFT.mean()\n",
    "    X_train.loc[idx, 'Rstd'] = realFFT.std()\n",
    "    X_train.loc[idx, 'Rmax'] = realFFT.max()\n",
    "    X_train.loc[idx, 'Rmin'] = realFFT.min()\n",
    "    X_train.loc[idx, 'Imean'] = imagFFT.mean()\n",
    "    X_train.loc[idx, 'Istd'] = imagFFT.std()\n",
    "    X_train.loc[idx, 'Imax'] = imagFFT.max()\n",
    "    X_train.loc[idx, 'Imin'] = imagFFT.min()\n",
    "    \n",
    "    X_train.loc[idx, 'Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X_train.loc[idx, 'Rstd_last_5000'] = realFFT[-5000:].std()\n",
    "    X_train.loc[idx, 'Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X_train.loc[idx, 'Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X_train.loc[idx, 'Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X_train.loc[idx, 'Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X_train.loc[idx, 'Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X_train.loc[idx, 'Rmin_last_15000'] = realFFT[-15000:].min() \n",
    "    \n",
    "    for windows in [10, 50, 100, 500, 1000, 5000, 10000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_mean'] = x_roll_mean.mean()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_std'] = x_roll_mean.std()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_max'] = x_roll_mean.max()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_min'] = x_roll_mean.min()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q01'] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q05'] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_median'] = np.median(x_roll_mean)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q95'] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q99'] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_mean))\n",
    "        \n",
    "        X_train.loc[idx, f'std_roll_{windows}_mean'] = x_roll_std.mean()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_std'] = x_roll_std.std()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_max'] = x_roll_std.max()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_min'] = x_roll_std.min()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q01'] = np.quantile(x_roll_std, 0.01)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q05'] = np.quantile(x_roll_std, 0.05)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_median'] = np.median(x_roll_std)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q95'] = np.quantile(x_roll_std, 0.95)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q99'] = np.quantile(x_roll_std, 0.99)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_std))       \n",
    "        \n",
    "        \n",
    "X_train.to_csv('more_features_test', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('more_features_test.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
