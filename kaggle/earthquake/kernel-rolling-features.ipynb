{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gc\n",
    "import time\n",
    "import numpy as np \n",
    "import pandas as pd \n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sns\n",
    "from statsmodels.robust import mad\n",
    "import pywt\n",
    "import scipy\n",
    "from scipy.signal import butter, deconvolve\n",
    "from scipy.signal import hilbert, hann, convolve\n",
    "from scipy import stats\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "from tsfresh.feature_extraction import feature_calculators\n",
    "from sklearn.linear_model import LinearRegression\n",
    "pd.options.display.precision = 15\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from hyperopt import STATUS_OK, tpe, hp, Trials, fmin"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a"
   },
   "outputs": [],
   "source": [
    "SIGNAL_LEN = 150_000\n",
    "SAMPLE_RATE = 4e6\n",
    "\n",
    "data_reader = pd.read_csv('D:/kaggle/earthquake/train.csv', \n",
    "                          dtype={'acoustic_data': np.int16,\n",
    "                                 'time_to_failure': np.float32},\n",
    "                          chunksize=300_000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maddest(d, axis=None):\n",
    "    return np.mean(np.absolute(d - np.mean(d, axis)), axis)\n",
    "\n",
    "\n",
    "def high_pass_filter(x, low_cutoff=1000, SAMPLE_RATE=SAMPLE_RATE):\n",
    "    nyquist = 0.5 * SAMPLE_RATE\n",
    "    norm_low_cutoff = low_cutoff / nyquist\n",
    "    \n",
    "    sos = butter(10, Wn=[norm_low_cutoff], btype='highpass', output='sos')\n",
    "    filtered_sig = scipy.signal.sosfilt(sos, x)\n",
    "    return filtered_sig\n",
    "\n",
    "\n",
    "def denoise_signal(x, wavelet='db4', level=1):\n",
    "    coeff = pywt.wavedec(x, wavelet, mode='per')\n",
    "    sigma = (1/0.6745) * maddest(coeff[-level])\n",
    "    uthresh = sigma * np.sqrt(2 * np.log(len(x)))\n",
    "    coeff[1:] = (pywt.threshold(i, value=uthresh, mode='hard') for i in coeff[1:])\n",
    "    return pywt.waverec(coeff, wavelet, mode='per')\n",
    "\n",
    "\n",
    "def add_trend_feature(arr, abs_values=False):\n",
    "    idx = np.array(range(len(arr)))\n",
    "    if abs_values:\n",
    "        arr = np.abs(arr)\n",
    "    lr = LinearRegression()\n",
    "    lr.fit(idx.reshape(-1, 1), arr)\n",
    "    return lr.coef_[0]\n",
    "\n",
    "\n",
    "def classic_sta_lta(x, length_sta, length_lta):\n",
    "    sta = np.cumsum(x**2)\n",
    "    sta = np.require(sta, dtype=np.float)\n",
    "    lta = sta.copy()\n",
    "    sta[length_sta:] = sta[length_sta:] - sta[:-length_sta]\n",
    "    sta /= length_sta\n",
    "    lta[length_lta:] = lta[length_lta:] - lta[:-length_lta]\n",
    "    lta /= length_lta\n",
    "    sta[:length_lta - 1] = 0\n",
    "    dtiny = np.finfo(0.0).tiny\n",
    "    idx = lta < dtiny\n",
    "    lta[idx] = dtiny\n",
    "    return sta / lta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "nrows = 629145481\n",
    "rows = 300_000\n",
    "segments = int(np.floor(nrows / rows))\n",
    "\n",
    "\n",
    "X_train = pd.DataFrame(dtype=np.float64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 2097/2097 [13:57:36<00:00, 23.25s/it]"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Invalid number of FFT data points (0) specified.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m-----------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-4d1a48b2b2a0>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mxc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSeries\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msegment\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0macoustic_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m75000\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;36m225000\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mzc\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mxc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[0mX_train\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'mean'\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mxc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\numpy\\fft\\fftpack.py\u001b[0m in \u001b[0;36mfft\u001b[1;34m(a, n, axis, norm)\u001b[0m\n\u001b[0;32m    190\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    191\u001b[0m         \u001b[0mn\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0ma\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 192\u001b[1;33m     \u001b[0moutput\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_raw_fft\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcffti\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfftpack\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcfftf\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_fft_cache\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    193\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0m_unitary\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mnorm\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    194\u001b[0m         \u001b[0moutput\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;33m/\u001b[0m \u001b[0msqrt\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\numpy\\fft\\fftpack.py\u001b[0m in \u001b[0;36m_raw_fft\u001b[1;34m(a, n, axis, init_function, work_function, fft_cache)\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[1;33m<\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     55\u001b[0m         raise ValueError(\"Invalid number of FFT data points (%d) specified.\"\n\u001b[1;32m---> 56\u001b[1;33m                          % n)\n\u001b[0m\u001b[0;32m     57\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     58\u001b[0m     \u001b[1;31m# We have to ensure that only a single thread can access a wsave array\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Invalid number of FFT data points (0) specified."
     ]
    }
   ],
   "source": [
    "idx = 4195\n",
    "for segment in tqdm(data_reader, total=segments):\n",
    "    \n",
    "    # ==================================================================\n",
    "    # =====================original data================================\n",
    "    # ==================================================================\n",
    "    \n",
    "    xc = pd.Series(segment.acoustic_data.values[75000:225000])\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    X_train.loc[idx, 'mean'] = xc.mean()\n",
    "    X_train.loc[idx, 'std'] =xc.std()\n",
    "    X_train.loc[idx, 'max'] = xc.max()\n",
    "    X_train.loc[idx, 'min'] = xc.min()   \n",
    "    X_train.loc[idx, 'mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X_train.loc[idx, 'mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X_train.loc[idx, 'abs_max'] = np.abs(xc).max()\n",
    "    \n",
    "    X_train.loc[idx, 'mean_first_50000'] = xc[:50000].mean()\n",
    "    X_train.loc[idx, 'mean_last_50000'] = xc[-50000:].mean()\n",
    "    X_train.loc[idx, 'mean_first_10000'] = xc[:10000].mean()\n",
    "    X_train.loc[idx, 'mean_last_10000'] = xc[-10000:].mean()\n",
    "    X_train.loc[idx, 'std_first_50000'] = xc[:50000].std()\n",
    "    X_train.loc[idx, 'std_last_50000'] = xc[-50000:].std()\n",
    "    X_train.loc[idx, 'std_first_10000'] = xc[:10000].std()\n",
    "    X_train.loc[idx, 'std_last_10000'] = xc[-10000:].std()\n",
    "    X_train.loc[idx, 'min_first_50000'] = xc[:50000].min()\n",
    "    X_train.loc[idx, 'min_last_50000'] = xc[-50000:].min()\n",
    "    X_train.loc[idx, 'min_first_10000'] = xc[:10000].min()\n",
    "    X_train.loc[idx, 'min_last_10000'] = xc[-10000:].min()\n",
    "    X_train.loc[idx, 'max_first_50000'] = xc[:50000].max()\n",
    "    X_train.loc[idx, 'max_last_50000'] = xc[-50000:].max()\n",
    "    X_train.loc[idx, 'max_first_10000'] = xc[:10000].max()\n",
    "    X_train.loc[idx, 'max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X_train.loc[idx, 'max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X_train.loc[idx, 'max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X_train.loc[idx, 'count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X_train.loc[idx, 'sum'] = xc.sum()\n",
    "    \n",
    "    X_train.loc[idx, 'mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X_train.loc[idx, 'mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X_train.loc[idx, 'q95'] = np.quantile(xc, 0.95)\n",
    "    X_train.loc[idx, 'q99'] = np.quantile(xc, 0.99)\n",
    "    X_train.loc[idx, 'q05'] = np.quantile(xc, 0.05)\n",
    "    X_train.loc[idx, 'q01'] = np.quantile(xc, 0.01)\n",
    "    X_train.loc[idx, 'abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X_train.loc[idx, 'abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X_train.loc[idx, 'abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X_train.loc[idx, 'abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X_train.loc[idx, 'trend'] = add_trend_feature(xc)\n",
    "    X_train.loc[idx, 'abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X_train.loc[idx, 'abs_mean'] = np.abs(xc).mean()\n",
    "    X_train.loc[idx, 'abs_std'] = np.abs(xc).std()\n",
    "\n",
    "    X_train.loc[idx, 'mad'] = xc.mad()\n",
    "    X_train.loc[idx, 'kurt'] = xc.kurtosis()\n",
    "    X_train.loc[idx, 'skew'] = xc.skew()\n",
    "    X_train.loc[idx, 'median'] = xc.median()\n",
    "    \n",
    "    X_train.loc[idx, 'Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_50'] = (convolve(xc, hann(50), mode='same')/sum(hann(50))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_150'] = (convolve(xc, hann(150), mode='same')/sum(hann(150))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_1500'] = (convolve(xc, hann(1500), mode='same')/sum(hann(1500))).mean()\n",
    "    X_train.loc[idx, 'Hann_window_mean_15000'] = (convolve(xc, hann(15000), mode='same')/sum(hann(15000))).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta1_mean'] = classic_sta_lta(xc, 500, 10000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta2_mean'] = classic_sta_lta(xc, 5000, 100000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta3_mean'] = classic_sta_lta(xc, 3333, 6666).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta4_mean'] = classic_sta_lta(xc, 10000, 25000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta5_mean'] = classic_sta_lta(xc, 50, 1000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta6_mean'] = classic_sta_lta(xc, 100, 5000).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta7_mean'] = classic_sta_lta(xc, 333, 666).mean()\n",
    "    X_train.loc[idx, 'classic_sta_lta8_mean'] = classic_sta_lta(xc, 4000, 10000).mean()\n",
    "    \n",
    "    X_train.loc[idx, 'Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_train.loc[idx, 'exp_moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_3000_mean'] = (ewma(xc, span=3000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_30000_mean'] = (ewma(xc, span=30000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'exp_moving_average_50000_mean'] = (ewma(xc, span=50000).mean()).mean(skipna=True)\n",
    "    \n",
    "    X_train.loc[idx, 'MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X_train.loc[idx,'MA_700MA_BB_high_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] + 2 * X_train.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx,'MA_700MA_BB_low_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] - 2 * X_train.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X_train.loc[idx,'MA_400MA_BB_high_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] + 2 * X_train.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx,'MA_400MA_BB_low_mean'] = (X_train.loc[idx, 'Moving_average_700_mean'] - 2 * X_train.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X_train.loc[idx, 'iqr'] = np.subtract(*np.percentile(xc, [25, 75]))\n",
    "    X_train.loc[idx, 'q999'] = np.quantile(xc, 0.999)\n",
    "    X_train.loc[idx, 'q001'] = np.quantile(xc, 0.001)\n",
    "    X_train.loc[idx, 'ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    X_train.loc[idx, 'number_peaks_50p'] = feature_calculators.number_peaks(xc.values, 50)\n",
    "    X_train.loc[idx, 'number_peaks_100p'] = feature_calculators.number_peaks(xc.values, 100)\n",
    "    X_train.loc[idx, 'number_peaks_500p'] = feature_calculators.number_peaks(xc.values, 500)\n",
    "    X_train.loc[idx, 'number_peaks_1000p'] = feature_calculators.number_peaks(xc.values, 1000)\n",
    "    X_train.loc[idx, 'number_peaks_10000p'] = feature_calculators.number_peaks(xc.values, 10000)\n",
    "    X_train.loc[idx, 'autocorrelaion_10'] = feature_calculators.autocorrelation(xc.values, 10)\n",
    "    X_train.loc[idx, 'autocorrelaion_50'] = feature_calculators.autocorrelation(xc.values, 50)\n",
    "    X_train.loc[idx, 'autocorrelaion_100'] = feature_calculators.autocorrelation(xc.values, 100)\n",
    "    X_train.loc[idx, 'autocorrelaion_1000'] = feature_calculators.autocorrelation(xc.values, 1000)\n",
    "    X_train.loc[idx, 'c3_5'] = feature_calculators.c3(xc.values, 5)\n",
    "    X_train.loc[idx, 'c3_10'] = feature_calculators.c3(xc.values, 10)\n",
    "    X_train.loc[idx, 'c3_100'] = feature_calculators.c3(xc.values, 100)\n",
    "    X_train.loc[idx, 'binned_entropy_50'] = feature_calculators.binned_entropy(xc.values, 50)\n",
    "    X_train.loc[idx, 'binned_entropy_80'] = feature_calculators.binned_entropy(xc.values, 80)\n",
    "    X_train.loc[idx, 'binned_entropy_100'] = feature_calculators.binned_entropy(xc.values, 100)\n",
    "    X_train.loc[idx, 'binned_entropy_500'] = feature_calculators.binned_entropy(xc.values, 500)\n",
    "    X_train.loc[idx, 'mean_abs_change'] = feature_calculators.mean_abs_change(xc.values)\n",
    " \n",
    "    # FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X_train.loc[idx, 'Rmean'] = realFFT.mean()\n",
    "    X_train.loc[idx, 'Rstd'] = realFFT.std()\n",
    "    X_train.loc[idx, 'Rmax'] = realFFT.max()\n",
    "    X_train.loc[idx, 'Rmin'] = realFFT.min()\n",
    "    X_train.loc[idx, 'Imean'] = imagFFT.mean()\n",
    "    X_train.loc[idx, 'Istd'] = imagFFT.std()\n",
    "    X_train.loc[idx, 'Imax'] = imagFFT.max()\n",
    "    X_train.loc[idx, 'Imin'] = imagFFT.min()\n",
    "    \n",
    "    X_train.loc[idx, 'Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X_train.loc[idx, 'Rstd_last_5000'] = realFFT[-5000:].std()\n",
    "    X_train.loc[idx, 'Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X_train.loc[idx, 'Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X_train.loc[idx, 'Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X_train.loc[idx, 'Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X_train.loc[idx, 'Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X_train.loc[idx, 'Rmin_last_15000'] = realFFT[-15000:].min() \n",
    "    \n",
    "    for windows in [10, 50, 100, 500, 1000, 5000, 10000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_mean'] = x_roll_mean.mean()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_std'] = x_roll_mean.std()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_max'] = x_roll_mean.max()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_min'] = x_roll_mean.min()\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q01'] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q05'] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_median'] = np.median(x_roll_mean)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q95'] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_q99'] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_train.loc[idx, f'mean_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_mean))\n",
    "        \n",
    "        X_train.loc[idx, f'std_roll_{windows}_mean'] = x_roll_std.mean()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_std'] = x_roll_std.std()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_max'] = x_roll_std.max()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_min'] = x_roll_std.min()\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q01'] = np.quantile(x_roll_std, 0.01)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q05'] = np.quantile(x_roll_std, 0.05)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_median'] = np.median(x_roll_std)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q95'] = np.quantile(x_roll_std, 0.95)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_q99'] = np.quantile(x_roll_std, 0.99)\n",
    "        X_train.loc[idx, f'std_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_std))       \n",
    "    \n",
    "    # ==================================================================\n",
    "    # =====================denosing data================================\n",
    "    # ==================================================================\n",
    "\n",
    "    x = denoise_signal(high_pass_filter(segment.acoustic_data, low_cutoff=100000), \n",
    "                       wavelet='haar', level=1)\n",
    "    xc = pd.DataFrame(x, columns=['signals']).signals\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    X_train.loc[idx, 'den_mean'] = xc.mean()\n",
    "    X_train.loc[idx, 'den_std'] =xc.std()\n",
    "    X_train.loc[idx, 'den_max'] = xc.max()\n",
    "    X_train.loc[idx, 'den_min'] = xc.min()   \n",
    "    X_train.loc[idx, 'den_mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X_train.loc[idx, 'den_mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X_train.loc[idx, 'den_abs_max'] = np.abs(xc).max()\n",
    "    \n",
    "    X_train.loc[idx, 'den_mean_first_50000'] = xc[:50000].mean()\n",
    "    X_train.loc[idx, 'den_mean_last_50000'] = xc[-50000:].mean()\n",
    "    X_train.loc[idx, 'den_mean_first_10000'] = xc[:10000].mean()\n",
    "    X_train.loc[idx, 'den_mean_last_10000'] = xc[-10000:].mean()\n",
    "    X_train.loc[idx, 'den_std_first_50000'] = xc[:50000].std()\n",
    "    X_train.loc[idx, 'den_std_last_50000'] = xc[-50000:].std()\n",
    "    X_train.loc[idx, 'den_std_first_10000'] = xc[:10000].std()\n",
    "    X_train.loc[idx, 'den_std_last_10000'] = xc[-10000:].std()\n",
    "    X_train.loc[idx, 'den_min_first_50000'] = xc[:50000].min()\n",
    "    X_train.loc[idx, 'den_min_last_50000'] = xc[-50000:].min()\n",
    "    X_train.loc[idx, 'den_min_first_10000'] = xc[:10000].min()\n",
    "    X_train.loc[idx, 'den_min_last_10000'] = xc[-10000:].min()\n",
    "    X_train.loc[idx, 'den_max_first_50000'] = xc[:50000].max()\n",
    "    X_train.loc[idx, 'den_max_last_50000'] = xc[-50000:].max()\n",
    "    X_train.loc[idx, 'den_max_first_10000'] = xc[:10000].max()\n",
    "    X_train.loc[idx, 'den_max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X_train.loc[idx, 'den_max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X_train.loc[idx, 'den_max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X_train.loc[idx, 'den_count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X_train.loc[idx, 'den_sum'] = xc.sum()\n",
    "    \n",
    "    X_train.loc[idx, 'den_mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X_train.loc[idx, 'den_mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X_train.loc[idx, 'den_mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X_train.loc[idx, 'den_mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X_train.loc[idx, 'den_q95'] = np.quantile(xc, 0.95)\n",
    "    X_train.loc[idx, 'den_q99'] = np.quantile(xc, 0.99)\n",
    "    X_train.loc[idx, 'den_q05'] = np.quantile(xc, 0.05)\n",
    "    X_train.loc[idx, 'den_q01'] = np.quantile(xc, 0.01)\n",
    "    X_train.loc[idx, 'den_abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X_train.loc[idx, 'den_abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X_train.loc[idx, 'den_abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X_train.loc[idx, 'den_abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X_train.loc[idx, 'den_trend'] = add_trend_feature(xc)\n",
    "    X_train.loc[idx, 'den_abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X_train.loc[idx, 'den_abs_mean'] = np.abs(xc).mean()\n",
    "    X_train.loc[idx, 'den_abs_std'] = np.abs(xc).std()\n",
    "\n",
    "    X_train.loc[idx, 'den_mad'] = xc.mad()\n",
    "    X_train.loc[idx, 'den_kurt'] = xc.kurtosis()\n",
    "    X_train.loc[idx, 'den_skew'] = xc.skew()\n",
    "    X_train.loc[idx, 'den_median'] = xc.median()\n",
    "    \n",
    "    X_train.loc[idx, 'den_Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X_train.loc[idx, 'den_Hann_window_mean_50'] = (convolve(xc, hann(50), mode='same')/sum(hann(50))).mean()\n",
    "    X_train.loc[idx, 'den_Hann_window_mean_150'] = (convolve(xc, hann(150), mode='same')/sum(hann(150))).mean()\n",
    "    X_train.loc[idx, 'den_Hann_window_mean_1500'] = (convolve(xc, hann(1500), mode='same')/sum(hann(1500))).mean()\n",
    "    X_train.loc[idx, 'den_Hann_window_mean_15000'] = (convolve(xc, hann(15000), mode='same')/sum(hann(15000))).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta1_mean'] = classic_sta_lta(xc, 500, 10000).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta2_mean'] = classic_sta_lta(xc, 5000, 100000).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta3_mean'] = classic_sta_lta(xc, 3333, 6666).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta4_mean'] = classic_sta_lta(xc, 10000, 25000).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta5_mean'] = classic_sta_lta(xc, 50, 1000).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta6_mean'] = classic_sta_lta(xc, 100, 5000).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta7_mean'] = classic_sta_lta(xc, 333, 666).mean()\n",
    "    X_train.loc[idx, 'den_classic_sta_lta8_mean'] = classic_sta_lta(xc, 4000, 10000).mean()\n",
    "    \n",
    "    X_train.loc[idx, 'den_Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_train.loc[idx, 'den_exp_moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_exp_moving_average_3000_mean'] = (ewma(xc, span=3000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_exp_moving_average_30000_mean'] = (ewma(xc, span=30000).mean()).mean(skipna=True)\n",
    "    X_train.loc[idx, 'den_exp_moving_average_50000_mean'] = (ewma(xc, span=50000).mean()).mean(skipna=True)\n",
    "    \n",
    "    X_train.loc[idx, 'den_MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X_train.loc[idx, 'den_MA_700MA_BB_high_mean'] = (X_train.loc[idx, 'den_Moving_average_700_mean'] + 2 * X_train.loc[idx, 'den_MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'den_MA_700MA_BB_low_mean'] = (X_train.loc[idx, 'den_Moving_average_700_mean'] - 2 * X_train.loc[idx, 'den_MA_700MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'den_MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X_train.loc[idx, 'den_MA_400MA_BB_high_mean'] = (X_train.loc[idx, 'den_Moving_average_700_mean'] + 2 * X_train.loc[idx, 'den_MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'den_MA_400MA_BB_low_mean'] = (X_train.loc[idx, 'den_Moving_average_700_mean'] - 2 * X_train.loc[idx, 'den_MA_400MA_std_mean']).mean()\n",
    "    X_train.loc[idx, 'den_MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X_train.loc[idx, 'den_iqr'] = np.subtract(*np.percentile(xc, [25, 75]))\n",
    "    X_train.loc[idx, 'den_q999'] = np.quantile(xc, 0.999)\n",
    "    X_train.loc[idx, 'den_q001'] = np.quantile(xc, 0.001)\n",
    "    X_train.loc[idx, 'den_ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    X_train.loc[idx, 'den_number_peaks_50p'] = feature_calculators.number_peaks(xc.values, 50)\n",
    "    X_train.loc[idx, 'den_number_peaks_100p'] = feature_calculators.number_peaks(xc.values, 100)\n",
    "    X_train.loc[idx, 'den_number_peaks_500p'] = feature_calculators.number_peaks(xc.values, 500)\n",
    "    X_train.loc[idx, 'den_number_peaks_1000p'] = feature_calculators.number_peaks(xc.values, 1000)\n",
    "    X_train.loc[idx, 'den_number_peaks_10000p'] = feature_calculators.number_peaks(xc.values, 10000)\n",
    "    X_train.loc[idx, 'den_autocorrelaion_10'] = feature_calculators.autocorrelation(xc.values, 10)\n",
    "    X_train.loc[idx, 'den_autocorrelaion_50'] = feature_calculators.autocorrelation(xc.values, 50)\n",
    "    X_train.loc[idx, 'den_autocorrelaion_100'] = feature_calculators.autocorrelation(xc.values, 100)\n",
    "    X_train.loc[idx, 'den_autocorrelaion_1000'] = feature_calculators.autocorrelation(xc.values, 1000)\n",
    "    X_train.loc[idx, 'den_c3_5'] = feature_calculators.c3(xc.values, 5)\n",
    "    X_train.loc[idx, 'den_c3_10'] = feature_calculators.c3(xc.values, 10)\n",
    "    X_train.loc[idx, 'den_c3_100'] = feature_calculators.c3(xc.values, 100)\n",
    "    X_train.loc[idx, 'den_binned_entropy_50'] = feature_calculators.binned_entropy(xc.values, 50)\n",
    "    X_train.loc[idx, 'den_binned_entropy_80'] = feature_calculators.binned_entropy(xc.values, 80)\n",
    "    X_train.loc[idx, 'den_binned_entropy_100'] = feature_calculators.binned_entropy(xc.values, 100)\n",
    "    X_train.loc[idx, 'den_binned_entropy_500'] = feature_calculators.binned_entropy(xc.values, 500)\n",
    "    X_train.loc[idx, 'den_mean_abs_change'] = feature_calculators.mean_abs_change(xc.values)\n",
    " \n",
    "    # FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X_train.loc[idx, 'den_Rmean'] = realFFT.mean()\n",
    "    X_train.loc[idx, 'den_Rstd'] = realFFT.std()\n",
    "    X_train.loc[idx, 'den_Rmax'] = realFFT.max()\n",
    "    X_train.loc[idx, 'den_Rmin'] = realFFT.min()\n",
    "    X_train.loc[idx, 'den_Imean'] = imagFFT.mean()\n",
    "    X_train.loc[idx, 'den_Istd'] = imagFFT.std()\n",
    "    X_train.loc[idx, 'den_Imax'] = imagFFT.max()\n",
    "    X_train.loc[idx, 'den_Imin'] = imagFFT.min()\n",
    "    \n",
    "    X_train.loc[idx, 'den_Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X_train.loc[idx, 'den_Rstd_last_5000'] = realFFT[-5000:].std()\n",
    "    X_train.loc[idx, 'den_Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X_train.loc[idx, 'den_Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X_train.loc[idx, 'den_Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X_train.loc[idx, 'den_Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X_train.loc[idx, 'den_Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X_train.loc[idx, 'den_Rmin_last_15000'] = realFFT[-15000:].min() \n",
    "    \n",
    "    for windows in [10, 50, 100, 500, 1000, 5000, 10000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_mean'] = x_roll_mean.mean()\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_std'] = x_roll_mean.std()\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_max'] = x_roll_mean.max()\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_min'] = x_roll_mean.min()\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_q01'] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_q05'] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_median'] = np.median(x_roll_mean)\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_q95'] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_q99'] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_train.loc[idx, f'den_mean_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_mean))\n",
    "        \n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_mean'] = x_roll_std.mean()\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_std'] = x_roll_std.std()\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_max'] = x_roll_std.max()\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_min'] = x_roll_std.min()\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_q01'] = np.quantile(x_roll_std, 0.01)\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_q05'] = np.quantile(x_roll_std, 0.05)\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_median'] = np.median(x_roll_std)\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_q95'] = np.quantile(x_roll_std, 0.95)\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_q99'] = np.quantile(x_roll_std, 0.99)\n",
    "        X_train.loc[idx, f'den_std_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_std))       \n",
    "        \n",
    "    idx += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.to_csv('./new_features/X_train_all_features2.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "mean                                  4.527200000000000\n",
       "std                                   4.015886080174593\n",
       "max                                  94.000000000000000\n",
       "min                                 -97.000000000000000\n",
       "mean_change_abs                      -0.000040000266668\n",
       "mean_change_rate                  74898.794000015230267\n",
       "abs_max                              97.000000000000000\n",
       "mean_first_50000                      4.398320000000000\n",
       "mean_last_50000                       4.557200000000000\n",
       "mean_first_10000                      4.473800000000000\n",
       "mean_last_10000                       4.367000000000000\n",
       "std_first_50000                       4.899867483067990\n",
       "std_last_50000                        3.254612113601281\n",
       "std_first_10000                       3.859015776111317\n",
       "std_last_10000                        3.578965199494111\n",
       "min_first_50000                     -97.000000000000000\n",
       "min_last_50000                      -26.000000000000000\n",
       "min_first_10000                     -26.000000000000000\n",
       "min_last_10000                      -21.000000000000000\n",
       "max_first_50000                      94.000000000000000\n",
       "max_last_50000                       40.000000000000000\n",
       "max_first_10000                      37.000000000000000\n",
       "max_last_10000                       28.000000000000000\n",
       "max_to_min                            0.969072163105011\n",
       "max_to_min_diff                      -3.000000000000000\n",
       "count_big                             0.000000000000000\n",
       "sum                              679080.000000000000000\n",
       "mean_change_rate_first_50000      25000.707263740518101\n",
       "mean_change_rate_last_50000       24996.647333699835144\n",
       "mean_change_rate_first_10000       5007.829606084686020\n",
       "                                          ...          \n",
       "den_std_roll_5000_mean                1.327113226307918\n",
       "den_std_roll_5000_std                 1.970819171585181\n",
       "den_std_roll_5000_max                10.889170443052555\n",
       "den_std_roll_5000_min                 0.000000000000000\n",
       "den_std_roll_5000_q01                 0.000000000000000\n",
       "den_std_roll_5000_q05                 0.000000000000000\n",
       "den_std_roll_5000_median              0.524832633281378\n",
       "den_std_roll_5000_q95                 5.511096482958391\n",
       "den_std_roll_5000_q99                10.880647888587442\n",
       "den_std_roll_5000_av_change          -0.000009861233361\n",
       "den_mean_roll_10000_mean             -0.000250097364400\n",
       "den_mean_roll_10000_std               0.001322851966880\n",
       "den_mean_roll_10000_max               0.027952282301114\n",
       "den_mean_roll_10000_min              -0.027980706388224\n",
       "den_mean_roll_10000_q01              -0.004031369856584\n",
       "den_mean_roll_10000_q05              -0.002093889761101\n",
       "den_mean_roll_10000_median           -0.000014212043555\n",
       "den_mean_roll_10000_q95              -0.000014212043555\n",
       "den_mean_roll_10000_q99               0.003211981591558\n",
       "den_mean_roll_10000_av_change        -0.000000007171302\n",
       "den_std_roll_10000_mean               1.636636986223048\n",
       "den_std_roll_10000_std                1.721270402627208\n",
       "den_std_roll_10000_max                7.704328285326663\n",
       "den_std_roll_10000_min                0.000000000000000\n",
       "den_std_roll_10000_q01                0.000000000000000\n",
       "den_std_roll_10000_q05                0.000000000000000\n",
       "den_std_roll_10000_median             1.198283241531780\n",
       "den_std_roll_10000_q95                4.714213820849198\n",
       "den_std_roll_10000_q99                7.701908980727690\n",
       "den_std_roll_10000_av_change          0.000001084854455\n",
       "Name: 6291, Length: 504, dtype: float64"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.loc[6291]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('D:/kaggle/earthquake/sample_submission.csv', index_col='seg_id')\n",
    "X_test = pd.DataFrame(columns=X_train.columns, dtype=np.float64, index=submission.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████████| 2624/2624 [15:33:11<00:00, 20.73s/it]\n"
     ]
    }
   ],
   "source": [
    "for idx in tqdm(list(submission.index.values)):\n",
    "    \n",
    "    file = 'D:/kaggle/earthquake/test/' + idx + '.csv'\n",
    "    seg = pd.read_csv(file)\n",
    "    \n",
    "    # ==================================================================\n",
    "    # =====================original data================================\n",
    "    # ==================================================================\n",
    "    \n",
    "    xc = pd.Series(seg.acoustic_data.values)\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    X_test.loc[idx, 'mean'] = xc.mean()\n",
    "    X_test.loc[idx, 'std'] =xc.std()\n",
    "    X_test.loc[idx, 'max'] = xc.max()\n",
    "    X_test.loc[idx, 'min'] = xc.min()   \n",
    "    X_test.loc[idx, 'mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X_test.loc[idx, 'mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X_test.loc[idx, 'abs_max'] = np.abs(xc).max()\n",
    "    \n",
    "    X_test.loc[idx, 'mean_first_50000'] = xc[:50000].mean()\n",
    "    X_test.loc[idx, 'mean_last_50000'] = xc[-50000:].mean()\n",
    "    X_test.loc[idx, 'mean_first_10000'] = xc[:10000].mean()\n",
    "    X_test.loc[idx, 'mean_last_10000'] = xc[-10000:].mean()\n",
    "    X_test.loc[idx, 'std_first_50000'] = xc[:50000].std()\n",
    "    X_test.loc[idx, 'std_last_50000'] = xc[-50000:].std()\n",
    "    X_test.loc[idx, 'std_first_10000'] = xc[:10000].std()\n",
    "    X_test.loc[idx, 'std_last_10000'] = xc[-10000:].std()\n",
    "    X_test.loc[idx, 'min_first_50000'] = xc[:50000].min()\n",
    "    X_test.loc[idx, 'min_last_50000'] = xc[-50000:].min()\n",
    "    X_test.loc[idx, 'min_first_10000'] = xc[:10000].min()\n",
    "    X_test.loc[idx, 'min_last_10000'] = xc[-10000:].min()\n",
    "    X_test.loc[idx, 'max_first_50000'] = xc[:50000].max()\n",
    "    X_test.loc[idx, 'max_last_50000'] = xc[-50000:].max()\n",
    "    X_test.loc[idx, 'max_first_10000'] = xc[:10000].max()\n",
    "    X_test.loc[idx, 'max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X_test.loc[idx, 'max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X_test.loc[idx, 'max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X_test.loc[idx, 'count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X_test.loc[idx, 'sum'] = xc.sum()\n",
    "    \n",
    "    X_test.loc[idx, 'mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X_test.loc[idx, 'mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X_test.loc[idx, 'mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X_test.loc[idx, 'mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X_test.loc[idx, 'q95'] = np.quantile(xc, 0.95)\n",
    "    X_test.loc[idx, 'q99'] = np.quantile(xc, 0.99)\n",
    "    X_test.loc[idx, 'q05'] = np.quantile(xc, 0.05)\n",
    "    X_test.loc[idx, 'q01'] = np.quantile(xc, 0.01)\n",
    "    X_test.loc[idx, 'abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X_test.loc[idx, 'abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X_test.loc[idx, 'abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X_test.loc[idx, 'abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X_test.loc[idx, 'trend'] = add_trend_feature(xc)\n",
    "    X_test.loc[idx, 'abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X_test.loc[idx, 'abs_mean'] = np.abs(xc).mean()\n",
    "    X_test.loc[idx, 'abs_std'] = np.abs(xc).std()\n",
    "\n",
    "    X_test.loc[idx, 'mad'] = xc.mad()\n",
    "    X_test.loc[idx, 'kurt'] = xc.kurtosis()\n",
    "    X_test.loc[idx, 'skew'] = xc.skew()\n",
    "    X_test.loc[idx, 'median'] = xc.median()\n",
    "    \n",
    "    X_test.loc[idx, 'Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X_test.loc[idx, 'Hann_window_mean_50'] = (convolve(xc, hann(50), mode='same')/sum(hann(50))).mean()\n",
    "    X_test.loc[idx, 'Hann_window_mean_150'] = (convolve(xc, hann(150), mode='same')/sum(hann(150))).mean()\n",
    "    X_test.loc[idx, 'Hann_window_mean_1500'] = (convolve(xc, hann(1500), mode='same')/sum(hann(1500))).mean()\n",
    "    X_test.loc[idx, 'Hann_window_mean_15000'] = (convolve(xc, hann(15000), mode='same')/sum(hann(15000))).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta1_mean'] = classic_sta_lta(xc, 500, 10000).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta2_mean'] = classic_sta_lta(xc, 5000, 100000).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta3_mean'] = classic_sta_lta(xc, 3333, 6666).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta4_mean'] = classic_sta_lta(xc, 10000, 25000).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta5_mean'] = classic_sta_lta(xc, 50, 1000).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta6_mean'] = classic_sta_lta(xc, 100, 5000).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta7_mean'] = classic_sta_lta(xc, 333, 666).mean()\n",
    "    X_test.loc[idx, 'classic_sta_lta8_mean'] = classic_sta_lta(xc, 4000, 10000).mean()\n",
    "    \n",
    "    X_test.loc[idx, 'Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_test.loc[idx, 'exp_moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'exp_moving_average_3000_mean'] = (ewma(xc, span=3000).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'exp_moving_average_30000_mean'] = (ewma(xc, span=30000).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'exp_moving_average_50000_mean'] = (ewma(xc, span=50000).mean()).mean(skipna=True)\n",
    "    \n",
    "    X_test.loc[idx, 'MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X_test.loc[idx,'MA_700MA_BB_high_mean'] = (X_test.loc[idx, 'Moving_average_700_mean'] + 2 * X_test.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[idx,'MA_700MA_BB_low_mean'] = (X_test.loc[idx, 'Moving_average_700_mean'] - 2 * X_test.loc[idx, 'MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X_test.loc[idx,'MA_400MA_BB_high_mean'] = (X_test.loc[idx, 'Moving_average_700_mean'] + 2 * X_test.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[idx,'MA_400MA_BB_low_mean'] = (X_test.loc[idx, 'Moving_average_700_mean'] - 2 * X_test.loc[idx, 'MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X_test.loc[idx, 'iqr'] = np.subtract(*np.percentile(xc, [25, 75]))\n",
    "    X_test.loc[idx, 'q999'] = np.quantile(xc, 0.999)\n",
    "    X_test.loc[idx, 'q001'] = np.quantile(xc, 0.001)\n",
    "    X_test.loc[idx, 'ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    X_test.loc[idx, 'number_peaks_50p'] = feature_calculators.number_peaks(xc.values, 50)\n",
    "    X_test.loc[idx, 'number_peaks_100p'] = feature_calculators.number_peaks(xc.values, 100)\n",
    "    X_test.loc[idx, 'number_peaks_500p'] = feature_calculators.number_peaks(xc.values, 500)\n",
    "    X_test.loc[idx, 'number_peaks_1000p'] = feature_calculators.number_peaks(xc.values, 1000)\n",
    "    X_test.loc[idx, 'number_peaks_10000p'] = feature_calculators.number_peaks(xc.values, 10000)\n",
    "    X_test.loc[idx, 'autocorrelaion_10'] = feature_calculators.autocorrelation(xc.values, 10)\n",
    "    X_test.loc[idx, 'autocorrelaion_50'] = feature_calculators.autocorrelation(xc.values, 50)\n",
    "    X_test.loc[idx, 'autocorrelaion_100'] = feature_calculators.autocorrelation(xc.values, 100)\n",
    "    X_test.loc[idx, 'autocorrelaion_1000'] = feature_calculators.autocorrelation(xc.values, 1000)\n",
    "    X_test.loc[idx, 'c3_5'] = feature_calculators.c3(xc.values, 5)\n",
    "    X_test.loc[idx, 'c3_10'] = feature_calculators.c3(xc.values, 10)\n",
    "    X_test.loc[idx, 'c3_100'] = feature_calculators.c3(xc.values, 100)\n",
    "    X_test.loc[idx, 'binned_entropy_50'] = feature_calculators.binned_entropy(xc.values, 50)\n",
    "    X_test.loc[idx, 'binned_entropy_80'] = feature_calculators.binned_entropy(xc.values, 80)\n",
    "    X_test.loc[idx, 'binned_entropy_100'] = feature_calculators.binned_entropy(xc.values, 100)\n",
    "    X_test.loc[idx, 'binned_entropy_500'] = feature_calculators.binned_entropy(xc.values, 500)\n",
    "    X_test.loc[idx, 'mean_abs_change'] = feature_calculators.mean_abs_change(xc.values)\n",
    " \n",
    "    # FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X_test.loc[idx, 'Rmean'] = realFFT.mean()\n",
    "    X_test.loc[idx, 'Rstd'] = realFFT.std()\n",
    "    X_test.loc[idx, 'Rmax'] = realFFT.max()\n",
    "    X_test.loc[idx, 'Rmin'] = realFFT.min()\n",
    "    X_test.loc[idx, 'Imean'] = imagFFT.mean()\n",
    "    X_test.loc[idx, 'Istd'] = imagFFT.std()\n",
    "    X_test.loc[idx, 'Imax'] = imagFFT.max()\n",
    "    X_test.loc[idx, 'Imin'] = imagFFT.min()\n",
    "    \n",
    "    X_test.loc[idx, 'Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X_test.loc[idx, 'Rstd_last_5000'] = realFFT[-5000:].std()\n",
    "    X_test.loc[idx, 'Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X_test.loc[idx, 'Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X_test.loc[idx, 'Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X_test.loc[idx, 'Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X_test.loc[idx, 'Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X_test.loc[idx, 'Rmin_last_15000'] = realFFT[-15000:].min() \n",
    "    \n",
    "    for windows in [10, 50, 100, 500, 1000, 5000, 10000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_mean'] = x_roll_mean.mean()\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_std'] = x_roll_mean.std()\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_max'] = x_roll_mean.max()\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_min'] = x_roll_mean.min()\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_q01'] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_q05'] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_median'] = np.median(x_roll_mean)\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_q95'] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_q99'] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_test.loc[idx, f'mean_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_mean))\n",
    "        \n",
    "        X_test.loc[idx, f'std_roll_{windows}_mean'] = x_roll_std.mean()\n",
    "        X_test.loc[idx, f'std_roll_{windows}_std'] = x_roll_std.std()\n",
    "        X_test.loc[idx, f'std_roll_{windows}_max'] = x_roll_std.max()\n",
    "        X_test.loc[idx, f'std_roll_{windows}_min'] = x_roll_std.min()\n",
    "        X_test.loc[idx, f'std_roll_{windows}_q01'] = np.quantile(x_roll_std, 0.01)\n",
    "        X_test.loc[idx, f'std_roll_{windows}_q05'] = np.quantile(x_roll_std, 0.05)\n",
    "        X_test.loc[idx, f'std_roll_{windows}_median'] = np.median(x_roll_std)\n",
    "        X_test.loc[idx, f'std_roll_{windows}_q95'] = np.quantile(x_roll_std, 0.95)\n",
    "        X_test.loc[idx, f'std_roll_{windows}_q99'] = np.quantile(x_roll_std, 0.99)\n",
    "        X_test.loc[idx, f'std_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_std))       \n",
    "        \n",
    "    \n",
    "    # ==================================================================\n",
    "    # =====================denosing data================================\n",
    "    # ==================================================================\n",
    "    \n",
    "    x = denoise_signal(high_pass_filter(seg.acoustic_data, low_cutoff=100000), \n",
    "                       wavelet='haar', level=1)\n",
    "    xc = pd.DataFrame(x, columns=['signals']).signals\n",
    "    zc = np.fft.fft(xc)\n",
    "    \n",
    "    X_test.loc[idx, 'den_mean'] = xc.mean()\n",
    "    X_test.loc[idx, 'den_std'] =xc.std()\n",
    "    X_test.loc[idx, 'den_max'] = xc.max()\n",
    "    X_test.loc[idx, 'den_min'] = xc.min()   \n",
    "    X_test.loc[idx, 'den_mean_change_abs'] = np.mean(np.diff(xc))\n",
    "    X_test.loc[idx, 'den_mean_change_rate'] = np.mean(np.nonzero((np.diff(xc) / xc[:-1]))[0])\n",
    "    X_test.loc[idx, 'den_abs_max'] = np.abs(xc).max()\n",
    "    \n",
    "    X_test.loc[idx, 'den_mean_first_50000'] = xc[:50000].mean()\n",
    "    X_test.loc[idx, 'den_mean_last_50000'] = xc[-50000:].mean()\n",
    "    X_test.loc[idx, 'den_mean_first_10000'] = xc[:10000].mean()\n",
    "    X_test.loc[idx, 'den_mean_last_10000'] = xc[-10000:].mean()\n",
    "    X_test.loc[idx, 'den_std_first_50000'] = xc[:50000].std()\n",
    "    X_test.loc[idx, 'den_std_last_50000'] = xc[-50000:].std()\n",
    "    X_test.loc[idx, 'den_std_first_10000'] = xc[:10000].std()\n",
    "    X_test.loc[idx, 'den_std_last_10000'] = xc[-10000:].std()\n",
    "    X_test.loc[idx, 'den_min_first_50000'] = xc[:50000].min()\n",
    "    X_test.loc[idx, 'den_min_last_50000'] = xc[-50000:].min()\n",
    "    X_test.loc[idx, 'den_min_first_10000'] = xc[:10000].min()\n",
    "    X_test.loc[idx, 'den_min_last_10000'] = xc[-10000:].min()\n",
    "    X_test.loc[idx, 'den_max_first_50000'] = xc[:50000].max()\n",
    "    X_test.loc[idx, 'den_max_last_50000'] = xc[-50000:].max()\n",
    "    X_test.loc[idx, 'den_max_first_10000'] = xc[:10000].max()\n",
    "    X_test.loc[idx, 'den_max_last_10000'] = xc[-10000:].max()\n",
    "    \n",
    "    X_test.loc[idx, 'den_max_to_min'] = xc.max() / np.abs(xc.min())\n",
    "    X_test.loc[idx, 'den_max_to_min_diff'] = xc.max() - np.abs(xc.min())\n",
    "    X_test.loc[idx, 'den_count_big'] = len(xc[np.abs(xc) > 500])\n",
    "    X_test.loc[idx, 'den_sum'] = xc.sum()\n",
    "    \n",
    "    X_test.loc[idx, 'den_mean_change_rate_first_50000'] = np.mean(np.nonzero((np.diff(xc[:50000]) / xc[:50000][:-1]))[0])\n",
    "    X_test.loc[idx, 'den_mean_change_rate_last_50000'] = np.mean(np.nonzero((np.diff(xc[-50000:]) / xc[-50000:][:-1]))[0])\n",
    "    X_test.loc[idx, 'den_mean_change_rate_first_10000'] = np.mean(np.nonzero((np.diff(xc[:10000]) / xc[:10000][:-1]))[0])\n",
    "    X_test.loc[idx, 'den_mean_change_rate_last_10000'] = np.mean(np.nonzero((np.diff(xc[-10000:]) / xc[-10000:][:-1]))[0])\n",
    "    \n",
    "    X_test.loc[idx, 'den_q95'] = np.quantile(xc, 0.95)\n",
    "    X_test.loc[idx, 'den_q99'] = np.quantile(xc, 0.99)\n",
    "    X_test.loc[idx, 'den_q05'] = np.quantile(xc, 0.05)\n",
    "    X_test.loc[idx, 'den_q01'] = np.quantile(xc, 0.01)\n",
    "    X_test.loc[idx, 'den_abs_q95'] = np.quantile(np.abs(xc), 0.95)\n",
    "    X_test.loc[idx, 'den_abs_q99'] = np.quantile(np.abs(xc), 0.99)\n",
    "    X_test.loc[idx, 'den_abs_q05'] = np.quantile(np.abs(xc), 0.05)\n",
    "    X_test.loc[idx, 'den_abs_q01'] = np.quantile(np.abs(xc), 0.01)\n",
    "    \n",
    "    X_test.loc[idx, 'den_trend'] = add_trend_feature(xc)\n",
    "    X_test.loc[idx, 'den_abs_trend'] = add_trend_feature(xc, abs_values=True)\n",
    "    X_test.loc[idx, 'den_abs_mean'] = np.abs(xc).mean()\n",
    "    X_test.loc[idx, 'den_abs_std'] = np.abs(xc).std()\n",
    "\n",
    "    X_test.loc[idx, 'den_mad'] = xc.mad()\n",
    "    X_test.loc[idx, 'den_kurt'] = xc.kurtosis()\n",
    "    X_test.loc[idx, 'den_skew'] = xc.skew()\n",
    "    X_test.loc[idx, 'den_median'] = xc.median()\n",
    "    \n",
    "    X_test.loc[idx, 'den_Hilbert_mean'] = np.abs(hilbert(xc)).mean()\n",
    "    X_test.loc[idx, 'den_Hann_window_mean_50'] = (convolve(xc, hann(50), mode='same')/sum(hann(50))).mean()\n",
    "    X_test.loc[idx, 'den_Hann_window_mean_150'] = (convolve(xc, hann(150), mode='same')/sum(hann(150))).mean()\n",
    "    X_test.loc[idx, 'den_Hann_window_mean_1500'] = (convolve(xc, hann(1500), mode='same')/sum(hann(1500))).mean()\n",
    "    X_test.loc[idx, 'den_Hann_window_mean_15000'] = (convolve(xc, hann(15000), mode='same')/sum(hann(15000))).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta1_mean'] = classic_sta_lta(xc, 500, 10000).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta2_mean'] = classic_sta_lta(xc, 5000, 100000).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta3_mean'] = classic_sta_lta(xc, 3333, 6666).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta4_mean'] = classic_sta_lta(xc, 10000, 25000).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta5_mean'] = classic_sta_lta(xc, 50, 1000).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta6_mean'] = classic_sta_lta(xc, 100, 5000).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta7_mean'] = classic_sta_lta(xc, 333, 666).mean()\n",
    "    X_test.loc[idx, 'den_classic_sta_lta8_mean'] = classic_sta_lta(xc, 4000, 10000).mean()\n",
    "    \n",
    "    X_test.loc[idx, 'den_Moving_average_700_mean'] = xc.rolling(window=700).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_Moving_average_1500_mean'] = xc.rolling(window=1500).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_Moving_average_3000_mean'] = xc.rolling(window=3000).mean().mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_Moving_average_6000_mean'] = xc.rolling(window=6000).mean().mean(skipna=True)\n",
    "    ewma = pd.Series.ewm\n",
    "    X_test.loc[idx, 'den_exp_moving_average_300_mean'] = (ewma(xc, span=300).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_exp_moving_average_3000_mean'] = (ewma(xc, span=3000).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_exp_moving_average_30000_mean'] = (ewma(xc, span=30000).mean()).mean(skipna=True)\n",
    "    X_test.loc[idx, 'den_exp_moving_average_50000_mean'] = (ewma(xc, span=50000).mean()).mean(skipna=True)\n",
    "    \n",
    "    X_test.loc[idx, 'den_MA_700MA_std_mean'] = xc.rolling(window=700).std().mean()\n",
    "    X_test.loc[idx, 'den_MA_700MA_BB_high_mean'] = (X_test.loc[idx, 'den_Moving_average_700_mean'] + 2 * X_test.loc[idx, 'den_MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'den_MA_700MA_BB_low_mean'] = (X_test.loc[idx, 'den_Moving_average_700_mean'] - 2 * X_test.loc[idx, 'den_MA_700MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'den_MA_400MA_std_mean'] = xc.rolling(window=400).std().mean()\n",
    "    X_test.loc[idx, 'den_MA_400MA_BB_high_mean'] = (X_test.loc[idx, 'den_Moving_average_700_mean'] + 2 * X_test.loc[idx, 'den_MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'den_MA_400MA_BB_low_mean'] = (X_test.loc[idx, 'den_Moving_average_700_mean'] - 2 * X_test.loc[idx, 'den_MA_400MA_std_mean']).mean()\n",
    "    X_test.loc[idx, 'den_MA_1000MA_std_mean'] = xc.rolling(window=1000).std().mean()\n",
    "    \n",
    "    X_test.loc[idx, 'den_iqr'] = np.subtract(*np.percentile(xc, [25, 75]))\n",
    "    X_test.loc[idx, 'den_q999'] = np.quantile(xc, 0.999)\n",
    "    X_test.loc[idx, 'den_q001'] = np.quantile(xc, 0.001)\n",
    "    X_test.loc[idx, 'den_ave10'] = stats.trim_mean(xc, 0.1)\n",
    "    \n",
    "    X_test.loc[idx, 'den_number_peaks_50p'] = feature_calculators.number_peaks(xc.values, 50)\n",
    "    X_test.loc[idx, 'den_number_peaks_100p'] = feature_calculators.number_peaks(xc.values, 100)\n",
    "    X_test.loc[idx, 'den_number_peaks_500p'] = feature_calculators.number_peaks(xc.values, 500)\n",
    "    X_test.loc[idx, 'den_number_peaks_1000p'] = feature_calculators.number_peaks(xc.values, 1000)\n",
    "    X_test.loc[idx, 'den_number_peaks_10000p'] = feature_calculators.number_peaks(xc.values, 10000)\n",
    "    X_test.loc[idx, 'den_autocorrelaion_10'] = feature_calculators.autocorrelation(xc.values, 10)\n",
    "    X_test.loc[idx, 'den_autocorrelaion_50'] = feature_calculators.autocorrelation(xc.values, 50)\n",
    "    X_test.loc[idx, 'den_autocorrelaion_100'] = feature_calculators.autocorrelation(xc.values, 100)\n",
    "    X_test.loc[idx, 'den_autocorrelaion_1000'] = feature_calculators.autocorrelation(xc.values, 1000)\n",
    "    X_test.loc[idx, 'den_c3_5'] = feature_calculators.c3(xc.values, 5)\n",
    "    X_test.loc[idx, 'den_c3_10'] = feature_calculators.c3(xc.values, 10)\n",
    "    X_test.loc[idx, 'den_c3_100'] = feature_calculators.c3(xc.values, 100)\n",
    "    X_test.loc[idx, 'den_binned_entropy_50'] = feature_calculators.binned_entropy(xc.values, 50)\n",
    "    X_test.loc[idx, 'den_binned_entropy_80'] = feature_calculators.binned_entropy(xc.values, 80)\n",
    "    X_test.loc[idx, 'den_binned_entropy_100'] = feature_calculators.binned_entropy(xc.values, 100)\n",
    "    X_test.loc[idx, 'den_binned_entropy_500'] = feature_calculators.binned_entropy(xc.values, 500)\n",
    "    X_test.loc[idx, 'den_mean_abs_change'] = feature_calculators.mean_abs_change(xc.values)\n",
    " \n",
    "    # FFT transform values\n",
    "    realFFT = np.real(zc)\n",
    "    imagFFT = np.imag(zc)\n",
    "    X_test.loc[idx, 'den_Rmean'] = realFFT.mean()\n",
    "    X_test.loc[idx, 'den_Rstd'] = realFFT.std()\n",
    "    X_test.loc[idx, 'den_Rmax'] = realFFT.max()\n",
    "    X_test.loc[idx, 'den_Rmin'] = realFFT.min()\n",
    "    X_test.loc[idx, 'den_Imean'] = imagFFT.mean()\n",
    "    X_test.loc[idx, 'den_Istd'] = imagFFT.std()\n",
    "    X_test.loc[idx, 'den_Imax'] = imagFFT.max()\n",
    "    X_test.loc[idx, 'den_Imin'] = imagFFT.min()\n",
    "    \n",
    "    X_test.loc[idx, 'den_Rmean_last_5000'] = realFFT[-5000:].mean()\n",
    "    X_test.loc[idx, 'den_Rstd_last_5000'] = realFFT[-5000:].std()\n",
    "    X_test.loc[idx, 'den_Rmax_last_5000'] = realFFT[-5000:].max()\n",
    "    X_test.loc[idx, 'den_Rmin_last_5000'] = realFFT[-5000:].min()\n",
    "    X_test.loc[idx, 'den_Rmean_last_15000'] = realFFT[-15000:].mean()\n",
    "    X_test.loc[idx, 'den_Rstd_last_15000'] = realFFT[-15000:].std()\n",
    "    X_test.loc[idx, 'den_Rmax_last_15000'] = realFFT[-15000:].max()\n",
    "    X_test.loc[idx, 'den_Rmin_last_15000'] = realFFT[-15000:].min() \n",
    "    \n",
    "    for windows in [10, 50, 100, 500, 1000, 5000, 10000]:\n",
    "        x_roll_std = xc.rolling(windows).std().dropna().values\n",
    "        x_roll_mean = xc.rolling(windows).mean().dropna().values\n",
    "\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_mean'] = x_roll_mean.mean()\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_std'] = x_roll_mean.std()\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_max'] = x_roll_mean.max()\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_min'] = x_roll_mean.min()\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_q01'] = np.quantile(x_roll_mean, 0.01)\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_q05'] = np.quantile(x_roll_mean, 0.05)\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_median'] = np.median(x_roll_mean)\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_q95'] = np.quantile(x_roll_mean, 0.95)\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_q99'] = np.quantile(x_roll_mean, 0.99)\n",
    "        X_test.loc[idx, f'den_mean_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_mean))\n",
    "        \n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_mean'] = x_roll_std.mean()\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_std'] = x_roll_std.std()\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_max'] = x_roll_std.max()\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_min'] = x_roll_std.min()\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_q01'] = np.quantile(x_roll_std, 0.01)\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_q05'] = np.quantile(x_roll_std, 0.05)\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_median'] = np.median(x_roll_std)\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_q95'] = np.quantile(x_roll_std, 0.95)\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_q99'] = np.quantile(x_roll_std, 0.99)\n",
    "        X_test.loc[idx, f'den_std_roll_{windows}_av_change'] = np.mean(np.diff(x_roll_std))   \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.to_csv('./new_features/X_test_all_features.csv', index=True, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>mean_change_abs</th>\n",
       "      <th>mean_change_rate</th>\n",
       "      <th>abs_max</th>\n",
       "      <th>mean_first_50000</th>\n",
       "      <th>mean_last_50000</th>\n",
       "      <th>mean_first_10000</th>\n",
       "      <th>...</th>\n",
       "      <th>den_std_roll_10000_mean</th>\n",
       "      <th>den_std_roll_10000_std</th>\n",
       "      <th>den_std_roll_10000_max</th>\n",
       "      <th>den_std_roll_10000_min</th>\n",
       "      <th>den_std_roll_10000_q01</th>\n",
       "      <th>den_std_roll_10000_q05</th>\n",
       "      <th>den_std_roll_10000_median</th>\n",
       "      <th>den_std_roll_10000_q95</th>\n",
       "      <th>den_std_roll_10000_q99</th>\n",
       "      <th>den_std_roll_10000_av_change</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_id</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>seg_00030f</th>\n",
       "      <td>4.491780000000000</td>\n",
       "      <td>4.893689687028083</td>\n",
       "      <td>115.0</td>\n",
       "      <td>-75.0</td>\n",
       "      <td>0.000026666844446</td>\n",
       "      <td>75044.983541275520111</td>\n",
       "      <td>115.0</td>\n",
       "      <td>4.46644</td>\n",
       "      <td>4.49598</td>\n",
       "      <td>4.3842</td>\n",
       "      <td>...</td>\n",
       "      <td>2.760738879234107</td>\n",
       "      <td>1.767032295683657</td>\n",
       "      <td>6.967250708302509</td>\n",
       "      <td>0.164405001196263</td>\n",
       "      <td>0.412846000585372</td>\n",
       "      <td>0.826215392499982</td>\n",
       "      <td>2.507467554558998</td>\n",
       "      <td>6.888663857287961</td>\n",
       "      <td>6.945255249711699</td>\n",
       "      <td>0.000005375311823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0012b5</th>\n",
       "      <td>4.171153333333334</td>\n",
       "      <td>5.922839443206501</td>\n",
       "      <td>152.0</td>\n",
       "      <td>-140.0</td>\n",
       "      <td>-0.000013333422223</td>\n",
       "      <td>74949.685652956031845</td>\n",
       "      <td>152.0</td>\n",
       "      <td>4.01786</td>\n",
       "      <td>4.24444</td>\n",
       "      <td>4.0635</td>\n",
       "      <td>...</td>\n",
       "      <td>3.895347848312298</td>\n",
       "      <td>2.597804433881185</td>\n",
       "      <td>9.684650699455403</td>\n",
       "      <td>0.621692447357012</td>\n",
       "      <td>0.621692447357012</td>\n",
       "      <td>1.005311049555419</td>\n",
       "      <td>2.724245903661253</td>\n",
       "      <td>8.196541548667495</td>\n",
       "      <td>9.670105862920673</td>\n",
       "      <td>0.000002960198122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_00184e</th>\n",
       "      <td>4.610260000000000</td>\n",
       "      <td>6.946990077499337</td>\n",
       "      <td>248.0</td>\n",
       "      <td>-193.0</td>\n",
       "      <td>-0.000020000133334</td>\n",
       "      <td>74997.632054261513986</td>\n",
       "      <td>248.0</td>\n",
       "      <td>4.55518</td>\n",
       "      <td>4.55380</td>\n",
       "      <td>4.2452</td>\n",
       "      <td>...</td>\n",
       "      <td>4.161058344029043</td>\n",
       "      <td>4.262120691132202</td>\n",
       "      <td>18.718209207638580</td>\n",
       "      <td>0.505298887790425</td>\n",
       "      <td>0.505298887790425</td>\n",
       "      <td>0.666166329089699</td>\n",
       "      <td>2.495974326304224</td>\n",
       "      <td>15.550837465973933</td>\n",
       "      <td>18.710928539918228</td>\n",
       "      <td>-0.000011807302605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_003339</th>\n",
       "      <td>4.531473333333333</td>\n",
       "      <td>4.114146602958790</td>\n",
       "      <td>85.0</td>\n",
       "      <td>-93.0</td>\n",
       "      <td>0.000046666977780</td>\n",
       "      <td>74997.954642264914582</td>\n",
       "      <td>93.0</td>\n",
       "      <td>4.49052</td>\n",
       "      <td>4.48922</td>\n",
       "      <td>4.3834</td>\n",
       "      <td>...</td>\n",
       "      <td>2.188771447927612</td>\n",
       "      <td>1.763563346630023</td>\n",
       "      <td>7.156822811026635</td>\n",
       "      <td>0.000000091560300</td>\n",
       "      <td>0.000000357584224</td>\n",
       "      <td>0.000000357584224</td>\n",
       "      <td>1.819209140846672</td>\n",
       "      <td>7.085477479461632</td>\n",
       "      <td>7.156822811026635</td>\n",
       "      <td>-0.000016477429210</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>seg_0042cc</th>\n",
       "      <td>4.128340000000000</td>\n",
       "      <td>5.797163636219714</td>\n",
       "      <td>177.0</td>\n",
       "      <td>-147.0</td>\n",
       "      <td>-0.000006666711111</td>\n",
       "      <td>75075.108146992672118</td>\n",
       "      <td>177.0</td>\n",
       "      <td>4.23020</td>\n",
       "      <td>4.10524</td>\n",
       "      <td>4.4902</td>\n",
       "      <td>...</td>\n",
       "      <td>3.511429543748389</td>\n",
       "      <td>3.108405193585451</td>\n",
       "      <td>12.939748054498009</td>\n",
       "      <td>0.203877298025122</td>\n",
       "      <td>0.305003526711859</td>\n",
       "      <td>0.622230050386334</td>\n",
       "      <td>2.664548667326618</td>\n",
       "      <td>12.652994419268135</td>\n",
       "      <td>12.937472170513461</td>\n",
       "      <td>0.000012995710112</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 504 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         mean                std    max    min  \\\n",
       "seg_id                                                           \n",
       "seg_00030f  4.491780000000000  4.893689687028083  115.0  -75.0   \n",
       "seg_0012b5  4.171153333333334  5.922839443206501  152.0 -140.0   \n",
       "seg_00184e  4.610260000000000  6.946990077499337  248.0 -193.0   \n",
       "seg_003339  4.531473333333333  4.114146602958790   85.0  -93.0   \n",
       "seg_0042cc  4.128340000000000  5.797163636219714  177.0 -147.0   \n",
       "\n",
       "              mean_change_abs       mean_change_rate  abs_max  \\\n",
       "seg_id                                                          \n",
       "seg_00030f  0.000026666844446  75044.983541275520111    115.0   \n",
       "seg_0012b5 -0.000013333422223  74949.685652956031845    152.0   \n",
       "seg_00184e -0.000020000133334  74997.632054261513986    248.0   \n",
       "seg_003339  0.000046666977780  74997.954642264914582     93.0   \n",
       "seg_0042cc -0.000006666711111  75075.108146992672118    177.0   \n",
       "\n",
       "            mean_first_50000  mean_last_50000  mean_first_10000  \\\n",
       "seg_id                                                            \n",
       "seg_00030f           4.46644          4.49598            4.3842   \n",
       "seg_0012b5           4.01786          4.24444            4.0635   \n",
       "seg_00184e           4.55518          4.55380            4.2452   \n",
       "seg_003339           4.49052          4.48922            4.3834   \n",
       "seg_0042cc           4.23020          4.10524            4.4902   \n",
       "\n",
       "                        ...               den_std_roll_10000_mean  \\\n",
       "seg_id                  ...                                         \n",
       "seg_00030f              ...                     2.760738879234107   \n",
       "seg_0012b5              ...                     3.895347848312298   \n",
       "seg_00184e              ...                     4.161058344029043   \n",
       "seg_003339              ...                     2.188771447927612   \n",
       "seg_0042cc              ...                     3.511429543748389   \n",
       "\n",
       "            den_std_roll_10000_std  den_std_roll_10000_max  \\\n",
       "seg_id                                                       \n",
       "seg_00030f       1.767032295683657       6.967250708302509   \n",
       "seg_0012b5       2.597804433881185       9.684650699455403   \n",
       "seg_00184e       4.262120691132202      18.718209207638580   \n",
       "seg_003339       1.763563346630023       7.156822811026635   \n",
       "seg_0042cc       3.108405193585451      12.939748054498009   \n",
       "\n",
       "            den_std_roll_10000_min  den_std_roll_10000_q01  \\\n",
       "seg_id                                                       \n",
       "seg_00030f       0.164405001196263       0.412846000585372   \n",
       "seg_0012b5       0.621692447357012       0.621692447357012   \n",
       "seg_00184e       0.505298887790425       0.505298887790425   \n",
       "seg_003339       0.000000091560300       0.000000357584224   \n",
       "seg_0042cc       0.203877298025122       0.305003526711859   \n",
       "\n",
       "            den_std_roll_10000_q05  den_std_roll_10000_median  \\\n",
       "seg_id                                                          \n",
       "seg_00030f       0.826215392499982          2.507467554558998   \n",
       "seg_0012b5       1.005311049555419          2.724245903661253   \n",
       "seg_00184e       0.666166329089699          2.495974326304224   \n",
       "seg_003339       0.000000357584224          1.819209140846672   \n",
       "seg_0042cc       0.622230050386334          2.664548667326618   \n",
       "\n",
       "            den_std_roll_10000_q95  den_std_roll_10000_q99  \\\n",
       "seg_id                                                       \n",
       "seg_00030f       6.888663857287961       6.945255249711699   \n",
       "seg_0012b5       8.196541548667495       9.670105862920673   \n",
       "seg_00184e      15.550837465973933      18.710928539918228   \n",
       "seg_003339       7.085477479461632       7.156822811026635   \n",
       "seg_0042cc      12.652994419268135      12.937472170513461   \n",
       "\n",
       "            den_std_roll_10000_av_change  \n",
       "seg_id                                    \n",
       "seg_00030f             0.000005375311823  \n",
       "seg_0012b5             0.000002960198122  \n",
       "seg_00184e            -0.000011807302605  \n",
       "seg_003339            -0.000016477429210  \n",
       "seg_0042cc             0.000012995710112  \n",
       "\n",
       "[5 rows x 504 columns]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(4195, 504)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EVALS = 1000\n",
    "N_FOLDS = 5\n",
    "XGB_MAX_LEAVES = 2**12 \n",
    "XGB_MAX_DEPTH = 50\n",
    "EVAL_METRIC_XGB_REG = 'mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_hyperopt(data, labels, num_evals=NUM_EVALS, diagnostic=False):\n",
    "        \n",
    "    print('Running {} rounds of XGBoost parameter optimisation:'.format(num_evals))\n",
    "    #clear space\n",
    "    gc.collect()\n",
    "\n",
    "    integer_params = ['max_depth']\n",
    "\n",
    "    def objective(space_params):\n",
    "\n",
    "        for param in integer_params:\n",
    "            space_params[param] = int(space_params[param])\n",
    "\n",
    "        #extract multiple nested tree_method conditional parameters\n",
    "        #libera te tutemet ex inferis\n",
    "        if space_params['tree_method']['tree_method'] == 'hist':\n",
    "            max_bin = space_params['tree_method'].get('max_bin')\n",
    "            space_params['max_bin'] = int(max_bin)\n",
    "            if space_params['tree_method']['grow_policy']['grow_policy']['grow_policy'] == 'depthwise':\n",
    "                grow_policy = space_params['tree_method'].get('grow_policy').get('grow_policy').get('grow_policy')\n",
    "                space_params['grow_policy'] = grow_policy\n",
    "                space_params['tree_method'] = 'hist'\n",
    "            else:\n",
    "                max_leaves = space_params['tree_method']['grow_policy']['grow_policy'].get('max_leaves')\n",
    "                space_params['grow_policy'] = 'lossguide'\n",
    "                space_params['max_leaves'] = int(max_leaves)\n",
    "                space_params['tree_method'] = 'hist'\n",
    "        else:\n",
    "            space_params['tree_method'] = space_params['tree_method'].get('tree_method')\n",
    "\n",
    "        #for classification replace EVAL_METRIC_XGB_REG with EVAL_METRIC_XGB_CLASS\n",
    "        cv_results = xgb.cv(space_params, train, nfold=N_FOLDS, metrics=[EVAL_METRIC_XGB_REG],\n",
    "                         early_stopping_rounds=100, stratified=False, seed=42)\n",
    "\n",
    "        best_loss = cv_results['test-mae-mean'].iloc[-1] #or 'test-rmse-mean' if using RMSE\n",
    "\n",
    "        return{'loss':best_loss, 'status': STATUS_OK }\n",
    "\n",
    "    train = xgb.DMatrix(data, labels)\n",
    "\n",
    "    #integer and string parameters, used with hp.choice()\n",
    "    boosting_list = ['gbtree', 'gblinear'] #if including 'dart', make sure to set 'n_estimators'\n",
    "    metric_list = ['mae'] \n",
    "\n",
    "\n",
    "    tree_method = [{'tree_method' : 'exact'},\n",
    "           {'tree_method' : 'approx'},\n",
    "           {'tree_method' : 'hist',\n",
    "            'max_bin': hp.quniform('max_bin', 2**3, 2**7, 1),\n",
    "            'grow_policy' : {'grow_policy': {'grow_policy':'depthwise'},\n",
    "                            'grow_policy' : {'grow_policy':'lossguide',\n",
    "                                              'max_leaves': hp.quniform('max_leaves', 32, XGB_MAX_LEAVES, 1)}}}]\n",
    "\n",
    "\n",
    "    objective_list_reg = ['reg:linear', 'reg:gamma', 'reg:tweedie']\n",
    "    objective_list_class = ['reg:logistic', 'binary:logistic']\n",
    "    #for classification change line below to 'objective_list = objective_list_class'\n",
    "    objective_list = objective_list_reg\n",
    "\n",
    "    space ={'boosting' : hp.choice('boosting', boosting_list),\n",
    "            'tree_method' : hp.choice('tree_method', tree_method),\n",
    "            'max_depth': hp.quniform('max_depth', 2, XGB_MAX_DEPTH, 1),\n",
    "            'reg_alpha' : hp.uniform('reg_alpha', 0, 5),\n",
    "            'reg_lambda' : hp.uniform('reg_lambda', 0, 5),\n",
    "            'min_child_weight' : hp.uniform('min_child_weight', 0, 5),\n",
    "            'gamma' : hp.uniform('gamma', 0, 5),\n",
    "            'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "            'eval_metric' : hp.choice('eval_metric', metric_list),\n",
    "            'objective' : hp.choice('objective', objective_list),\n",
    "            'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "            'colsample_bynode' : hp.quniform('colsample_bynode', 0.1, 1, 0.01),\n",
    "            'colsample_bylevel' : hp.quniform('colsample_bylevel', 0.1, 1, 0.01),\n",
    "            'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "            'nthread' : 3\n",
    "        }\n",
    "\n",
    "    trials = Trials()\n",
    "    best = fmin(fn=objective,\n",
    "                space=space,\n",
    "                algo=tpe.suggest,\n",
    "                max_evals=num_evals, \n",
    "                trials=trials)\n",
    "\n",
    "    best['tree_method'] = tree_method[best['tree_method']]['tree_method']\n",
    "    best['boosting'] = boosting_list[best['boosting']]\n",
    "    best['eval_metric'] = metric_list[best['eval_metric']]\n",
    "    best['objective'] = objective_list[best['objective']]\n",
    "\n",
    "    #cast floats of integer params to int\n",
    "    for param in integer_params:\n",
    "        best[param] = int(best[param])\n",
    "    if 'max_leaves' in best:\n",
    "        best['max_leaves'] = int(best['max_leaves'])\n",
    "    if 'max_bin' in best:\n",
    "        best['max_bin'] = int(best['max_bin'])\n",
    "\n",
    "    print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "\n",
    "    if diagnostic:\n",
    "        return(best, trials)\n",
    "    else:\n",
    "        return(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgb_params = quick_hyperopt(X_train, y_train, 3000, diagnostic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(X, X_test, y, model_type, params=None, folds=folds, model=None):\n",
    "    \n",
    "    oof = np.zeros(len(X))\n",
    "    prediction = np.zeros(len(X_test))\n",
    "    scores = []\n",
    "    feature_importance = pd.DataFrame()\n",
    "    \n",
    "    for fold_n, (train_idx, valid_idx) in enumerate(folds.split(X)):\n",
    "        print('Fold', fold_n, 'started at', time.ctime())\n",
    "        X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
    "        X_valid, y_valid = X.iloc[valid_idx], y.iloc[valid_idx]\n",
    "        \n",
    "        if model_type == 'xgb':\n",
    "            train_data = xgb.DMatrix(data=X_train, label=y_train, feature_names=X.columns)\n",
    "            valid_data = xgb.DMatrix(data=X_valid, label=y_valid, feature_names=X.columns)\n",
    "            model = xgb.train(dtrain=train_data, num_boost_round=20000,\n",
    "                              evals=[(train_data, 'train'), (valid_data, 'valid_data')], \n",
    "                              early_stopping_rounds=200, verbose_eval=500, params=params)\n",
    "            y_pred_valid = model.predict(xgb.DMatrix(X_valid, feature_names=X.columns),\n",
    "                                         ntree_limit=model.best_ntree_limit)\n",
    "            y_pred = model.predict(xgb.DMatrix(X_test, feature_names=X.columns),\n",
    "                                   ntree_limit=model.best_ntree_limit)\n",
    "            \n",
    "        if model_type == 'sklearn':\n",
    "            model.fit(X_train, y_train)\n",
    "            y_pred_valid = model.predict(X_valid).reshape(-1,)\n",
    "            score = mean_absolute_error(y_valid, y_pred_valid)\n",
    "            print(f'Fold: {fold_n},  MAE: {score:.4f}')\n",
    "            y_pred = model.predict(X_test).reshape(-1,)\n",
    "            \n",
    "        oof[valid_idx] = y_pred_valid\n",
    "        scores.append(mean_absolute_error(y_valid, y_pred_valid))\n",
    "        prediction += y_pred\n",
    "        \n",
    "    prediction /= n_fold\n",
    "    print('CV mean score: {0:.4f}, std: {1:.4f}'.format(np.mean(scores), np.std(scores)))\n",
    "    \n",
    "    return oof, prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oof_xgb, prediction_xgb = train_model(X_train, X_test, y_train, model_type='xgb', params=xgb_params, folds=folds, model=None)\n",
    "pd.DataFrame(prediction_xgb, index=X_test.index, columns=['time_to_failure']).to_csv('submission_xgboost_hyperopt.csv', index=True, header=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
