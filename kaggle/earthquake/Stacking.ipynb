{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xgboost as xgb\n",
    "import lightgbm as lgb\n",
    "from sklearn.model_selection import KFold\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "import time\n",
    "from sklearn.metrics import mean_absolute_error\n",
    "pd.options.display.precision = 15\n",
    "import gc\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.kernel_ridge import KernelRidge\n",
    "from sklearn.ensemble import RandomForestRegressor, GradientBoostingRegressor\n",
    "from hyperopt import STATUS_OK, tpe, hp, Trials, fmin\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = pd.read_csv('./new_features/X_train_all_features.csv')\n",
    "X_test = pd.read_csv('./new_features/X_test_all_features.csv', index_col='seg_id')\n",
    "y_train = pd.read_csv('./new_features/y.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_columns = ['classic_sta_lta5_mean', 'classic_sta_lta7_mean', 'den_mean_change_rate_first_10000', 'den_mean_change_rate_last_10000']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.drop(drop_columns, axis=1, inplace=True)\n",
    "X_test.drop(drop_columns, axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import MinMaxScaler\n",
    "\n",
    "mmscaler = MinMaxScaler()\n",
    "mmscaler.fit(X_train)\n",
    "X = pd.DataFrame(mmscaler.transform(X_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import VarianceThreshold\n",
    "\n",
    "var_thresh = VarianceThreshold(threshold=0.0005)\n",
    "var_thresh.fit(X)\n",
    "X_std = var_thresh.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "\n",
    "skb = SelectKBest(k=400)\n",
    "skb.fit(X_std, y_train.values)\n",
    "X = pd.DataFrame(skb.transform(X_std))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = pd.DataFrame(mmscaler.transform(X_test))\n",
    "X_test = pd.DataFrame(var_thresh.transform(X_test))\n",
    "X_test = pd.DataFrame(skb.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "pca = PCA(n_components=200)\n",
    "pca.fit(X)\n",
    "X = pd.DataFrame(pca.transform(X))\n",
    "X_test = pd.DataFrame(pca.transform(X_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>...</th>\n",
       "      <th>190</th>\n",
       "      <th>191</th>\n",
       "      <th>192</th>\n",
       "      <th>193</th>\n",
       "      <th>194</th>\n",
       "      <th>195</th>\n",
       "      <th>196</th>\n",
       "      <th>197</th>\n",
       "      <th>198</th>\n",
       "      <th>199</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.107953364877607</td>\n",
       "      <td>0.086226865656091</td>\n",
       "      <td>-0.167818417721777</td>\n",
       "      <td>0.312307470300600</td>\n",
       "      <td>0.244489311680046</td>\n",
       "      <td>-0.001822412789794</td>\n",
       "      <td>-0.050234845996122</td>\n",
       "      <td>0.037648349724365</td>\n",
       "      <td>0.018483746630681</td>\n",
       "      <td>-0.052131525718691</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001928125914900</td>\n",
       "      <td>0.002563871415589</td>\n",
       "      <td>-0.000823923331111</td>\n",
       "      <td>-0.001098049802039</td>\n",
       "      <td>0.000597022701590</td>\n",
       "      <td>0.004364257419833</td>\n",
       "      <td>0.000530133000811</td>\n",
       "      <td>0.003978025346216</td>\n",
       "      <td>0.000749330515440</td>\n",
       "      <td>-0.001039345626020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.074021890090182</td>\n",
       "      <td>0.932263484791567</td>\n",
       "      <td>-0.123465986278116</td>\n",
       "      <td>0.098984145334026</td>\n",
       "      <td>-0.049151006516144</td>\n",
       "      <td>-0.093352771822127</td>\n",
       "      <td>-0.025024240316138</td>\n",
       "      <td>-0.106406674703662</td>\n",
       "      <td>-0.029576807274270</td>\n",
       "      <td>-0.254047826232103</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002557218373314</td>\n",
       "      <td>-0.008403150036891</td>\n",
       "      <td>0.001201057578292</td>\n",
       "      <td>-0.005216769893716</td>\n",
       "      <td>0.001204372040778</td>\n",
       "      <td>-0.006707823695777</td>\n",
       "      <td>0.007310979723563</td>\n",
       "      <td>-0.005060041100921</td>\n",
       "      <td>-0.000323091387568</td>\n",
       "      <td>-0.001852468954791</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.142300464125533</td>\n",
       "      <td>-0.222630072354468</td>\n",
       "      <td>0.038490503825945</td>\n",
       "      <td>-0.497853654724442</td>\n",
       "      <td>0.156513206635084</td>\n",
       "      <td>-0.004417379216215</td>\n",
       "      <td>-0.065859585976154</td>\n",
       "      <td>-0.233747121459388</td>\n",
       "      <td>0.171279719129034</td>\n",
       "      <td>0.125032847613868</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009196674847936</td>\n",
       "      <td>-0.002872894399093</td>\n",
       "      <td>0.001979264474429</td>\n",
       "      <td>-0.010232868965435</td>\n",
       "      <td>-0.002878841605539</td>\n",
       "      <td>-0.006214416203690</td>\n",
       "      <td>-0.008308896075411</td>\n",
       "      <td>0.005252679321940</td>\n",
       "      <td>0.006303940100064</td>\n",
       "      <td>-0.000229716608700</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.569991644675375</td>\n",
       "      <td>-0.024058900859753</td>\n",
       "      <td>0.333619199598011</td>\n",
       "      <td>-0.000539947402312</td>\n",
       "      <td>-0.098507221104535</td>\n",
       "      <td>-0.092875748678984</td>\n",
       "      <td>0.045925772847427</td>\n",
       "      <td>-0.212183227473374</td>\n",
       "      <td>0.150593319394154</td>\n",
       "      <td>-0.082318763109323</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002742516136841</td>\n",
       "      <td>0.002837979962513</td>\n",
       "      <td>-0.000637577022757</td>\n",
       "      <td>0.000760017445405</td>\n",
       "      <td>-0.000876505485806</td>\n",
       "      <td>-0.003799985311299</td>\n",
       "      <td>0.001787012074628</td>\n",
       "      <td>-0.000986058229067</td>\n",
       "      <td>0.000052297438232</td>\n",
       "      <td>0.002134307351140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.002404344120400</td>\n",
       "      <td>1.119962002672693</td>\n",
       "      <td>0.131407591932466</td>\n",
       "      <td>-0.050751654597614</td>\n",
       "      <td>0.208697129687365</td>\n",
       "      <td>-0.243934963777461</td>\n",
       "      <td>-0.166666676603874</td>\n",
       "      <td>0.045232772065823</td>\n",
       "      <td>-0.187745756716340</td>\n",
       "      <td>-0.124000839924599</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007180084631313</td>\n",
       "      <td>-0.006184689506597</td>\n",
       "      <td>-0.002184689545173</td>\n",
       "      <td>-0.002904251671204</td>\n",
       "      <td>-0.001556154123799</td>\n",
       "      <td>-0.004817724573237</td>\n",
       "      <td>0.000084039422586</td>\n",
       "      <td>-0.001454695615976</td>\n",
       "      <td>-0.007510820747236</td>\n",
       "      <td>0.000718869289658</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>1.368303726230983</td>\n",
       "      <td>-6.348571240149794</td>\n",
       "      <td>-0.208174830220828</td>\n",
       "      <td>0.270976227611800</td>\n",
       "      <td>-0.679025483034904</td>\n",
       "      <td>-0.354220364448557</td>\n",
       "      <td>0.237716481016429</td>\n",
       "      <td>-1.402612743981089</td>\n",
       "      <td>-1.045034082901071</td>\n",
       "      <td>5.449803289605591</td>\n",
       "      <td>...</td>\n",
       "      <td>0.309974438651387</td>\n",
       "      <td>-0.246523374497256</td>\n",
       "      <td>0.046132334685531</td>\n",
       "      <td>0.029611680769988</td>\n",
       "      <td>-0.038925051566779</td>\n",
       "      <td>-0.140671994044290</td>\n",
       "      <td>0.132721180506935</td>\n",
       "      <td>-0.123343406608153</td>\n",
       "      <td>0.017717426102491</td>\n",
       "      <td>-0.096484932410283</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>-0.145009674409088</td>\n",
       "      <td>1.039111366282783</td>\n",
       "      <td>0.270829097996883</td>\n",
       "      <td>-0.280933202352895</td>\n",
       "      <td>0.907833400975354</td>\n",
       "      <td>0.073175759556139</td>\n",
       "      <td>0.376823173436476</td>\n",
       "      <td>0.191317070384733</td>\n",
       "      <td>0.298109466747540</td>\n",
       "      <td>0.247450286005519</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005678973152716</td>\n",
       "      <td>0.004866539750272</td>\n",
       "      <td>0.001832447944927</td>\n",
       "      <td>0.004310121405954</td>\n",
       "      <td>-0.001061258847010</td>\n",
       "      <td>-0.005592333070450</td>\n",
       "      <td>-0.000122205523965</td>\n",
       "      <td>0.003935154241584</td>\n",
       "      <td>0.003030882348314</td>\n",
       "      <td>0.002337306230006</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.197159001377078</td>\n",
       "      <td>0.522417644142654</td>\n",
       "      <td>-0.253137085059994</td>\n",
       "      <td>0.218038008754565</td>\n",
       "      <td>-0.057430886289150</td>\n",
       "      <td>-0.046633138181694</td>\n",
       "      <td>-0.016759919665123</td>\n",
       "      <td>0.143677925918000</td>\n",
       "      <td>0.229093970665383</td>\n",
       "      <td>0.017668133863542</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010088298289631</td>\n",
       "      <td>-0.001819670563087</td>\n",
       "      <td>-0.006115905969301</td>\n",
       "      <td>-0.002636726882337</td>\n",
       "      <td>-0.005281727571862</td>\n",
       "      <td>-0.003250766532919</td>\n",
       "      <td>0.000299141006850</td>\n",
       "      <td>0.003752738341596</td>\n",
       "      <td>-0.004201705285258</td>\n",
       "      <td>0.000029843784724</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.175828846637904</td>\n",
       "      <td>1.371310653455119</td>\n",
       "      <td>-0.280105991125906</td>\n",
       "      <td>0.109007008123958</td>\n",
       "      <td>-0.141814295964524</td>\n",
       "      <td>-0.111838950295712</td>\n",
       "      <td>0.362288046370743</td>\n",
       "      <td>0.082444236168159</td>\n",
       "      <td>0.154759775080573</td>\n",
       "      <td>0.021332295264981</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009084744416026</td>\n",
       "      <td>-0.004651580918087</td>\n",
       "      <td>-0.001679562129941</td>\n",
       "      <td>-0.000304324849361</td>\n",
       "      <td>0.004471254075611</td>\n",
       "      <td>-0.003635081302268</td>\n",
       "      <td>0.002464149519200</td>\n",
       "      <td>-0.001879851928775</td>\n",
       "      <td>0.001084688154346</td>\n",
       "      <td>0.001301067895431</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.733078498168000</td>\n",
       "      <td>0.411122663535047</td>\n",
       "      <td>-0.319787589024885</td>\n",
       "      <td>-0.407907960143995</td>\n",
       "      <td>0.148815271467845</td>\n",
       "      <td>0.032104845040887</td>\n",
       "      <td>-0.078815432634563</td>\n",
       "      <td>-0.063473535726602</td>\n",
       "      <td>-0.049090226988619</td>\n",
       "      <td>-0.382624650743360</td>\n",
       "      <td>...</td>\n",
       "      <td>0.030894136781666</td>\n",
       "      <td>-0.010833345336499</td>\n",
       "      <td>-0.000815166120895</td>\n",
       "      <td>-0.004519821287130</td>\n",
       "      <td>0.003159970781413</td>\n",
       "      <td>-0.003448957378676</td>\n",
       "      <td>0.004540408050658</td>\n",
       "      <td>0.013449114304178</td>\n",
       "      <td>0.002552495051319</td>\n",
       "      <td>0.000237701537133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.230601173756517</td>\n",
       "      <td>0.380968333352997</td>\n",
       "      <td>-0.489064941719550</td>\n",
       "      <td>0.128989956685638</td>\n",
       "      <td>0.202677077000145</td>\n",
       "      <td>0.451938881045423</td>\n",
       "      <td>0.072390103419855</td>\n",
       "      <td>-0.030731613571471</td>\n",
       "      <td>0.061477811002977</td>\n",
       "      <td>-0.125133389728551</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000761380931180</td>\n",
       "      <td>0.002396810458998</td>\n",
       "      <td>0.002817919349108</td>\n",
       "      <td>-0.007035995914803</td>\n",
       "      <td>-0.000680939202520</td>\n",
       "      <td>0.000103546374979</td>\n",
       "      <td>0.000138400765918</td>\n",
       "      <td>-0.000220703588083</td>\n",
       "      <td>-0.000528403597871</td>\n",
       "      <td>0.005051626203396</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>0.311982259925272</td>\n",
       "      <td>1.413130933408412</td>\n",
       "      <td>-0.269152312932617</td>\n",
       "      <td>-0.074445503609192</td>\n",
       "      <td>0.209589634714750</td>\n",
       "      <td>0.422675765179273</td>\n",
       "      <td>0.222702362540597</td>\n",
       "      <td>-0.010847205101022</td>\n",
       "      <td>-0.297049741415257</td>\n",
       "      <td>-0.232319421343355</td>\n",
       "      <td>...</td>\n",
       "      <td>0.010695696996467</td>\n",
       "      <td>-0.000843509767563</td>\n",
       "      <td>-0.002301359844929</td>\n",
       "      <td>-0.002128684083064</td>\n",
       "      <td>-0.000617971152925</td>\n",
       "      <td>-0.000635348765363</td>\n",
       "      <td>-0.002156253244315</td>\n",
       "      <td>0.002556444725611</td>\n",
       "      <td>-0.001657382953619</td>\n",
       "      <td>-0.002308618534418</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>0.588099588371664</td>\n",
       "      <td>1.771058462300618</td>\n",
       "      <td>-0.559428842544288</td>\n",
       "      <td>0.221073301907222</td>\n",
       "      <td>0.082689637583144</td>\n",
       "      <td>-0.090090460120507</td>\n",
       "      <td>-0.025531930340718</td>\n",
       "      <td>-0.038491675495519</td>\n",
       "      <td>0.039025538219517</td>\n",
       "      <td>-0.213997404903251</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006602978336143</td>\n",
       "      <td>-0.001787345837332</td>\n",
       "      <td>-0.004059272274155</td>\n",
       "      <td>-0.000011167386155</td>\n",
       "      <td>0.001183605900913</td>\n",
       "      <td>0.002971059820928</td>\n",
       "      <td>0.002156198565688</td>\n",
       "      <td>0.005137084526362</td>\n",
       "      <td>-0.000349528261056</td>\n",
       "      <td>-0.003517765820293</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>0.534442325837132</td>\n",
       "      <td>0.982931745326434</td>\n",
       "      <td>-0.672664022579045</td>\n",
       "      <td>0.234327893551614</td>\n",
       "      <td>-0.125994160866426</td>\n",
       "      <td>-0.103657044188898</td>\n",
       "      <td>-0.063083565228877</td>\n",
       "      <td>0.032274127412412</td>\n",
       "      <td>-0.047869626250985</td>\n",
       "      <td>-0.039716968346788</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003750862136872</td>\n",
       "      <td>-0.009174617266008</td>\n",
       "      <td>-0.002654281072378</td>\n",
       "      <td>-0.003525898711185</td>\n",
       "      <td>0.006590370016468</td>\n",
       "      <td>-0.006530694607343</td>\n",
       "      <td>0.001340278158080</td>\n",
       "      <td>0.004312626534221</td>\n",
       "      <td>-0.004655227754739</td>\n",
       "      <td>-0.008866523603246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>-0.461157372903915</td>\n",
       "      <td>0.032538748659147</td>\n",
       "      <td>0.370432036473850</td>\n",
       "      <td>-0.005814483698929</td>\n",
       "      <td>-0.207817148275779</td>\n",
       "      <td>-0.072879667257811</td>\n",
       "      <td>-0.175566811000919</td>\n",
       "      <td>-0.035271474986852</td>\n",
       "      <td>-0.101820142673654</td>\n",
       "      <td>-0.137771585812761</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000255580553792</td>\n",
       "      <td>0.002952911221578</td>\n",
       "      <td>-0.002339985994224</td>\n",
       "      <td>-0.000260504172227</td>\n",
       "      <td>0.002867816729487</td>\n",
       "      <td>0.005784645653010</td>\n",
       "      <td>0.002077349265494</td>\n",
       "      <td>-0.004478553734698</td>\n",
       "      <td>-0.003632021287719</td>\n",
       "      <td>-0.004271991112923</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.674152278315528</td>\n",
       "      <td>1.711934879430221</td>\n",
       "      <td>-0.347710334931038</td>\n",
       "      <td>-0.261997679227798</td>\n",
       "      <td>-0.086516011227720</td>\n",
       "      <td>0.209231871058188</td>\n",
       "      <td>-0.063935594395306</td>\n",
       "      <td>-0.095211779096220</td>\n",
       "      <td>0.216858186476243</td>\n",
       "      <td>-0.253773865216560</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013362077964025</td>\n",
       "      <td>-0.009329581883381</td>\n",
       "      <td>-0.001863544030124</td>\n",
       "      <td>-0.002630876395907</td>\n",
       "      <td>-0.004319841857169</td>\n",
       "      <td>-0.010842189746488</td>\n",
       "      <td>-0.003307291954965</td>\n",
       "      <td>0.000893341756210</td>\n",
       "      <td>-0.006390202844853</td>\n",
       "      <td>-0.007306874861624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>-0.045908871550408</td>\n",
       "      <td>1.269833461818795</td>\n",
       "      <td>-0.083289013994115</td>\n",
       "      <td>0.146318439370343</td>\n",
       "      <td>-0.974369097832974</td>\n",
       "      <td>0.118430160213521</td>\n",
       "      <td>-0.184496417720081</td>\n",
       "      <td>0.210829855394130</td>\n",
       "      <td>-0.232891815534744</td>\n",
       "      <td>0.123462529710109</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005633084733445</td>\n",
       "      <td>-0.000165614323724</td>\n",
       "      <td>0.005439384018315</td>\n",
       "      <td>-0.003073515418670</td>\n",
       "      <td>0.000569524280667</td>\n",
       "      <td>-0.004580572547898</td>\n",
       "      <td>0.004254116444521</td>\n",
       "      <td>-0.000973340396306</td>\n",
       "      <td>0.000626669072669</td>\n",
       "      <td>-0.006348379372395</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>0.968092314353599</td>\n",
       "      <td>2.323042932516783</td>\n",
       "      <td>-0.647648508153066</td>\n",
       "      <td>0.192806525136082</td>\n",
       "      <td>-0.004616837954496</td>\n",
       "      <td>-0.177784060857628</td>\n",
       "      <td>0.002670108971107</td>\n",
       "      <td>-0.029431520452971</td>\n",
       "      <td>-0.119531291278291</td>\n",
       "      <td>-0.101066901852805</td>\n",
       "      <td>...</td>\n",
       "      <td>0.016272844851859</td>\n",
       "      <td>-0.010001675689910</td>\n",
       "      <td>-0.010564934716000</td>\n",
       "      <td>-0.004031769366028</td>\n",
       "      <td>-0.004053183262339</td>\n",
       "      <td>-0.012464292522075</td>\n",
       "      <td>0.012331283845416</td>\n",
       "      <td>0.002157606684578</td>\n",
       "      <td>-0.005831948271178</td>\n",
       "      <td>0.003614721803380</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>-0.291616260116330</td>\n",
       "      <td>0.787643410413558</td>\n",
       "      <td>0.095043494711661</td>\n",
       "      <td>0.219567016452799</td>\n",
       "      <td>0.012070297763071</td>\n",
       "      <td>0.056678438042741</td>\n",
       "      <td>-0.298876942795759</td>\n",
       "      <td>0.198249234504911</td>\n",
       "      <td>0.055395879098497</td>\n",
       "      <td>-0.000194510075461</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002793652944895</td>\n",
       "      <td>-0.002376950776106</td>\n",
       "      <td>0.002917636000172</td>\n",
       "      <td>-0.001760848304273</td>\n",
       "      <td>-0.000550660770998</td>\n",
       "      <td>-0.002988582332533</td>\n",
       "      <td>0.003623600503185</td>\n",
       "      <td>-0.000788823048615</td>\n",
       "      <td>-0.001392429600518</td>\n",
       "      <td>-0.000962167294556</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>0.046633723826725</td>\n",
       "      <td>0.587041048816640</td>\n",
       "      <td>-0.214843727509524</td>\n",
       "      <td>0.092664362150248</td>\n",
       "      <td>-0.249491477271549</td>\n",
       "      <td>-0.105468052229099</td>\n",
       "      <td>0.088517208837341</td>\n",
       "      <td>-0.225411718034439</td>\n",
       "      <td>0.147148940770361</td>\n",
       "      <td>0.052244335340634</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001256857330347</td>\n",
       "      <td>-0.002354618380044</td>\n",
       "      <td>-0.002526657109306</td>\n",
       "      <td>-0.004636900458665</td>\n",
       "      <td>0.001263661725471</td>\n",
       "      <td>-0.000647530696452</td>\n",
       "      <td>-0.000700074887553</td>\n",
       "      <td>-0.000662426676947</td>\n",
       "      <td>-0.006539411246654</td>\n",
       "      <td>-0.008445953970378</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>0.176119225884777</td>\n",
       "      <td>0.999076342711137</td>\n",
       "      <td>-0.159922552473635</td>\n",
       "      <td>-0.271115974370511</td>\n",
       "      <td>-0.237579046899261</td>\n",
       "      <td>0.248575354562878</td>\n",
       "      <td>0.360279571218485</td>\n",
       "      <td>0.188810611858742</td>\n",
       "      <td>0.020067049105279</td>\n",
       "      <td>-0.108994166993939</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001066070169161</td>\n",
       "      <td>0.003161278513049</td>\n",
       "      <td>0.000168948896444</td>\n",
       "      <td>-0.001945568274602</td>\n",
       "      <td>-0.004447457055554</td>\n",
       "      <td>-0.002636581498042</td>\n",
       "      <td>-0.001190711229548</td>\n",
       "      <td>0.004511925556224</td>\n",
       "      <td>0.002005544004962</td>\n",
       "      <td>0.006858958959941</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>-0.284795361059280</td>\n",
       "      <td>1.036758958526178</td>\n",
       "      <td>0.488205019361915</td>\n",
       "      <td>-0.683560739192604</td>\n",
       "      <td>-0.004516986281112</td>\n",
       "      <td>-0.044267643435312</td>\n",
       "      <td>-0.095509856950345</td>\n",
       "      <td>-0.192112324841709</td>\n",
       "      <td>-0.221786416302202</td>\n",
       "      <td>0.316313428663336</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.006108297924179</td>\n",
       "      <td>0.012501258656324</td>\n",
       "      <td>-0.002187213825456</td>\n",
       "      <td>0.002846381115791</td>\n",
       "      <td>-0.000921408647303</td>\n",
       "      <td>0.002209089356473</td>\n",
       "      <td>-0.007509157284641</td>\n",
       "      <td>0.005912369680306</td>\n",
       "      <td>-0.010067339800596</td>\n",
       "      <td>-0.005140018528662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>0.783808472318038</td>\n",
       "      <td>1.802757446494078</td>\n",
       "      <td>-0.499094913372130</td>\n",
       "      <td>-0.148002500011901</td>\n",
       "      <td>-0.024745724121103</td>\n",
       "      <td>0.248966177882665</td>\n",
       "      <td>0.019601614089117</td>\n",
       "      <td>0.240093393587048</td>\n",
       "      <td>0.136715667681107</td>\n",
       "      <td>-0.098318562844015</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013032723926886</td>\n",
       "      <td>-0.007946030002196</td>\n",
       "      <td>0.003138641023335</td>\n",
       "      <td>-0.005459182049663</td>\n",
       "      <td>0.002654875623938</td>\n",
       "      <td>-0.000554545710986</td>\n",
       "      <td>0.011866998305114</td>\n",
       "      <td>-0.007836614985571</td>\n",
       "      <td>-0.000581680780461</td>\n",
       "      <td>-0.000270286765597</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>0.352587929382788</td>\n",
       "      <td>1.693232764845110</td>\n",
       "      <td>-0.151959377601231</td>\n",
       "      <td>0.253838282051440</td>\n",
       "      <td>1.005190589990301</td>\n",
       "      <td>-0.246758940199215</td>\n",
       "      <td>0.036544903633221</td>\n",
       "      <td>-0.101579084164902</td>\n",
       "      <td>-0.018777713994131</td>\n",
       "      <td>-0.114325012414993</td>\n",
       "      <td>...</td>\n",
       "      <td>0.006047062189508</td>\n",
       "      <td>0.005736405988839</td>\n",
       "      <td>-0.006647003119645</td>\n",
       "      <td>0.000051474540654</td>\n",
       "      <td>-0.001974512793350</td>\n",
       "      <td>-0.006404225612187</td>\n",
       "      <td>-0.001507412783082</td>\n",
       "      <td>-0.000962266597940</td>\n",
       "      <td>-0.006602515127879</td>\n",
       "      <td>-0.002341324341645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>-0.413386818990905</td>\n",
       "      <td>0.923058912181972</td>\n",
       "      <td>0.153541360757046</td>\n",
       "      <td>0.220208159150782</td>\n",
       "      <td>0.223547142734930</td>\n",
       "      <td>0.007763705491297</td>\n",
       "      <td>0.033360581110475</td>\n",
       "      <td>-0.111520304007106</td>\n",
       "      <td>0.174189692315627</td>\n",
       "      <td>-0.097522629290465</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002362079340243</td>\n",
       "      <td>-0.001453539404187</td>\n",
       "      <td>0.003232170960381</td>\n",
       "      <td>-0.004080538075199</td>\n",
       "      <td>-0.001808530124362</td>\n",
       "      <td>0.006868048045070</td>\n",
       "      <td>-0.001176774254037</td>\n",
       "      <td>0.004893036823264</td>\n",
       "      <td>-0.007709440829266</td>\n",
       "      <td>0.004496736322972</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>0.422573961235782</td>\n",
       "      <td>1.251535389264973</td>\n",
       "      <td>0.010037249422795</td>\n",
       "      <td>-0.229384477852779</td>\n",
       "      <td>0.167938607147873</td>\n",
       "      <td>-0.397951070727617</td>\n",
       "      <td>-0.390202971574161</td>\n",
       "      <td>0.169894773762272</td>\n",
       "      <td>-0.121532265648944</td>\n",
       "      <td>-0.136398468489340</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013493322237432</td>\n",
       "      <td>-0.017011866014270</td>\n",
       "      <td>0.003771199711761</td>\n",
       "      <td>-0.006418664823256</td>\n",
       "      <td>-0.005935279996081</td>\n",
       "      <td>-0.007088720323283</td>\n",
       "      <td>0.013481144981963</td>\n",
       "      <td>0.000964390020989</td>\n",
       "      <td>0.003021063732837</td>\n",
       "      <td>-0.005500501538375</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>-0.533662136963621</td>\n",
       "      <td>1.735556215295156</td>\n",
       "      <td>0.428385887290163</td>\n",
       "      <td>0.272105668621130</td>\n",
       "      <td>0.152175152725088</td>\n",
       "      <td>0.136634020881375</td>\n",
       "      <td>-0.139068658118502</td>\n",
       "      <td>0.187196156894365</td>\n",
       "      <td>0.116367864424142</td>\n",
       "      <td>-0.036195333028832</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002686028098625</td>\n",
       "      <td>0.006782637673260</td>\n",
       "      <td>0.006941049555091</td>\n",
       "      <td>-0.000968859846805</td>\n",
       "      <td>0.005283888979897</td>\n",
       "      <td>-0.003075302809797</td>\n",
       "      <td>0.003253013717152</td>\n",
       "      <td>-0.004612173830570</td>\n",
       "      <td>0.002402460376744</td>\n",
       "      <td>-0.000444261367160</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>0.557544520479502</td>\n",
       "      <td>2.414583521208957</td>\n",
       "      <td>-0.470349014027945</td>\n",
       "      <td>-0.023747204838111</td>\n",
       "      <td>0.396303087792280</td>\n",
       "      <td>0.322407031237901</td>\n",
       "      <td>0.003891025298346</td>\n",
       "      <td>0.012687730816175</td>\n",
       "      <td>0.334234624277808</td>\n",
       "      <td>-0.021317325675947</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009818463261167</td>\n",
       "      <td>-0.001230176829074</td>\n",
       "      <td>0.010214522294819</td>\n",
       "      <td>0.000144034212702</td>\n",
       "      <td>0.004009724237539</td>\n",
       "      <td>-0.002841588337365</td>\n",
       "      <td>0.001986082192603</td>\n",
       "      <td>-0.001867693606699</td>\n",
       "      <td>-0.005673877025018</td>\n",
       "      <td>-0.001467535633284</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>0.616444702490542</td>\n",
       "      <td>0.343694944409247</td>\n",
       "      <td>-0.498957855353603</td>\n",
       "      <td>-0.430115443421893</td>\n",
       "      <td>0.167383036565033</td>\n",
       "      <td>0.595359917145952</td>\n",
       "      <td>0.054929329774506</td>\n",
       "      <td>-0.079057435836443</td>\n",
       "      <td>0.037644488481219</td>\n",
       "      <td>-0.048778236404052</td>\n",
       "      <td>...</td>\n",
       "      <td>0.011735926771958</td>\n",
       "      <td>0.005463907969883</td>\n",
       "      <td>0.007866749447610</td>\n",
       "      <td>0.000105548923666</td>\n",
       "      <td>-0.004099964822912</td>\n",
       "      <td>-0.002085374988624</td>\n",
       "      <td>-0.004229976706260</td>\n",
       "      <td>-0.000794423917604</td>\n",
       "      <td>-0.004833474215376</td>\n",
       "      <td>-0.004343024666140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>0.239460111785652</td>\n",
       "      <td>1.795044012579051</td>\n",
       "      <td>-0.021983110551699</td>\n",
       "      <td>-0.141178729801472</td>\n",
       "      <td>0.389473186392314</td>\n",
       "      <td>-0.377414713579540</td>\n",
       "      <td>0.073203624163984</td>\n",
       "      <td>-0.174447946126800</td>\n",
       "      <td>0.495148254160603</td>\n",
       "      <td>-0.177500608441879</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007795474454111</td>\n",
       "      <td>-0.002849974628674</td>\n",
       "      <td>0.005662375792470</td>\n",
       "      <td>-0.007039941399752</td>\n",
       "      <td>0.002425403961001</td>\n",
       "      <td>0.000628351900942</td>\n",
       "      <td>0.000485797260828</td>\n",
       "      <td>0.000229216714982</td>\n",
       "      <td>0.000160966287027</td>\n",
       "      <td>0.000668678611369</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2594</th>\n",
       "      <td>-0.668466308794481</td>\n",
       "      <td>1.401884073693892</td>\n",
       "      <td>0.636365301620166</td>\n",
       "      <td>0.070037915761163</td>\n",
       "      <td>0.048919022460984</td>\n",
       "      <td>-0.022978921713994</td>\n",
       "      <td>0.076673311227218</td>\n",
       "      <td>-0.301235417574800</td>\n",
       "      <td>-0.023469172801760</td>\n",
       "      <td>0.133056198135230</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.002797332790865</td>\n",
       "      <td>0.000554230417054</td>\n",
       "      <td>0.004977722331214</td>\n",
       "      <td>0.002862895829309</td>\n",
       "      <td>0.004108712734945</td>\n",
       "      <td>0.001328267166044</td>\n",
       "      <td>0.001430763046091</td>\n",
       "      <td>-0.000566134140073</td>\n",
       "      <td>0.001331380869707</td>\n",
       "      <td>-0.004659076825260</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2595</th>\n",
       "      <td>0.345747330061832</td>\n",
       "      <td>1.402598040142019</td>\n",
       "      <td>-0.100095461115915</td>\n",
       "      <td>-0.078588889449413</td>\n",
       "      <td>0.126754900529840</td>\n",
       "      <td>-0.279442611794759</td>\n",
       "      <td>-0.073075260757029</td>\n",
       "      <td>-0.171832886783050</td>\n",
       "      <td>0.091245250518346</td>\n",
       "      <td>-0.114029426520402</td>\n",
       "      <td>...</td>\n",
       "      <td>0.012068400577331</td>\n",
       "      <td>-0.005097360667409</td>\n",
       "      <td>0.002730598475549</td>\n",
       "      <td>-0.006492957625136</td>\n",
       "      <td>0.003768082544614</td>\n",
       "      <td>-0.000537769790000</td>\n",
       "      <td>-0.001678561486993</td>\n",
       "      <td>-0.001774382257578</td>\n",
       "      <td>-0.002956844225233</td>\n",
       "      <td>-0.004486177829350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2596</th>\n",
       "      <td>0.040808484418086</td>\n",
       "      <td>0.636620655940451</td>\n",
       "      <td>0.151020078138185</td>\n",
       "      <td>-0.115477318285541</td>\n",
       "      <td>0.303826609163029</td>\n",
       "      <td>-0.316687833181552</td>\n",
       "      <td>0.094234208272854</td>\n",
       "      <td>0.163840618217476</td>\n",
       "      <td>-0.100542583740147</td>\n",
       "      <td>-0.353986930726454</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000938803918916</td>\n",
       "      <td>0.000516435935463</td>\n",
       "      <td>0.005561067048926</td>\n",
       "      <td>-0.006448157073868</td>\n",
       "      <td>-0.006267998302797</td>\n",
       "      <td>-0.000405381387480</td>\n",
       "      <td>-0.005048490360774</td>\n",
       "      <td>0.003644783453183</td>\n",
       "      <td>-0.000927922776513</td>\n",
       "      <td>0.000441036003150</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2597</th>\n",
       "      <td>-0.595697563270237</td>\n",
       "      <td>0.546266228702776</td>\n",
       "      <td>0.548245550790974</td>\n",
       "      <td>-0.067052729675857</td>\n",
       "      <td>-0.098644512370196</td>\n",
       "      <td>-0.092498082743788</td>\n",
       "      <td>-0.106841650612374</td>\n",
       "      <td>-0.050250116763430</td>\n",
       "      <td>0.270414048888208</td>\n",
       "      <td>-0.174505473930095</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003973317847911</td>\n",
       "      <td>-0.004578069130433</td>\n",
       "      <td>-0.000981670045082</td>\n",
       "      <td>-0.001211507699016</td>\n",
       "      <td>-0.002111484625398</td>\n",
       "      <td>0.000049350804586</td>\n",
       "      <td>-0.001035327223484</td>\n",
       "      <td>-0.000788364335670</td>\n",
       "      <td>0.000030133890091</td>\n",
       "      <td>-0.001125776637932</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2598</th>\n",
       "      <td>0.433357359070176</td>\n",
       "      <td>2.520021830719412</td>\n",
       "      <td>0.013515150411987</td>\n",
       "      <td>-0.717783589847440</td>\n",
       "      <td>0.039366401449105</td>\n",
       "      <td>0.280481307332102</td>\n",
       "      <td>-0.351515690061900</td>\n",
       "      <td>0.270281064313787</td>\n",
       "      <td>0.202933420739289</td>\n",
       "      <td>-0.007526325631835</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005710468456740</td>\n",
       "      <td>-0.006400887321687</td>\n",
       "      <td>0.004401763809849</td>\n",
       "      <td>-0.005923211279419</td>\n",
       "      <td>0.005103186994485</td>\n",
       "      <td>0.002132775035146</td>\n",
       "      <td>-0.001804766416253</td>\n",
       "      <td>-0.001532616184248</td>\n",
       "      <td>0.000201683933648</td>\n",
       "      <td>-0.001897665951475</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2599</th>\n",
       "      <td>0.032977177686974</td>\n",
       "      <td>2.120258179305941</td>\n",
       "      <td>-0.259865625497013</td>\n",
       "      <td>0.454823079797600</td>\n",
       "      <td>-0.118092675109130</td>\n",
       "      <td>0.198693213435356</td>\n",
       "      <td>0.058207223490639</td>\n",
       "      <td>-0.041821729146936</td>\n",
       "      <td>0.157660276314101</td>\n",
       "      <td>-0.054347359731665</td>\n",
       "      <td>...</td>\n",
       "      <td>0.007988965104917</td>\n",
       "      <td>-0.007602920491608</td>\n",
       "      <td>0.000073123431900</td>\n",
       "      <td>0.002684041763995</td>\n",
       "      <td>-0.001347568195879</td>\n",
       "      <td>-0.002044181553117</td>\n",
       "      <td>0.005872221778255</td>\n",
       "      <td>-0.000012331281218</td>\n",
       "      <td>-0.004092629659556</td>\n",
       "      <td>0.000615593234225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2600</th>\n",
       "      <td>-0.242120197530141</td>\n",
       "      <td>0.931082384898190</td>\n",
       "      <td>-0.082862663731624</td>\n",
       "      <td>0.285967766025507</td>\n",
       "      <td>-0.213947712174966</td>\n",
       "      <td>0.111593277377224</td>\n",
       "      <td>-0.006608045717621</td>\n",
       "      <td>-0.139408621398251</td>\n",
       "      <td>0.119566630160397</td>\n",
       "      <td>0.045999145983867</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003578068276018</td>\n",
       "      <td>0.004385376921569</td>\n",
       "      <td>-0.001871434968624</td>\n",
       "      <td>0.001260274533438</td>\n",
       "      <td>0.001061077854133</td>\n",
       "      <td>-0.001611046605555</td>\n",
       "      <td>0.000621684430604</td>\n",
       "      <td>-0.004091973065319</td>\n",
       "      <td>-0.002345284332026</td>\n",
       "      <td>-0.008450535982807</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2601</th>\n",
       "      <td>0.334979226376467</td>\n",
       "      <td>1.892049351012161</td>\n",
       "      <td>-0.102755741739438</td>\n",
       "      <td>-0.228619725421926</td>\n",
       "      <td>-0.041148990418444</td>\n",
       "      <td>0.256297753921019</td>\n",
       "      <td>0.139128307536883</td>\n",
       "      <td>-0.106836938921537</td>\n",
       "      <td>0.069680729682497</td>\n",
       "      <td>-0.121737292553178</td>\n",
       "      <td>...</td>\n",
       "      <td>0.009193608590818</td>\n",
       "      <td>-0.006779196094890</td>\n",
       "      <td>0.004593895807583</td>\n",
       "      <td>0.000354792025089</td>\n",
       "      <td>0.008578193750863</td>\n",
       "      <td>0.006000655541570</td>\n",
       "      <td>0.004772025398276</td>\n",
       "      <td>-0.008026171697336</td>\n",
       "      <td>0.002266640964319</td>\n",
       "      <td>0.000908248712647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2602</th>\n",
       "      <td>0.518042117032004</td>\n",
       "      <td>0.831080738360389</td>\n",
       "      <td>-0.254162437093913</td>\n",
       "      <td>-0.184254680155807</td>\n",
       "      <td>0.134008942490264</td>\n",
       "      <td>-0.417189540591375</td>\n",
       "      <td>-0.251753973800287</td>\n",
       "      <td>0.037691101859377</td>\n",
       "      <td>-0.119100702943013</td>\n",
       "      <td>-0.173119720673516</td>\n",
       "      <td>...</td>\n",
       "      <td>0.028731274650569</td>\n",
       "      <td>-0.011762242342391</td>\n",
       "      <td>-0.001669522307196</td>\n",
       "      <td>-0.009855147336578</td>\n",
       "      <td>0.000570569386950</td>\n",
       "      <td>-0.008161600901983</td>\n",
       "      <td>0.007712053368642</td>\n",
       "      <td>0.005912466328546</td>\n",
       "      <td>-0.006852781116065</td>\n",
       "      <td>-0.003611498925687</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2603</th>\n",
       "      <td>0.781229407902167</td>\n",
       "      <td>2.191738477269508</td>\n",
       "      <td>0.000960247213628</td>\n",
       "      <td>-0.672979173659621</td>\n",
       "      <td>-0.054513641803516</td>\n",
       "      <td>-0.387178348599110</td>\n",
       "      <td>0.322851109251353</td>\n",
       "      <td>0.081811307894553</td>\n",
       "      <td>0.127280621369351</td>\n",
       "      <td>-0.513337741318296</td>\n",
       "      <td>...</td>\n",
       "      <td>0.049142762803614</td>\n",
       "      <td>-0.035642853092357</td>\n",
       "      <td>0.000300239592706</td>\n",
       "      <td>-0.005736539436020</td>\n",
       "      <td>0.004558680836570</td>\n",
       "      <td>-0.017976127018208</td>\n",
       "      <td>0.051691286884792</td>\n",
       "      <td>0.000108109804664</td>\n",
       "      <td>0.009550930448562</td>\n",
       "      <td>0.005751785174456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2604</th>\n",
       "      <td>16.079134019112953</td>\n",
       "      <td>22.182293648873550</td>\n",
       "      <td>-9.043463312951923</td>\n",
       "      <td>-1.515257416976371</td>\n",
       "      <td>0.104177299281805</td>\n",
       "      <td>-0.902052257159188</td>\n",
       "      <td>0.629212822616143</td>\n",
       "      <td>3.217573582309930</td>\n",
       "      <td>2.274146461881054</td>\n",
       "      <td>-12.901916937037376</td>\n",
       "      <td>...</td>\n",
       "      <td>3.142048598054680</td>\n",
       "      <td>-2.357582573082159</td>\n",
       "      <td>-0.203098398168536</td>\n",
       "      <td>-0.691342771662797</td>\n",
       "      <td>0.979765798339566</td>\n",
       "      <td>-1.095475384199674</td>\n",
       "      <td>2.177253746238920</td>\n",
       "      <td>0.042780189676718</td>\n",
       "      <td>0.010054424140972</td>\n",
       "      <td>0.257398583728647</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2605</th>\n",
       "      <td>-0.221305590134429</td>\n",
       "      <td>0.137811940632885</td>\n",
       "      <td>-0.098869760275395</td>\n",
       "      <td>0.410266407182754</td>\n",
       "      <td>0.172227331434995</td>\n",
       "      <td>0.103672441271017</td>\n",
       "      <td>-0.046843000423810</td>\n",
       "      <td>0.008418057641589</td>\n",
       "      <td>-0.411589207299127</td>\n",
       "      <td>-0.003501227082549</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000832659578232</td>\n",
       "      <td>-0.000736912428702</td>\n",
       "      <td>0.002767668251083</td>\n",
       "      <td>-0.002109311501895</td>\n",
       "      <td>-0.000936523856985</td>\n",
       "      <td>-0.000567036927166</td>\n",
       "      <td>-0.006175996922595</td>\n",
       "      <td>0.001886950678671</td>\n",
       "      <td>-0.001312639991405</td>\n",
       "      <td>0.000326659050056</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2606</th>\n",
       "      <td>-0.102680025265257</td>\n",
       "      <td>1.339130299741649</td>\n",
       "      <td>0.208627574847052</td>\n",
       "      <td>-0.039270557766125</td>\n",
       "      <td>0.060067960114207</td>\n",
       "      <td>0.114168125770622</td>\n",
       "      <td>-0.229611361824885</td>\n",
       "      <td>0.177468169872380</td>\n",
       "      <td>0.033672153018612</td>\n",
       "      <td>-0.372611395962441</td>\n",
       "      <td>...</td>\n",
       "      <td>0.015996961482097</td>\n",
       "      <td>0.002215888378631</td>\n",
       "      <td>0.002234812908331</td>\n",
       "      <td>0.001431571889917</td>\n",
       "      <td>-0.003550513901791</td>\n",
       "      <td>0.002123314718777</td>\n",
       "      <td>0.001681719418624</td>\n",
       "      <td>-0.001682449077631</td>\n",
       "      <td>0.000901213095176</td>\n",
       "      <td>-0.003230396097427</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2607</th>\n",
       "      <td>2.017230896170188</td>\n",
       "      <td>0.563986550112786</td>\n",
       "      <td>-0.483597003579138</td>\n",
       "      <td>-0.581377899286883</td>\n",
       "      <td>-0.088131880544896</td>\n",
       "      <td>-0.168728735754146</td>\n",
       "      <td>-0.231295076170054</td>\n",
       "      <td>-0.073545916277965</td>\n",
       "      <td>0.148046516357375</td>\n",
       "      <td>0.005200290503144</td>\n",
       "      <td>...</td>\n",
       "      <td>0.386877974955469</td>\n",
       "      <td>-0.360133031885668</td>\n",
       "      <td>0.009165294607584</td>\n",
       "      <td>-0.026855505686864</td>\n",
       "      <td>0.098740993425453</td>\n",
       "      <td>-0.144097697666441</td>\n",
       "      <td>0.338448427707441</td>\n",
       "      <td>-0.075795548090447</td>\n",
       "      <td>0.080336929356450</td>\n",
       "      <td>0.025446468329530</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2608</th>\n",
       "      <td>0.468699303564236</td>\n",
       "      <td>1.318877153930527</td>\n",
       "      <td>-0.419965047865746</td>\n",
       "      <td>-0.073425503039883</td>\n",
       "      <td>-0.044253559428666</td>\n",
       "      <td>0.355345083583973</td>\n",
       "      <td>-0.168375338587060</td>\n",
       "      <td>0.104691551972907</td>\n",
       "      <td>0.095063687902251</td>\n",
       "      <td>-0.101279773721304</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013262430720210</td>\n",
       "      <td>-0.005955401004905</td>\n",
       "      <td>0.001825069905657</td>\n",
       "      <td>0.008154817761689</td>\n",
       "      <td>-0.000415956132562</td>\n",
       "      <td>-0.003530123728283</td>\n",
       "      <td>0.001596140473523</td>\n",
       "      <td>-0.001850090445070</td>\n",
       "      <td>0.000721918893222</td>\n",
       "      <td>-0.005706800643407</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2609</th>\n",
       "      <td>0.437749548490492</td>\n",
       "      <td>0.961386026990311</td>\n",
       "      <td>-0.454017912253871</td>\n",
       "      <td>0.087385799900365</td>\n",
       "      <td>-0.090505964842905</td>\n",
       "      <td>0.239584448548153</td>\n",
       "      <td>-0.155654227381243</td>\n",
       "      <td>0.066230942721640</td>\n",
       "      <td>0.218295955705439</td>\n",
       "      <td>-0.135320870050126</td>\n",
       "      <td>...</td>\n",
       "      <td>0.004658730497260</td>\n",
       "      <td>-0.004543623305705</td>\n",
       "      <td>-0.001000364819270</td>\n",
       "      <td>-0.001120394551829</td>\n",
       "      <td>0.003930939332642</td>\n",
       "      <td>-0.000269511612127</td>\n",
       "      <td>0.000406360289198</td>\n",
       "      <td>-0.004840465866457</td>\n",
       "      <td>0.001700167673784</td>\n",
       "      <td>0.000603156955423</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2610</th>\n",
       "      <td>-0.173014474457105</td>\n",
       "      <td>1.224287414595434</td>\n",
       "      <td>0.203457872091359</td>\n",
       "      <td>0.080022080701578</td>\n",
       "      <td>0.091728266710831</td>\n",
       "      <td>-0.095853816596634</td>\n",
       "      <td>0.071699008805696</td>\n",
       "      <td>-0.179728077615433</td>\n",
       "      <td>0.072737223386387</td>\n",
       "      <td>-0.116888534420115</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001915144406417</td>\n",
       "      <td>0.001070582877533</td>\n",
       "      <td>0.001630170270008</td>\n",
       "      <td>0.002444479318067</td>\n",
       "      <td>0.004506265412957</td>\n",
       "      <td>0.000941582490464</td>\n",
       "      <td>0.003657443726992</td>\n",
       "      <td>-0.001111518301015</td>\n",
       "      <td>-0.000726912064616</td>\n",
       "      <td>-0.004763720140836</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2611</th>\n",
       "      <td>-0.243082071842395</td>\n",
       "      <td>1.548337647316750</td>\n",
       "      <td>0.494027863086215</td>\n",
       "      <td>-0.562599275890592</td>\n",
       "      <td>0.225281069577942</td>\n",
       "      <td>0.039112561381370</td>\n",
       "      <td>-0.174172617246544</td>\n",
       "      <td>0.095563919626292</td>\n",
       "      <td>-0.028443747834971</td>\n",
       "      <td>0.066671086317148</td>\n",
       "      <td>...</td>\n",
       "      <td>0.005863874448206</td>\n",
       "      <td>-0.000198277526044</td>\n",
       "      <td>0.000676866774742</td>\n",
       "      <td>-0.003343859505855</td>\n",
       "      <td>0.002793095604696</td>\n",
       "      <td>-0.004365593833230</td>\n",
       "      <td>-0.009965725312768</td>\n",
       "      <td>0.002330443306796</td>\n",
       "      <td>-0.009027715679747</td>\n",
       "      <td>-0.001061857470221</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2612</th>\n",
       "      <td>-0.028356875197429</td>\n",
       "      <td>0.722601050198597</td>\n",
       "      <td>-0.109730823929210</td>\n",
       "      <td>0.029478911651608</td>\n",
       "      <td>0.053167401306135</td>\n",
       "      <td>0.478765239821885</td>\n",
       "      <td>-0.223770159358298</td>\n",
       "      <td>0.171942458971460</td>\n",
       "      <td>-0.220931953184515</td>\n",
       "      <td>-0.111480931144149</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001946284513743</td>\n",
       "      <td>-0.001702983287498</td>\n",
       "      <td>-0.003756673327160</td>\n",
       "      <td>0.000884059133244</td>\n",
       "      <td>-0.002433751417760</td>\n",
       "      <td>-0.001037968503035</td>\n",
       "      <td>-0.002276188829880</td>\n",
       "      <td>-0.000069439046080</td>\n",
       "      <td>-0.001768188956335</td>\n",
       "      <td>-0.001969455277900</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2613</th>\n",
       "      <td>-0.733330407214726</td>\n",
       "      <td>0.609729871069928</td>\n",
       "      <td>0.389120925301873</td>\n",
       "      <td>0.466352390769609</td>\n",
       "      <td>0.287822917682987</td>\n",
       "      <td>0.229607440712409</td>\n",
       "      <td>0.006971757251464</td>\n",
       "      <td>-0.067220595402763</td>\n",
       "      <td>0.091920947885978</td>\n",
       "      <td>-0.007150315789043</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002318458952065</td>\n",
       "      <td>-0.005886109437796</td>\n",
       "      <td>0.000530514472226</td>\n",
       "      <td>0.002574800780645</td>\n",
       "      <td>-0.000361176223487</td>\n",
       "      <td>0.002016133216367</td>\n",
       "      <td>-0.005351940401815</td>\n",
       "      <td>-0.002370296534950</td>\n",
       "      <td>0.000229492119188</td>\n",
       "      <td>-0.000309740969908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2614</th>\n",
       "      <td>-0.368603260176166</td>\n",
       "      <td>0.715735779078583</td>\n",
       "      <td>0.081506789803423</td>\n",
       "      <td>0.367525784191201</td>\n",
       "      <td>0.148156031867460</td>\n",
       "      <td>0.101940322824359</td>\n",
       "      <td>0.105681100460727</td>\n",
       "      <td>-0.199515113913101</td>\n",
       "      <td>-0.102260488839445</td>\n",
       "      <td>-0.192295750049408</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.001409592188466</td>\n",
       "      <td>-0.002965471477088</td>\n",
       "      <td>0.002564861930820</td>\n",
       "      <td>0.000422208210078</td>\n",
       "      <td>-0.002987466756190</td>\n",
       "      <td>0.002131501765258</td>\n",
       "      <td>-0.001787471167545</td>\n",
       "      <td>0.001395577751254</td>\n",
       "      <td>-0.000667595526889</td>\n",
       "      <td>-0.002631651298227</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2615</th>\n",
       "      <td>-0.655373730542272</td>\n",
       "      <td>0.492889235749574</td>\n",
       "      <td>0.344599629348436</td>\n",
       "      <td>0.382636492470709</td>\n",
       "      <td>0.177546592940027</td>\n",
       "      <td>0.187032497882302</td>\n",
       "      <td>-0.105071388497284</td>\n",
       "      <td>0.118731809055373</td>\n",
       "      <td>0.189023019156477</td>\n",
       "      <td>0.065626557038091</td>\n",
       "      <td>...</td>\n",
       "      <td>0.008225583751994</td>\n",
       "      <td>0.004276290640494</td>\n",
       "      <td>0.001445721482037</td>\n",
       "      <td>0.000232432770106</td>\n",
       "      <td>0.001937082387851</td>\n",
       "      <td>-0.000169720993090</td>\n",
       "      <td>-0.000562436838196</td>\n",
       "      <td>-0.000202496680744</td>\n",
       "      <td>-0.000188762197282</td>\n",
       "      <td>0.003719234605140</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2616</th>\n",
       "      <td>0.602366518798170</td>\n",
       "      <td>1.464489534964053</td>\n",
       "      <td>-0.339049178788183</td>\n",
       "      <td>-0.052089811369223</td>\n",
       "      <td>0.123946966186117</td>\n",
       "      <td>0.309853127166107</td>\n",
       "      <td>0.047175674730246</td>\n",
       "      <td>0.020804600520997</td>\n",
       "      <td>-0.026373556737390</td>\n",
       "      <td>-0.276699079974552</td>\n",
       "      <td>...</td>\n",
       "      <td>0.013406438468488</td>\n",
       "      <td>-0.000902340268169</td>\n",
       "      <td>0.002296235775816</td>\n",
       "      <td>0.003631316884949</td>\n",
       "      <td>0.002262811416062</td>\n",
       "      <td>-0.001325088483465</td>\n",
       "      <td>0.004192051168454</td>\n",
       "      <td>0.002241845940306</td>\n",
       "      <td>-0.003116441873521</td>\n",
       "      <td>-0.001187348694580</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2617</th>\n",
       "      <td>-0.620199576164927</td>\n",
       "      <td>0.274426676320380</td>\n",
       "      <td>0.439411176839955</td>\n",
       "      <td>0.073024874683129</td>\n",
       "      <td>0.107275614994205</td>\n",
       "      <td>-0.007084994394655</td>\n",
       "      <td>-0.255765015786330</td>\n",
       "      <td>0.107661277451568</td>\n",
       "      <td>0.162915323950699</td>\n",
       "      <td>-0.142482169876478</td>\n",
       "      <td>...</td>\n",
       "      <td>0.001414199067571</td>\n",
       "      <td>0.001973637820828</td>\n",
       "      <td>-0.002256964662505</td>\n",
       "      <td>-0.002587648609806</td>\n",
       "      <td>0.000714252815333</td>\n",
       "      <td>-0.000601595533837</td>\n",
       "      <td>-0.002002168018647</td>\n",
       "      <td>-0.000025451476053</td>\n",
       "      <td>-0.001961132201097</td>\n",
       "      <td>-0.000258610367123</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2618</th>\n",
       "      <td>-0.026836845568049</td>\n",
       "      <td>2.385139238209117</td>\n",
       "      <td>-0.011877825909074</td>\n",
       "      <td>0.277442791852377</td>\n",
       "      <td>0.000194972480980</td>\n",
       "      <td>0.097695087615899</td>\n",
       "      <td>-0.125829629592112</td>\n",
       "      <td>0.098834757461447</td>\n",
       "      <td>-0.022372548307763</td>\n",
       "      <td>-0.070898411616958</td>\n",
       "      <td>...</td>\n",
       "      <td>0.003389971502152</td>\n",
       "      <td>0.000417668474048</td>\n",
       "      <td>-0.001101435874912</td>\n",
       "      <td>0.001737694242738</td>\n",
       "      <td>0.001493658240808</td>\n",
       "      <td>-0.004274733025650</td>\n",
       "      <td>0.000472997649016</td>\n",
       "      <td>0.000049911935883</td>\n",
       "      <td>0.000430754743771</td>\n",
       "      <td>-0.002841478078975</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2619</th>\n",
       "      <td>-0.046729001009653</td>\n",
       "      <td>1.134860372357454</td>\n",
       "      <td>-0.200704201529380</td>\n",
       "      <td>0.419469175930440</td>\n",
       "      <td>-0.160596035572179</td>\n",
       "      <td>0.169352653763356</td>\n",
       "      <td>0.303479698831223</td>\n",
       "      <td>0.392823933796917</td>\n",
       "      <td>0.097856153043720</td>\n",
       "      <td>0.113849984988652</td>\n",
       "      <td>...</td>\n",
       "      <td>0.002860739558951</td>\n",
       "      <td>-0.002092547705145</td>\n",
       "      <td>0.002187731920107</td>\n",
       "      <td>-0.000446823831347</td>\n",
       "      <td>-0.004572092901484</td>\n",
       "      <td>-0.000024852528293</td>\n",
       "      <td>-0.003594110085565</td>\n",
       "      <td>-0.002435909160470</td>\n",
       "      <td>0.004107732830892</td>\n",
       "      <td>-0.003089734697278</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2620</th>\n",
       "      <td>-0.075306716073579</td>\n",
       "      <td>1.066322935422788</td>\n",
       "      <td>0.250030007850223</td>\n",
       "      <td>-0.083615444131335</td>\n",
       "      <td>-0.109567043295179</td>\n",
       "      <td>-0.223555408605445</td>\n",
       "      <td>0.423927292094029</td>\n",
       "      <td>-0.190490256296860</td>\n",
       "      <td>0.271645218621666</td>\n",
       "      <td>-0.037976306605946</td>\n",
       "      <td>...</td>\n",
       "      <td>-0.000824088557978</td>\n",
       "      <td>-0.004898881116314</td>\n",
       "      <td>-0.000956361152833</td>\n",
       "      <td>0.001632706975553</td>\n",
       "      <td>0.001431706846077</td>\n",
       "      <td>0.000990205348140</td>\n",
       "      <td>0.005780603432836</td>\n",
       "      <td>-0.004830769569260</td>\n",
       "      <td>-0.000754200257222</td>\n",
       "      <td>0.009811823881547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2621</th>\n",
       "      <td>0.760535105076133</td>\n",
       "      <td>1.950811811224737</td>\n",
       "      <td>-0.093503419756996</td>\n",
       "      <td>-0.486102443301907</td>\n",
       "      <td>-0.098844781769617</td>\n",
       "      <td>0.047976507531607</td>\n",
       "      <td>-0.061231251764139</td>\n",
       "      <td>-0.150029157881255</td>\n",
       "      <td>0.327569308862748</td>\n",
       "      <td>-0.242520822108756</td>\n",
       "      <td>...</td>\n",
       "      <td>0.051996593284572</td>\n",
       "      <td>-0.042373501205878</td>\n",
       "      <td>0.001947715524265</td>\n",
       "      <td>-0.013241843847301</td>\n",
       "      <td>0.010007409990148</td>\n",
       "      <td>-0.015776520298394</td>\n",
       "      <td>0.040109952889930</td>\n",
       "      <td>-0.002918300959031</td>\n",
       "      <td>0.009423516304395</td>\n",
       "      <td>-0.000669191424538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2622</th>\n",
       "      <td>1.522704922973124</td>\n",
       "      <td>0.227480447299246</td>\n",
       "      <td>-0.660648091667944</td>\n",
       "      <td>-0.254066725663745</td>\n",
       "      <td>0.062628157095321</td>\n",
       "      <td>0.026487487938947</td>\n",
       "      <td>0.001702908798819</td>\n",
       "      <td>0.122247246165993</td>\n",
       "      <td>-0.064470789355426</td>\n",
       "      <td>0.115092528495284</td>\n",
       "      <td>...</td>\n",
       "      <td>0.043662021864677</td>\n",
       "      <td>-0.012951194464522</td>\n",
       "      <td>0.005058497947824</td>\n",
       "      <td>-0.025750877470585</td>\n",
       "      <td>-0.007993040485704</td>\n",
       "      <td>-0.006406891366510</td>\n",
       "      <td>-0.011603634185908</td>\n",
       "      <td>0.018177459435638</td>\n",
       "      <td>-0.050877877316674</td>\n",
       "      <td>-0.027625801660614</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2623</th>\n",
       "      <td>-0.709532926579520</td>\n",
       "      <td>0.823171761016180</td>\n",
       "      <td>0.494910929750389</td>\n",
       "      <td>0.132168104916997</td>\n",
       "      <td>-0.041855821207883</td>\n",
       "      <td>0.030805122134570</td>\n",
       "      <td>0.206335284300866</td>\n",
       "      <td>-0.149492979113440</td>\n",
       "      <td>-0.045065092338212</td>\n",
       "      <td>-0.013820123853698</td>\n",
       "      <td>...</td>\n",
       "      <td>0.000658839568177</td>\n",
       "      <td>-0.003522082525116</td>\n",
       "      <td>-0.000129190177598</td>\n",
       "      <td>0.000525284929651</td>\n",
       "      <td>-0.000648814188914</td>\n",
       "      <td>0.002343030890860</td>\n",
       "      <td>0.001316519387852</td>\n",
       "      <td>-0.001662080109133</td>\n",
       "      <td>-0.004450024784143</td>\n",
       "      <td>0.000149091725053</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2624 rows × 200 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     0                   1                  2    \\\n",
       "0     -0.107953364877607   0.086226865656091 -0.167818417721777   \n",
       "1      0.074021890090182   0.932263484791567 -0.123465986278116   \n",
       "2      0.142300464125533  -0.222630072354468  0.038490503825945   \n",
       "3     -0.569991644675375  -0.024058900859753  0.333619199598011   \n",
       "4      0.002404344120400   1.119962002672693  0.131407591932466   \n",
       "5      1.368303726230983  -6.348571240149794 -0.208174830220828   \n",
       "6     -0.145009674409088   1.039111366282783  0.270829097996883   \n",
       "7      0.197159001377078   0.522417644142654 -0.253137085059994   \n",
       "8      0.175828846637904   1.371310653455119 -0.280105991125906   \n",
       "9      0.733078498168000   0.411122663535047 -0.319787589024885   \n",
       "10     0.230601173756517   0.380968333352997 -0.489064941719550   \n",
       "11     0.311982259925272   1.413130933408412 -0.269152312932617   \n",
       "12     0.588099588371664   1.771058462300618 -0.559428842544288   \n",
       "13     0.534442325837132   0.982931745326434 -0.672664022579045   \n",
       "14    -0.461157372903915   0.032538748659147  0.370432036473850   \n",
       "15     0.674152278315528   1.711934879430221 -0.347710334931038   \n",
       "16    -0.045908871550408   1.269833461818795 -0.083289013994115   \n",
       "17     0.968092314353599   2.323042932516783 -0.647648508153066   \n",
       "18    -0.291616260116330   0.787643410413558  0.095043494711661   \n",
       "19     0.046633723826725   0.587041048816640 -0.214843727509524   \n",
       "20     0.176119225884777   0.999076342711137 -0.159922552473635   \n",
       "21    -0.284795361059280   1.036758958526178  0.488205019361915   \n",
       "22     0.783808472318038   1.802757446494078 -0.499094913372130   \n",
       "23     0.352587929382788   1.693232764845110 -0.151959377601231   \n",
       "24    -0.413386818990905   0.923058912181972  0.153541360757046   \n",
       "25     0.422573961235782   1.251535389264973  0.010037249422795   \n",
       "26    -0.533662136963621   1.735556215295156  0.428385887290163   \n",
       "27     0.557544520479502   2.414583521208957 -0.470349014027945   \n",
       "28     0.616444702490542   0.343694944409247 -0.498957855353603   \n",
       "29     0.239460111785652   1.795044012579051 -0.021983110551699   \n",
       "...                  ...                 ...                ...   \n",
       "2594  -0.668466308794481   1.401884073693892  0.636365301620166   \n",
       "2595   0.345747330061832   1.402598040142019 -0.100095461115915   \n",
       "2596   0.040808484418086   0.636620655940451  0.151020078138185   \n",
       "2597  -0.595697563270237   0.546266228702776  0.548245550790974   \n",
       "2598   0.433357359070176   2.520021830719412  0.013515150411987   \n",
       "2599   0.032977177686974   2.120258179305941 -0.259865625497013   \n",
       "2600  -0.242120197530141   0.931082384898190 -0.082862663731624   \n",
       "2601   0.334979226376467   1.892049351012161 -0.102755741739438   \n",
       "2602   0.518042117032004   0.831080738360389 -0.254162437093913   \n",
       "2603   0.781229407902167   2.191738477269508  0.000960247213628   \n",
       "2604  16.079134019112953  22.182293648873550 -9.043463312951923   \n",
       "2605  -0.221305590134429   0.137811940632885 -0.098869760275395   \n",
       "2606  -0.102680025265257   1.339130299741649  0.208627574847052   \n",
       "2607   2.017230896170188   0.563986550112786 -0.483597003579138   \n",
       "2608   0.468699303564236   1.318877153930527 -0.419965047865746   \n",
       "2609   0.437749548490492   0.961386026990311 -0.454017912253871   \n",
       "2610  -0.173014474457105   1.224287414595434  0.203457872091359   \n",
       "2611  -0.243082071842395   1.548337647316750  0.494027863086215   \n",
       "2612  -0.028356875197429   0.722601050198597 -0.109730823929210   \n",
       "2613  -0.733330407214726   0.609729871069928  0.389120925301873   \n",
       "2614  -0.368603260176166   0.715735779078583  0.081506789803423   \n",
       "2615  -0.655373730542272   0.492889235749574  0.344599629348436   \n",
       "2616   0.602366518798170   1.464489534964053 -0.339049178788183   \n",
       "2617  -0.620199576164927   0.274426676320380  0.439411176839955   \n",
       "2618  -0.026836845568049   2.385139238209117 -0.011877825909074   \n",
       "2619  -0.046729001009653   1.134860372357454 -0.200704201529380   \n",
       "2620  -0.075306716073579   1.066322935422788  0.250030007850223   \n",
       "2621   0.760535105076133   1.950811811224737 -0.093503419756996   \n",
       "2622   1.522704922973124   0.227480447299246 -0.660648091667944   \n",
       "2623  -0.709532926579520   0.823171761016180  0.494910929750389   \n",
       "\n",
       "                    3                  4                  5    \\\n",
       "0     0.312307470300600  0.244489311680046 -0.001822412789794   \n",
       "1     0.098984145334026 -0.049151006516144 -0.093352771822127   \n",
       "2    -0.497853654724442  0.156513206635084 -0.004417379216215   \n",
       "3    -0.000539947402312 -0.098507221104535 -0.092875748678984   \n",
       "4    -0.050751654597614  0.208697129687365 -0.243934963777461   \n",
       "5     0.270976227611800 -0.679025483034904 -0.354220364448557   \n",
       "6    -0.280933202352895  0.907833400975354  0.073175759556139   \n",
       "7     0.218038008754565 -0.057430886289150 -0.046633138181694   \n",
       "8     0.109007008123958 -0.141814295964524 -0.111838950295712   \n",
       "9    -0.407907960143995  0.148815271467845  0.032104845040887   \n",
       "10    0.128989956685638  0.202677077000145  0.451938881045423   \n",
       "11   -0.074445503609192  0.209589634714750  0.422675765179273   \n",
       "12    0.221073301907222  0.082689637583144 -0.090090460120507   \n",
       "13    0.234327893551614 -0.125994160866426 -0.103657044188898   \n",
       "14   -0.005814483698929 -0.207817148275779 -0.072879667257811   \n",
       "15   -0.261997679227798 -0.086516011227720  0.209231871058188   \n",
       "16    0.146318439370343 -0.974369097832974  0.118430160213521   \n",
       "17    0.192806525136082 -0.004616837954496 -0.177784060857628   \n",
       "18    0.219567016452799  0.012070297763071  0.056678438042741   \n",
       "19    0.092664362150248 -0.249491477271549 -0.105468052229099   \n",
       "20   -0.271115974370511 -0.237579046899261  0.248575354562878   \n",
       "21   -0.683560739192604 -0.004516986281112 -0.044267643435312   \n",
       "22   -0.148002500011901 -0.024745724121103  0.248966177882665   \n",
       "23    0.253838282051440  1.005190589990301 -0.246758940199215   \n",
       "24    0.220208159150782  0.223547142734930  0.007763705491297   \n",
       "25   -0.229384477852779  0.167938607147873 -0.397951070727617   \n",
       "26    0.272105668621130  0.152175152725088  0.136634020881375   \n",
       "27   -0.023747204838111  0.396303087792280  0.322407031237901   \n",
       "28   -0.430115443421893  0.167383036565033  0.595359917145952   \n",
       "29   -0.141178729801472  0.389473186392314 -0.377414713579540   \n",
       "...                 ...                ...                ...   \n",
       "2594  0.070037915761163  0.048919022460984 -0.022978921713994   \n",
       "2595 -0.078588889449413  0.126754900529840 -0.279442611794759   \n",
       "2596 -0.115477318285541  0.303826609163029 -0.316687833181552   \n",
       "2597 -0.067052729675857 -0.098644512370196 -0.092498082743788   \n",
       "2598 -0.717783589847440  0.039366401449105  0.280481307332102   \n",
       "2599  0.454823079797600 -0.118092675109130  0.198693213435356   \n",
       "2600  0.285967766025507 -0.213947712174966  0.111593277377224   \n",
       "2601 -0.228619725421926 -0.041148990418444  0.256297753921019   \n",
       "2602 -0.184254680155807  0.134008942490264 -0.417189540591375   \n",
       "2603 -0.672979173659621 -0.054513641803516 -0.387178348599110   \n",
       "2604 -1.515257416976371  0.104177299281805 -0.902052257159188   \n",
       "2605  0.410266407182754  0.172227331434995  0.103672441271017   \n",
       "2606 -0.039270557766125  0.060067960114207  0.114168125770622   \n",
       "2607 -0.581377899286883 -0.088131880544896 -0.168728735754146   \n",
       "2608 -0.073425503039883 -0.044253559428666  0.355345083583973   \n",
       "2609  0.087385799900365 -0.090505964842905  0.239584448548153   \n",
       "2610  0.080022080701578  0.091728266710831 -0.095853816596634   \n",
       "2611 -0.562599275890592  0.225281069577942  0.039112561381370   \n",
       "2612  0.029478911651608  0.053167401306135  0.478765239821885   \n",
       "2613  0.466352390769609  0.287822917682987  0.229607440712409   \n",
       "2614  0.367525784191201  0.148156031867460  0.101940322824359   \n",
       "2615  0.382636492470709  0.177546592940027  0.187032497882302   \n",
       "2616 -0.052089811369223  0.123946966186117  0.309853127166107   \n",
       "2617  0.073024874683129  0.107275614994205 -0.007084994394655   \n",
       "2618  0.277442791852377  0.000194972480980  0.097695087615899   \n",
       "2619  0.419469175930440 -0.160596035572179  0.169352653763356   \n",
       "2620 -0.083615444131335 -0.109567043295179 -0.223555408605445   \n",
       "2621 -0.486102443301907 -0.098844781769617  0.047976507531607   \n",
       "2622 -0.254066725663745  0.062628157095321  0.026487487938947   \n",
       "2623  0.132168104916997 -0.041855821207883  0.030805122134570   \n",
       "\n",
       "                    6                  7                  8    \\\n",
       "0    -0.050234845996122  0.037648349724365  0.018483746630681   \n",
       "1    -0.025024240316138 -0.106406674703662 -0.029576807274270   \n",
       "2    -0.065859585976154 -0.233747121459388  0.171279719129034   \n",
       "3     0.045925772847427 -0.212183227473374  0.150593319394154   \n",
       "4    -0.166666676603874  0.045232772065823 -0.187745756716340   \n",
       "5     0.237716481016429 -1.402612743981089 -1.045034082901071   \n",
       "6     0.376823173436476  0.191317070384733  0.298109466747540   \n",
       "7    -0.016759919665123  0.143677925918000  0.229093970665383   \n",
       "8     0.362288046370743  0.082444236168159  0.154759775080573   \n",
       "9    -0.078815432634563 -0.063473535726602 -0.049090226988619   \n",
       "10    0.072390103419855 -0.030731613571471  0.061477811002977   \n",
       "11    0.222702362540597 -0.010847205101022 -0.297049741415257   \n",
       "12   -0.025531930340718 -0.038491675495519  0.039025538219517   \n",
       "13   -0.063083565228877  0.032274127412412 -0.047869626250985   \n",
       "14   -0.175566811000919 -0.035271474986852 -0.101820142673654   \n",
       "15   -0.063935594395306 -0.095211779096220  0.216858186476243   \n",
       "16   -0.184496417720081  0.210829855394130 -0.232891815534744   \n",
       "17    0.002670108971107 -0.029431520452971 -0.119531291278291   \n",
       "18   -0.298876942795759  0.198249234504911  0.055395879098497   \n",
       "19    0.088517208837341 -0.225411718034439  0.147148940770361   \n",
       "20    0.360279571218485  0.188810611858742  0.020067049105279   \n",
       "21   -0.095509856950345 -0.192112324841709 -0.221786416302202   \n",
       "22    0.019601614089117  0.240093393587048  0.136715667681107   \n",
       "23    0.036544903633221 -0.101579084164902 -0.018777713994131   \n",
       "24    0.033360581110475 -0.111520304007106  0.174189692315627   \n",
       "25   -0.390202971574161  0.169894773762272 -0.121532265648944   \n",
       "26   -0.139068658118502  0.187196156894365  0.116367864424142   \n",
       "27    0.003891025298346  0.012687730816175  0.334234624277808   \n",
       "28    0.054929329774506 -0.079057435836443  0.037644488481219   \n",
       "29    0.073203624163984 -0.174447946126800  0.495148254160603   \n",
       "...                 ...                ...                ...   \n",
       "2594  0.076673311227218 -0.301235417574800 -0.023469172801760   \n",
       "2595 -0.073075260757029 -0.171832886783050  0.091245250518346   \n",
       "2596  0.094234208272854  0.163840618217476 -0.100542583740147   \n",
       "2597 -0.106841650612374 -0.050250116763430  0.270414048888208   \n",
       "2598 -0.351515690061900  0.270281064313787  0.202933420739289   \n",
       "2599  0.058207223490639 -0.041821729146936  0.157660276314101   \n",
       "2600 -0.006608045717621 -0.139408621398251  0.119566630160397   \n",
       "2601  0.139128307536883 -0.106836938921537  0.069680729682497   \n",
       "2602 -0.251753973800287  0.037691101859377 -0.119100702943013   \n",
       "2603  0.322851109251353  0.081811307894553  0.127280621369351   \n",
       "2604  0.629212822616143  3.217573582309930  2.274146461881054   \n",
       "2605 -0.046843000423810  0.008418057641589 -0.411589207299127   \n",
       "2606 -0.229611361824885  0.177468169872380  0.033672153018612   \n",
       "2607 -0.231295076170054 -0.073545916277965  0.148046516357375   \n",
       "2608 -0.168375338587060  0.104691551972907  0.095063687902251   \n",
       "2609 -0.155654227381243  0.066230942721640  0.218295955705439   \n",
       "2610  0.071699008805696 -0.179728077615433  0.072737223386387   \n",
       "2611 -0.174172617246544  0.095563919626292 -0.028443747834971   \n",
       "2612 -0.223770159358298  0.171942458971460 -0.220931953184515   \n",
       "2613  0.006971757251464 -0.067220595402763  0.091920947885978   \n",
       "2614  0.105681100460727 -0.199515113913101 -0.102260488839445   \n",
       "2615 -0.105071388497284  0.118731809055373  0.189023019156477   \n",
       "2616  0.047175674730246  0.020804600520997 -0.026373556737390   \n",
       "2617 -0.255765015786330  0.107661277451568  0.162915323950699   \n",
       "2618 -0.125829629592112  0.098834757461447 -0.022372548307763   \n",
       "2619  0.303479698831223  0.392823933796917  0.097856153043720   \n",
       "2620  0.423927292094029 -0.190490256296860  0.271645218621666   \n",
       "2621 -0.061231251764139 -0.150029157881255  0.327569308862748   \n",
       "2622  0.001702908798819  0.122247246165993 -0.064470789355426   \n",
       "2623  0.206335284300866 -0.149492979113440 -0.045065092338212   \n",
       "\n",
       "                     9          ...                        190  \\\n",
       "0     -0.052131525718691        ...         -0.001928125914900   \n",
       "1     -0.254047826232103        ...         -0.002557218373314   \n",
       "2      0.125032847613868        ...          0.009196674847936   \n",
       "3     -0.082318763109323        ...         -0.002742516136841   \n",
       "4     -0.124000839924599        ...          0.007180084631313   \n",
       "5      5.449803289605591        ...          0.309974438651387   \n",
       "6      0.247450286005519        ...          0.005678973152716   \n",
       "7      0.017668133863542        ...          0.010088298289631   \n",
       "8      0.021332295264981        ...          0.009084744416026   \n",
       "9     -0.382624650743360        ...          0.030894136781666   \n",
       "10    -0.125133389728551        ...          0.000761380931180   \n",
       "11    -0.232319421343355        ...          0.010695696996467   \n",
       "12    -0.213997404903251        ...          0.006602978336143   \n",
       "13    -0.039716968346788        ...          0.003750862136872   \n",
       "14    -0.137771585812761        ...         -0.000255580553792   \n",
       "15    -0.253773865216560        ...          0.013362077964025   \n",
       "16     0.123462529710109        ...          0.005633084733445   \n",
       "17    -0.101066901852805        ...          0.016272844851859   \n",
       "18    -0.000194510075461        ...          0.002793652944895   \n",
       "19     0.052244335340634        ...         -0.001256857330347   \n",
       "20    -0.108994166993939        ...          0.001066070169161   \n",
       "21     0.316313428663336        ...         -0.006108297924179   \n",
       "22    -0.098318562844015        ...          0.013032723926886   \n",
       "23    -0.114325012414993        ...          0.006047062189508   \n",
       "24    -0.097522629290465        ...         -0.002362079340243   \n",
       "25    -0.136398468489340        ...          0.013493322237432   \n",
       "26    -0.036195333028832        ...         -0.002686028098625   \n",
       "27    -0.021317325675947        ...          0.009818463261167   \n",
       "28    -0.048778236404052        ...          0.011735926771958   \n",
       "29    -0.177500608441879        ...          0.007795474454111   \n",
       "...                  ...        ...                        ...   \n",
       "2594   0.133056198135230        ...         -0.002797332790865   \n",
       "2595  -0.114029426520402        ...          0.012068400577331   \n",
       "2596  -0.353986930726454        ...         -0.000938803918916   \n",
       "2597  -0.174505473930095        ...          0.003973317847911   \n",
       "2598  -0.007526325631835        ...          0.005710468456740   \n",
       "2599  -0.054347359731665        ...          0.007988965104917   \n",
       "2600   0.045999145983867        ...          0.003578068276018   \n",
       "2601  -0.121737292553178        ...          0.009193608590818   \n",
       "2602  -0.173119720673516        ...          0.028731274650569   \n",
       "2603  -0.513337741318296        ...          0.049142762803614   \n",
       "2604 -12.901916937037376        ...          3.142048598054680   \n",
       "2605  -0.003501227082549        ...          0.000832659578232   \n",
       "2606  -0.372611395962441        ...          0.015996961482097   \n",
       "2607   0.005200290503144        ...          0.386877974955469   \n",
       "2608  -0.101279773721304        ...          0.013262430720210   \n",
       "2609  -0.135320870050126        ...          0.004658730497260   \n",
       "2610  -0.116888534420115        ...          0.001915144406417   \n",
       "2611   0.066671086317148        ...          0.005863874448206   \n",
       "2612  -0.111480931144149        ...          0.001946284513743   \n",
       "2613  -0.007150315789043        ...          0.002318458952065   \n",
       "2614  -0.192295750049408        ...         -0.001409592188466   \n",
       "2615   0.065626557038091        ...          0.008225583751994   \n",
       "2616  -0.276699079974552        ...          0.013406438468488   \n",
       "2617  -0.142482169876478        ...          0.001414199067571   \n",
       "2618  -0.070898411616958        ...          0.003389971502152   \n",
       "2619   0.113849984988652        ...          0.002860739558951   \n",
       "2620  -0.037976306605946        ...         -0.000824088557978   \n",
       "2621  -0.242520822108756        ...          0.051996593284572   \n",
       "2622   0.115092528495284        ...          0.043662021864677   \n",
       "2623  -0.013820123853698        ...          0.000658839568177   \n",
       "\n",
       "                    191                192                193  \\\n",
       "0     0.002563871415589 -0.000823923331111 -0.001098049802039   \n",
       "1    -0.008403150036891  0.001201057578292 -0.005216769893716   \n",
       "2    -0.002872894399093  0.001979264474429 -0.010232868965435   \n",
       "3     0.002837979962513 -0.000637577022757  0.000760017445405   \n",
       "4    -0.006184689506597 -0.002184689545173 -0.002904251671204   \n",
       "5    -0.246523374497256  0.046132334685531  0.029611680769988   \n",
       "6     0.004866539750272  0.001832447944927  0.004310121405954   \n",
       "7    -0.001819670563087 -0.006115905969301 -0.002636726882337   \n",
       "8    -0.004651580918087 -0.001679562129941 -0.000304324849361   \n",
       "9    -0.010833345336499 -0.000815166120895 -0.004519821287130   \n",
       "10    0.002396810458998  0.002817919349108 -0.007035995914803   \n",
       "11   -0.000843509767563 -0.002301359844929 -0.002128684083064   \n",
       "12   -0.001787345837332 -0.004059272274155 -0.000011167386155   \n",
       "13   -0.009174617266008 -0.002654281072378 -0.003525898711185   \n",
       "14    0.002952911221578 -0.002339985994224 -0.000260504172227   \n",
       "15   -0.009329581883381 -0.001863544030124 -0.002630876395907   \n",
       "16   -0.000165614323724  0.005439384018315 -0.003073515418670   \n",
       "17   -0.010001675689910 -0.010564934716000 -0.004031769366028   \n",
       "18   -0.002376950776106  0.002917636000172 -0.001760848304273   \n",
       "19   -0.002354618380044 -0.002526657109306 -0.004636900458665   \n",
       "20    0.003161278513049  0.000168948896444 -0.001945568274602   \n",
       "21    0.012501258656324 -0.002187213825456  0.002846381115791   \n",
       "22   -0.007946030002196  0.003138641023335 -0.005459182049663   \n",
       "23    0.005736405988839 -0.006647003119645  0.000051474540654   \n",
       "24   -0.001453539404187  0.003232170960381 -0.004080538075199   \n",
       "25   -0.017011866014270  0.003771199711761 -0.006418664823256   \n",
       "26    0.006782637673260  0.006941049555091 -0.000968859846805   \n",
       "27   -0.001230176829074  0.010214522294819  0.000144034212702   \n",
       "28    0.005463907969883  0.007866749447610  0.000105548923666   \n",
       "29   -0.002849974628674  0.005662375792470 -0.007039941399752   \n",
       "...                 ...                ...                ...   \n",
       "2594  0.000554230417054  0.004977722331214  0.002862895829309   \n",
       "2595 -0.005097360667409  0.002730598475549 -0.006492957625136   \n",
       "2596  0.000516435935463  0.005561067048926 -0.006448157073868   \n",
       "2597 -0.004578069130433 -0.000981670045082 -0.001211507699016   \n",
       "2598 -0.006400887321687  0.004401763809849 -0.005923211279419   \n",
       "2599 -0.007602920491608  0.000073123431900  0.002684041763995   \n",
       "2600  0.004385376921569 -0.001871434968624  0.001260274533438   \n",
       "2601 -0.006779196094890  0.004593895807583  0.000354792025089   \n",
       "2602 -0.011762242342391 -0.001669522307196 -0.009855147336578   \n",
       "2603 -0.035642853092357  0.000300239592706 -0.005736539436020   \n",
       "2604 -2.357582573082159 -0.203098398168536 -0.691342771662797   \n",
       "2605 -0.000736912428702  0.002767668251083 -0.002109311501895   \n",
       "2606  0.002215888378631  0.002234812908331  0.001431571889917   \n",
       "2607 -0.360133031885668  0.009165294607584 -0.026855505686864   \n",
       "2608 -0.005955401004905  0.001825069905657  0.008154817761689   \n",
       "2609 -0.004543623305705 -0.001000364819270 -0.001120394551829   \n",
       "2610  0.001070582877533  0.001630170270008  0.002444479318067   \n",
       "2611 -0.000198277526044  0.000676866774742 -0.003343859505855   \n",
       "2612 -0.001702983287498 -0.003756673327160  0.000884059133244   \n",
       "2613 -0.005886109437796  0.000530514472226  0.002574800780645   \n",
       "2614 -0.002965471477088  0.002564861930820  0.000422208210078   \n",
       "2615  0.004276290640494  0.001445721482037  0.000232432770106   \n",
       "2616 -0.000902340268169  0.002296235775816  0.003631316884949   \n",
       "2617  0.001973637820828 -0.002256964662505 -0.002587648609806   \n",
       "2618  0.000417668474048 -0.001101435874912  0.001737694242738   \n",
       "2619 -0.002092547705145  0.002187731920107 -0.000446823831347   \n",
       "2620 -0.004898881116314 -0.000956361152833  0.001632706975553   \n",
       "2621 -0.042373501205878  0.001947715524265 -0.013241843847301   \n",
       "2622 -0.012951194464522  0.005058497947824 -0.025750877470585   \n",
       "2623 -0.003522082525116 -0.000129190177598  0.000525284929651   \n",
       "\n",
       "                    194                195                196  \\\n",
       "0     0.000597022701590  0.004364257419833  0.000530133000811   \n",
       "1     0.001204372040778 -0.006707823695777  0.007310979723563   \n",
       "2    -0.002878841605539 -0.006214416203690 -0.008308896075411   \n",
       "3    -0.000876505485806 -0.003799985311299  0.001787012074628   \n",
       "4    -0.001556154123799 -0.004817724573237  0.000084039422586   \n",
       "5    -0.038925051566779 -0.140671994044290  0.132721180506935   \n",
       "6    -0.001061258847010 -0.005592333070450 -0.000122205523965   \n",
       "7    -0.005281727571862 -0.003250766532919  0.000299141006850   \n",
       "8     0.004471254075611 -0.003635081302268  0.002464149519200   \n",
       "9     0.003159970781413 -0.003448957378676  0.004540408050658   \n",
       "10   -0.000680939202520  0.000103546374979  0.000138400765918   \n",
       "11   -0.000617971152925 -0.000635348765363 -0.002156253244315   \n",
       "12    0.001183605900913  0.002971059820928  0.002156198565688   \n",
       "13    0.006590370016468 -0.006530694607343  0.001340278158080   \n",
       "14    0.002867816729487  0.005784645653010  0.002077349265494   \n",
       "15   -0.004319841857169 -0.010842189746488 -0.003307291954965   \n",
       "16    0.000569524280667 -0.004580572547898  0.004254116444521   \n",
       "17   -0.004053183262339 -0.012464292522075  0.012331283845416   \n",
       "18   -0.000550660770998 -0.002988582332533  0.003623600503185   \n",
       "19    0.001263661725471 -0.000647530696452 -0.000700074887553   \n",
       "20   -0.004447457055554 -0.002636581498042 -0.001190711229548   \n",
       "21   -0.000921408647303  0.002209089356473 -0.007509157284641   \n",
       "22    0.002654875623938 -0.000554545710986  0.011866998305114   \n",
       "23   -0.001974512793350 -0.006404225612187 -0.001507412783082   \n",
       "24   -0.001808530124362  0.006868048045070 -0.001176774254037   \n",
       "25   -0.005935279996081 -0.007088720323283  0.013481144981963   \n",
       "26    0.005283888979897 -0.003075302809797  0.003253013717152   \n",
       "27    0.004009724237539 -0.002841588337365  0.001986082192603   \n",
       "28   -0.004099964822912 -0.002085374988624 -0.004229976706260   \n",
       "29    0.002425403961001  0.000628351900942  0.000485797260828   \n",
       "...                 ...                ...                ...   \n",
       "2594  0.004108712734945  0.001328267166044  0.001430763046091   \n",
       "2595  0.003768082544614 -0.000537769790000 -0.001678561486993   \n",
       "2596 -0.006267998302797 -0.000405381387480 -0.005048490360774   \n",
       "2597 -0.002111484625398  0.000049350804586 -0.001035327223484   \n",
       "2598  0.005103186994485  0.002132775035146 -0.001804766416253   \n",
       "2599 -0.001347568195879 -0.002044181553117  0.005872221778255   \n",
       "2600  0.001061077854133 -0.001611046605555  0.000621684430604   \n",
       "2601  0.008578193750863  0.006000655541570  0.004772025398276   \n",
       "2602  0.000570569386950 -0.008161600901983  0.007712053368642   \n",
       "2603  0.004558680836570 -0.017976127018208  0.051691286884792   \n",
       "2604  0.979765798339566 -1.095475384199674  2.177253746238920   \n",
       "2605 -0.000936523856985 -0.000567036927166 -0.006175996922595   \n",
       "2606 -0.003550513901791  0.002123314718777  0.001681719418624   \n",
       "2607  0.098740993425453 -0.144097697666441  0.338448427707441   \n",
       "2608 -0.000415956132562 -0.003530123728283  0.001596140473523   \n",
       "2609  0.003930939332642 -0.000269511612127  0.000406360289198   \n",
       "2610  0.004506265412957  0.000941582490464  0.003657443726992   \n",
       "2611  0.002793095604696 -0.004365593833230 -0.009965725312768   \n",
       "2612 -0.002433751417760 -0.001037968503035 -0.002276188829880   \n",
       "2613 -0.000361176223487  0.002016133216367 -0.005351940401815   \n",
       "2614 -0.002987466756190  0.002131501765258 -0.001787471167545   \n",
       "2615  0.001937082387851 -0.000169720993090 -0.000562436838196   \n",
       "2616  0.002262811416062 -0.001325088483465  0.004192051168454   \n",
       "2617  0.000714252815333 -0.000601595533837 -0.002002168018647   \n",
       "2618  0.001493658240808 -0.004274733025650  0.000472997649016   \n",
       "2619 -0.004572092901484 -0.000024852528293 -0.003594110085565   \n",
       "2620  0.001431706846077  0.000990205348140  0.005780603432836   \n",
       "2621  0.010007409990148 -0.015776520298394  0.040109952889930   \n",
       "2622 -0.007993040485704 -0.006406891366510 -0.011603634185908   \n",
       "2623 -0.000648814188914  0.002343030890860  0.001316519387852   \n",
       "\n",
       "                    197                198                199  \n",
       "0     0.003978025346216  0.000749330515440 -0.001039345626020  \n",
       "1    -0.005060041100921 -0.000323091387568 -0.001852468954791  \n",
       "2     0.005252679321940  0.006303940100064 -0.000229716608700  \n",
       "3    -0.000986058229067  0.000052297438232  0.002134307351140  \n",
       "4    -0.001454695615976 -0.007510820747236  0.000718869289658  \n",
       "5    -0.123343406608153  0.017717426102491 -0.096484932410283  \n",
       "6     0.003935154241584  0.003030882348314  0.002337306230006  \n",
       "7     0.003752738341596 -0.004201705285258  0.000029843784724  \n",
       "8    -0.001879851928775  0.001084688154346  0.001301067895431  \n",
       "9     0.013449114304178  0.002552495051319  0.000237701537133  \n",
       "10   -0.000220703588083 -0.000528403597871  0.005051626203396  \n",
       "11    0.002556444725611 -0.001657382953619 -0.002308618534418  \n",
       "12    0.005137084526362 -0.000349528261056 -0.003517765820293  \n",
       "13    0.004312626534221 -0.004655227754739 -0.008866523603246  \n",
       "14   -0.004478553734698 -0.003632021287719 -0.004271991112923  \n",
       "15    0.000893341756210 -0.006390202844853 -0.007306874861624  \n",
       "16   -0.000973340396306  0.000626669072669 -0.006348379372395  \n",
       "17    0.002157606684578 -0.005831948271178  0.003614721803380  \n",
       "18   -0.000788823048615 -0.001392429600518 -0.000962167294556  \n",
       "19   -0.000662426676947 -0.006539411246654 -0.008445953970378  \n",
       "20    0.004511925556224  0.002005544004962  0.006858958959941  \n",
       "21    0.005912369680306 -0.010067339800596 -0.005140018528662  \n",
       "22   -0.007836614985571 -0.000581680780461 -0.000270286765597  \n",
       "23   -0.000962266597940 -0.006602515127879 -0.002341324341645  \n",
       "24    0.004893036823264 -0.007709440829266  0.004496736322972  \n",
       "25    0.000964390020989  0.003021063732837 -0.005500501538375  \n",
       "26   -0.004612173830570  0.002402460376744 -0.000444261367160  \n",
       "27   -0.001867693606699 -0.005673877025018 -0.001467535633284  \n",
       "28   -0.000794423917604 -0.004833474215376 -0.004343024666140  \n",
       "29    0.000229216714982  0.000160966287027  0.000668678611369  \n",
       "...                 ...                ...                ...  \n",
       "2594 -0.000566134140073  0.001331380869707 -0.004659076825260  \n",
       "2595 -0.001774382257578 -0.002956844225233 -0.004486177829350  \n",
       "2596  0.003644783453183 -0.000927922776513  0.000441036003150  \n",
       "2597 -0.000788364335670  0.000030133890091 -0.001125776637932  \n",
       "2598 -0.001532616184248  0.000201683933648 -0.001897665951475  \n",
       "2599 -0.000012331281218 -0.004092629659556  0.000615593234225  \n",
       "2600 -0.004091973065319 -0.002345284332026 -0.008450535982807  \n",
       "2601 -0.008026171697336  0.002266640964319  0.000908248712647  \n",
       "2602  0.005912466328546 -0.006852781116065 -0.003611498925687  \n",
       "2603  0.000108109804664  0.009550930448562  0.005751785174456  \n",
       "2604  0.042780189676718  0.010054424140972  0.257398583728647  \n",
       "2605  0.001886950678671 -0.001312639991405  0.000326659050056  \n",
       "2606 -0.001682449077631  0.000901213095176 -0.003230396097427  \n",
       "2607 -0.075795548090447  0.080336929356450  0.025446468329530  \n",
       "2608 -0.001850090445070  0.000721918893222 -0.005706800643407  \n",
       "2609 -0.004840465866457  0.001700167673784  0.000603156955423  \n",
       "2610 -0.001111518301015 -0.000726912064616 -0.004763720140836  \n",
       "2611  0.002330443306796 -0.009027715679747 -0.001061857470221  \n",
       "2612 -0.000069439046080 -0.001768188956335 -0.001969455277900  \n",
       "2613 -0.002370296534950  0.000229492119188 -0.000309740969908  \n",
       "2614  0.001395577751254 -0.000667595526889 -0.002631651298227  \n",
       "2615 -0.000202496680744 -0.000188762197282  0.003719234605140  \n",
       "2616  0.002241845940306 -0.003116441873521 -0.001187348694580  \n",
       "2617 -0.000025451476053 -0.001961132201097 -0.000258610367123  \n",
       "2618  0.000049911935883  0.000430754743771 -0.002841478078975  \n",
       "2619 -0.002435909160470  0.004107732830892 -0.003089734697278  \n",
       "2620 -0.004830769569260 -0.000754200257222  0.009811823881547  \n",
       "2621 -0.002918300959031  0.009423516304395 -0.000669191424538  \n",
       "2622  0.018177459435638 -0.050877877316674 -0.027625801660614  \n",
       "2623 -0.001662080109133 -0.004450024784143  0.000149091725053  \n",
       "\n",
       "[2624 rows x 200 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_outliers(model, X, y, sigma=3):\n",
    "    # 查找离群值\n",
    "    # 标准偏差预先已知的情况\n",
    "    # predict y values using model\n",
    "    try:\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "    # if predicting fails, try fitting the model first\n",
    "    except:\n",
    "        model.fit(X, y)\n",
    "        y_pred = pd.Series(model.predict(X), index=y.index)\n",
    "        \n",
    "    # calculate residuals between the model prediction and true y values\n",
    "    resid = y - y_pred\n",
    "    mean_resid = resid.mean()\n",
    "    std_resid = resid.std()\n",
    "    \n",
    "    # calculate z statistic, define outliers to be where |z|>sigma\n",
    "    z = (resid - mean_resid) / std_resid\n",
    "    outliers = z[abs(z) > sigma].index\n",
    "    \n",
    "    # print and plot the results\n",
    "    print('R2 =', model.score(X, y))\n",
    "    print('mae =', mean_absolute_error(y, y_pred))\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "    print('mean of residuals:', mean_resid)\n",
    "    print('std of residuals:', std_resid)\n",
    "    print('---------------------------------------')\n",
    "    \n",
    "    print(len(outliers), 'outliers: ')\n",
    "    print(outliers.tolist())\n",
    "    \n",
    "    plt.figure(figsize=(15, 5))\n",
    "    ax_131 = plt.subplot(1,3,1)\n",
    "    plt.plot(y, y_pred, '.')\n",
    "    plt.plot(y.loc[outliers], y_pred.loc[outliers], 'ro')\n",
    "    # loc[1]是DataFrame的行索引, loc[1,2]是行列索引\n",
    "    # o表示小圆圈，ro表示红色小圆圈\n",
    "    plt.legend(['Accepted', 'Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y_pred')\n",
    "    \n",
    "    ax_132 = plt.subplot(1,3,2)\n",
    "    plt.plot(y, y - y_pred, '.')\n",
    "    plt.plot(y.loc[outliers], y.loc[outliers] - y_pred.loc[outliers], 'ro')\n",
    "    plt.legend(['Accepted', 'Outlier'])\n",
    "    plt.xlabel('y')\n",
    "    plt.ylabel('y - y_pred')\n",
    "    \n",
    "    ax_133 = plt.subplot(1,3,3)\n",
    "    z.plot.hist(bins=50, ax=ax_133)\n",
    "    z.loc[outliers].plot.hist(color='r', bins=50, ax=ax_133)\n",
    "    plt.legend(['Accepted', 'Outlier'])\n",
    "    plt.xlabel('z')\n",
    "    \n",
    "    plt.show()\n",
    "    \n",
    "    return outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "R2 = 0.4909061223656772\n",
      "mae = 2.051716365813128\n",
      "---------------------------------------\n",
      "mean of residuals: -2.7100557263794046e-16\n",
      "std of residuals: 2.620891170801408\n",
      "---------------------------------------\n",
      "48 outliers: \n",
      "[33, 34, 35, 36, 330, 331, 332, 695, 696, 921, 923, 924, 1247, 1248, 1249, 1454, 1455, 1456, 1636, 1637, 2048, 2050, 2051, 2252, 2253, 2254, 2499, 2500, 2501, 2791, 2792, 2793, 2794, 3077, 3302, 3303, 3304, 3522, 3523, 3524, 3726, 3900, 3901, 3902, 4142, 4143, 4144, 4145]\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1080x360 with 3 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "outliers = find_outliers(Ridge(), X, y_train.time_to_failure)\n",
    "\n",
    "X_outliers = X.loc[outliers]\n",
    "y_outliers = y_train.loc[outliers]\n",
    "X_t = X.drop(outliers)\n",
    "y_t = y_train.drop(outliers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EVALS = 1000\n",
    "N_FOLDS = 5\n",
    "XGB_MAX_LEAVES = 2**12 \n",
    "XGB_MAX_DEPTH = 50\n",
    "EVAL_METRIC_XGB_REG = 'mae'\n",
    "LGBM_MAX_LEAVES = 2**11\n",
    "LGBM_MAX_DEPTH = 35\n",
    "EVAL_METRIC_LGBM_REG = 'mae'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def quick_hyperopt(data, labels, package='lgbm', num_evals=NUM_EVALS, diagnostic=False):\n",
    "    \n",
    "    #==========\n",
    "    #LightGBM\n",
    "    #==========\n",
    "    \n",
    "    if package=='lgbm':\n",
    "        \n",
    "        print('Running {} rounds of LightGBM parameter optimisation:'.format(num_evals))\n",
    "        #clear space\n",
    "        gc.collect()\n",
    "        \n",
    "        integer_params = ['max_depth',\n",
    "                          'num_leaves',\n",
    "                          'max_bin',\n",
    "                          'min_data_in_leaf',\n",
    "                          'min_data_in_bin']\n",
    "        \n",
    "        def objective(space_params):\n",
    "            \n",
    "            #cast integer params from float to int\n",
    "            for param in integer_params:\n",
    "                space_params[param] = int(space_params[param])\n",
    "            \n",
    "            #extract nested conditional parameters\n",
    "            if space_params['boosting']['boosting'] == 'goss':\n",
    "                top_rate = space_params['boosting'].get('top_rate')\n",
    "                other_rate = space_params['boosting'].get('other_rate')\n",
    "                #0 <= top_rate + other_rate <= 1\n",
    "                top_rate = max(top_rate, 0)\n",
    "                top_rate = min(top_rate, 0.5)\n",
    "                other_rate = max(other_rate, 0)\n",
    "                other_rate = min(other_rate, 0.5)\n",
    "                space_params['top_rate'] = top_rate\n",
    "                space_params['other_rate'] = other_rate\n",
    "            \n",
    "            subsample = space_params['boosting'].get('subsample', 1.0)\n",
    "            space_params['boosting'] = space_params['boosting']['boosting']\n",
    "            space_params['subsample'] = subsample\n",
    "            \n",
    "            #for classification, set stratified=True and metrics=EVAL_METRIC_LGBM_CLASS\n",
    "            cv_results = lgb.cv(space_params, train, num_boost_round=100, nfold = N_FOLDS, stratified=False,\n",
    "                                early_stopping_rounds=100, metrics=EVAL_METRIC_LGBM_REG, seed=42)\n",
    "            \n",
    "            best_loss = cv_results['l1-mean'][-1] #'l2-mean' for rmse\n",
    "            #for classification, comment out the line above and uncomment the line below:\n",
    "            #best_loss = 1 - cv_results['auc-mean'][-1]\n",
    "            #if necessary, replace 'auc-mean' with '[your-preferred-metric]-mean'\n",
    "            return{'loss':best_loss, 'status': STATUS_OK }\n",
    "        \n",
    "        train = lgb.Dataset(data, labels)\n",
    "                \n",
    "        #integer and string parameters, used with hp.choice()\n",
    "        boosting_list = [{'boosting': 'gbdt',\n",
    "                          'subsample': hp.uniform('subsample', 0.5, 1)},\n",
    "                         {'boosting': 'goss',\n",
    "                          'subsample': 1.0,\n",
    "                         'top_rate': hp.uniform('top_rate', 0, 0.5),\n",
    "                         'other_rate': hp.uniform('other_rate', 0, 0.5)}] #if including 'dart', make sure to set 'n_estimators'\n",
    "        metric_list = ['MAE'] \n",
    "        #for classification comment out the line above and uncomment the line below\n",
    "        #metric_list = ['auc'] #modify as required for other classification metrics\n",
    "        objective_list_reg = ['huber',  'gamma', 'tweedie', 'fair']\n",
    "        objective_list_class = ['binary', 'cross_entropy']\n",
    "        #for classification set objective_list = objective_list_class\n",
    "        objective_list = objective_list_reg\n",
    "\n",
    "        space ={'boosting' : hp.choice('boosting', boosting_list),\n",
    "                'num_leaves' : hp.quniform('num_leaves', 2, LGBM_MAX_LEAVES, 1),\n",
    "                'max_depth': hp.quniform('max_depth', 2, LGBM_MAX_DEPTH, 1),\n",
    "                'max_bin': hp.quniform('max_bin', 32, 255, 1),\n",
    "                'min_data_in_leaf': hp.quniform('min_data_in_leaf', 1, 256, 1),\n",
    "                'min_data_in_bin': hp.quniform('min_data_in_bin', 1, 256, 1),\n",
    "                'min_gain_to_split' : hp.quniform('min_gain_to_split', 0.1, 5, 0.01),\n",
    "                'lambda_l1' : hp.uniform('lambda_l1', 0, 5),\n",
    "                'lambda_l2' : hp.uniform('lambda_l2', 0, 5),\n",
    "                'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'metric' : hp.choice('metric', metric_list),\n",
    "                'objective' : hp.choice('objective', objective_list),\n",
    "                'feature_fraction' : hp.quniform('feature_fraction', 0.5, 1, 0.01),\n",
    "                'bagging_fraction' : hp.quniform('bagging_fraction', 0.5, 1, 0.01)\n",
    "            }\n",
    "        \n",
    "        #optional: activate GPU for LightGBM\n",
    "        #follow compilation steps here:\n",
    "        #https://www.kaggle.com/vinhnguyen/gpu-acceleration-for-lightgbm/\n",
    "        #then uncomment lines below:\n",
    "        #space['device'] = 'gpu'\n",
    "        #space['gpu_platform_id'] = 0,\n",
    "        #space['gpu_device_id'] =  0\n",
    "\n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=num_evals, \n",
    "                    trials=trials)\n",
    "                \n",
    "        #fmin() will return the index of values chosen from the lists/arrays in 'space'\n",
    "        #to obtain actual values, index values are used to subset the original lists/arrays\n",
    "        best['boosting'] = boosting_list[best['boosting']]['boosting']#nested dict, index twice\n",
    "        best['metric'] = metric_list[best['metric']]\n",
    "        best['objective'] = objective_list[best['objective']]\n",
    "                \n",
    "        #cast floats of integer params to int\n",
    "        for param in integer_params:\n",
    "            best[param] = int(best[param])\n",
    "        \n",
    "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "        if diagnostic:\n",
    "            return(best, trials)\n",
    "        else:\n",
    "            return(best)\n",
    "    \n",
    "    #==========\n",
    "    #XGBoost\n",
    "    #==========\n",
    "    \n",
    "    if package=='xgb':\n",
    "        \n",
    "        print('Running {} rounds of XGBoost parameter optimisation:'.format(num_evals))\n",
    "        #clear space\n",
    "        gc.collect()\n",
    "        \n",
    "        integer_params = ['max_depth']\n",
    "        \n",
    "        def objective(space_params):\n",
    "            \n",
    "            for param in integer_params:\n",
    "                space_params[param] = int(space_params[param])\n",
    "                \n",
    "            #extract multiple nested tree_method conditional parameters\n",
    "            #libera te tutemet ex inferis\n",
    "            if space_params['tree_method']['tree_method'] == 'hist':\n",
    "                max_bin = space_params['tree_method'].get('max_bin')\n",
    "                space_params['max_bin'] = int(max_bin)\n",
    "                if space_params['tree_method']['grow_policy']['grow_policy']['grow_policy'] == 'depthwise':\n",
    "                    grow_policy = space_params['tree_method'].get('grow_policy').get('grow_policy').get('grow_policy')\n",
    "                    space_params['grow_policy'] = grow_policy\n",
    "                    space_params['tree_method'] = 'hist'\n",
    "                else:\n",
    "                    max_leaves = space_params['tree_method']['grow_policy']['grow_policy'].get('max_leaves')\n",
    "                    space_params['grow_policy'] = 'lossguide'\n",
    "                    space_params['max_leaves'] = int(max_leaves)\n",
    "                    space_params['tree_method'] = 'hist'\n",
    "            else:\n",
    "                space_params['tree_method'] = space_params['tree_method'].get('tree_method')\n",
    "                \n",
    "            #for classification replace EVAL_METRIC_XGB_REG with EVAL_METRIC_XGB_CLASS\n",
    "            cv_results = xgb.cv(space_params, train, num_boost_round=100, nfold=N_FOLDS, metrics=[EVAL_METRIC_XGB_REG],\n",
    "                             early_stopping_rounds=100, stratified=False, seed=42)\n",
    "            \n",
    "            best_loss = cv_results['test-mae-mean'].iloc[-1] #or 'test-rmse-mean' if using RMSE\n",
    "            #for classification, comment out the line above and uncomment the line below:\n",
    "            #best_loss = 1 - cv_results['test-auc-mean'].iloc[-1]\n",
    "            #if necessary, replace 'test-auc-mean' with 'test-[your-preferred-metric]-mean'\n",
    "            return{'loss':best_loss, 'status': STATUS_OK }\n",
    "        \n",
    "        train = xgb.DMatrix(data, labels)\n",
    "        \n",
    "        #integer and string parameters, used with hp.choice()\n",
    "        boosting_list = ['gbtree', 'gblinear'] #if including 'dart', make sure to set 'n_estimators'\n",
    "        metric_list = ['mae'] \n",
    "        #for classification comment out the line above and uncomment the line below\n",
    "        #metric_list = ['auc']\n",
    "        #modify as required for other classification metrics classification\n",
    "        \n",
    "        tree_method = [{'tree_method' : 'exact'},\n",
    "               {'tree_method' : 'approx'},\n",
    "               {'tree_method' : 'hist',\n",
    "                'max_bin': hp.quniform('max_bin', 2**3, 2**7, 1),\n",
    "                'grow_policy' : {'grow_policy': {'grow_policy':'depthwise'},\n",
    "                                'grow_policy' : {'grow_policy':'lossguide',\n",
    "                                                  'max_leaves': hp.quniform('max_leaves', 32, XGB_MAX_LEAVES, 1)}}}]\n",
    "        \n",
    "        #if using GPU, replace 'exact' with 'gpu_exact' and 'hist' with\n",
    "        #'gpu_hist' in the nested dictionary above\n",
    "        \n",
    "        objective_list_reg = ['reg:linear']\n",
    "        objective_list_class = ['reg:logistic', 'binary:logistic']\n",
    "        #for classification change line below to 'objective_list = objective_list_class'\n",
    "        objective_list = objective_list_reg\n",
    "        \n",
    "        space ={'boosting' : hp.choice('boosting', boosting_list),\n",
    "                'tree_method' : hp.choice('tree_method', tree_method),\n",
    "                'max_depth': hp.quniform('max_depth', 2, XGB_MAX_DEPTH, 1),\n",
    "                'reg_alpha' : hp.uniform('reg_alpha', 0, 5),\n",
    "                'reg_lambda' : hp.uniform('reg_lambda', 0, 5),\n",
    "                'min_child_weight' : hp.uniform('min_child_weight', 0, 5),\n",
    "                'gamma' : hp.uniform('gamma', 0, 5),\n",
    "                'learning_rate' : hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "                'eval_metric' : hp.choice('eval_metric', metric_list),\n",
    "                'objective' : hp.choice('objective', objective_list),\n",
    "                'colsample_bytree' : hp.quniform('colsample_bytree', 0.1, 1, 0.01),\n",
    "                'colsample_bynode' : hp.quniform('colsample_bynode', 0.1, 1, 0.01),\n",
    "                'colsample_bylevel' : hp.quniform('colsample_bylevel', 0.1, 1, 0.01),\n",
    "                'subsample' : hp.quniform('subsample', 0.5, 1, 0.05),\n",
    "                'nthread' : 3\n",
    "            }\n",
    "        \n",
    "        trials = Trials()\n",
    "        best = fmin(fn=objective,\n",
    "                    space=space,\n",
    "                    algo=tpe.suggest,\n",
    "                    max_evals=num_evals, \n",
    "                    trials=trials)\n",
    "        \n",
    "        best['tree_method'] = tree_method[best['tree_method']]['tree_method']\n",
    "        best['boosting'] = boosting_list[best['boosting']]\n",
    "        best['eval_metric'] = metric_list[best['eval_metric']]\n",
    "        best['objective'] = objective_list[best['objective']]\n",
    "        \n",
    "        #cast floats of integer params to int\n",
    "        for param in integer_params:\n",
    "            best[param] = int(best[param])\n",
    "        if 'max_leaves' in best:\n",
    "            best['max_leaves'] = int(best['max_leaves'])\n",
    "        if 'max_bin' in best:\n",
    "            best['max_bin'] = int(best['max_bin'])\n",
    "        \n",
    "        print('{' + '\\n'.join('{}: {}'.format(k, v) for k, v in best.items()) + '}')\n",
    "        \n",
    "        if diagnostic:\n",
    "            return(best, trials)\n",
    "        else:\n",
    "            return(best)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 rounds of LightGBM parameter optimisation:\n",
      "100%|██████████| 500/500 [21:03<00:00,  2.61s/it, best loss: 1.971265063144043]\n",
      "{bagging_fraction: 0.75\n",
      "boosting: goss\n",
      "feature_fraction: 0.99\n",
      "lambda_l1: 2.8525910168234634\n",
      "lambda_l2: 2.260249028234329\n",
      "learning_rate: 0.18372282527182085\n",
      "max_bin: 193\n",
      "max_depth: 17\n",
      "metric: MAE\n",
      "min_data_in_bin: 41\n",
      "min_data_in_leaf: 40\n",
      "min_gain_to_split: 3.42\n",
      "num_leaves: 1992\n",
      "objective: huber\n",
      "other_rate: 0.4399969362781391\n",
      "top_rate: 0.29229534308486604}\n"
     ]
    }
   ],
   "source": [
    "lgb_params = quick_hyperopt(X_t, y_t, package='lgbm', num_evals=500)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bagging_fraction': 0.75,\n",
       " 'boosting': 'goss',\n",
       " 'feature_fraction': 0.99,\n",
       " 'lambda_l1': 2.8525910168234634,\n",
       " 'lambda_l2': 2.260249028234329,\n",
       " 'learning_rate': 0.18372282527182085,\n",
       " 'max_bin': 193,\n",
       " 'max_depth': 17,\n",
       " 'metric': 'MAE',\n",
       " 'min_data_in_bin': 41,\n",
       " 'min_data_in_leaf': 40,\n",
       " 'min_gain_to_split': 3.42,\n",
       " 'num_leaves': 1992,\n",
       " 'objective': 'huber',\n",
       " 'other_rate': 0.4399969362781391,\n",
       " 'top_rate': 0.29229534308486604}"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "lgb_params = {'bagging_fraction': 0.75,\n",
    "             'boosting': 'goss',\n",
    "             'feature_fraction': 0.99,\n",
    "             'lambda_l1': 2.8525910168234634,\n",
    "             'lambda_l2': 2.260249028234329,\n",
    "             'learning_rate': 0.18372282527182085,\n",
    "             'max_bin': 193,\n",
    "             'max_depth': 17,\n",
    "             'metric': 'MAE',\n",
    "             'min_data_in_bin': 41,\n",
    "             'min_data_in_leaf': 40,\n",
    "             'min_gain_to_split': 3.42,\n",
    "             'num_leaves': 1992,\n",
    "             'objective': 'huber',\n",
    "             'other_rate': 0.4399969362781391,\n",
    "             'top_rate': 0.29229534308486604}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[86]\ttraining's l1: 1.60759\tvalid_1's l1: 2.01436\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[48]\ttraining's l1: 1.741\tvalid_1's l1: 2.00593\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[64]\ttraining's l1: 1.66502\tvalid_1's l1: 1.90236\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[76]\ttraining's l1: 1.60454\tvalid_1's l1: 1.99678\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[114]\ttraining's l1: 1.57154\tvalid_1's l1: 2.05359\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[141]\ttraining's l1: 1.58698\tvalid_1's l1: 1.89048\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[103]\ttraining's l1: 1.5906\tvalid_1's l1: 1.96064\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[131]\ttraining's l1: 1.58405\tvalid_1's l1: 1.97159\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[111]\ttraining's l1: 1.58488\tvalid_1's l1: 1.96668\n",
      "Training until validation scores don't improve for 200 rounds.\n",
      "Early stopping, best iteration is:\n",
      "[156]\ttraining's l1: 1.58856\tvalid_1's l1: 1.80646\n",
      "CV score: 1.9568880113768543\n"
     ]
    }
   ],
   "source": [
    "MAE = 0\n",
    "lgb_preds = np.zeros(len(X_test))\n",
    "oof_lgb = np.zeros(len(X_t))\n",
    "feature_importance_df = pd.DataFrame()\n",
    "\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for fold, (train_idx, valid_idx) in enumerate(folds.split(y_t)):\n",
    "#     print(train_idx)\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    model = lgb.LGBMRegressor(**lgb_params, n_estimators=20000, n_jobs=3)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=10000, early_stopping_rounds=200)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    oof_lgb[valid_idx] = val_preds\n",
    "    MAE += mean_absolute_error(y_valid, val_preds) / n_fold\n",
    "    lgb_preds += model.predict(X_test, num_iteration=model.best_iteration_) / n_fold\n",
    "    fold_importance = pd.DataFrame()\n",
    "    fold_importance[\"feature\"] = X_t.columns\n",
    "    fold_importance[\"importance\"] = model.feature_importances_\n",
    "    fold_importance[\"fold\"] = fold + 1\n",
    "    feature_importance_df = pd.concat([feature_importance_df, fold_importance], axis=0)\n",
    "    \n",
    "print('CV score: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature</th>\n",
       "      <th>importance</th>\n",
       "      <th>fold</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>113</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>81</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>121</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>33</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>5</td>\n",
       "      <td>8</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>8</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>9</td>\n",
       "      <td>40</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>10</td>\n",
       "      <td>28</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>11</td>\n",
       "      <td>20</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>14</td>\n",
       "      <td>13</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>15</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>16</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>17</td>\n",
       "      <td>26</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>18</td>\n",
       "      <td>12</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>19</td>\n",
       "      <td>19</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>20</td>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>21</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>22</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>23</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>24</td>\n",
       "      <td>15</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>25</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>26</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>27</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>28</td>\n",
       "      <td>7</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>29</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>170</th>\n",
       "      <td>170</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>171</th>\n",
       "      <td>171</td>\n",
       "      <td>5</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>172</th>\n",
       "      <td>172</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>173</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>174</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>175</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>176</td>\n",
       "      <td>3</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>177</td>\n",
       "      <td>23</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>178</th>\n",
       "      <td>178</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>179</th>\n",
       "      <td>179</td>\n",
       "      <td>8</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>180</th>\n",
       "      <td>180</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>181</th>\n",
       "      <td>181</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>182</th>\n",
       "      <td>182</td>\n",
       "      <td>9</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>183</th>\n",
       "      <td>183</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>184</th>\n",
       "      <td>184</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>185</th>\n",
       "      <td>185</td>\n",
       "      <td>21</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>186</th>\n",
       "      <td>186</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>187</th>\n",
       "      <td>187</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>188</th>\n",
       "      <td>188</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>189</th>\n",
       "      <td>189</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>190</th>\n",
       "      <td>190</td>\n",
       "      <td>15</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>191</th>\n",
       "      <td>191</td>\n",
       "      <td>4</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>192</th>\n",
       "      <td>192</td>\n",
       "      <td>2</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>193</th>\n",
       "      <td>193</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>194</th>\n",
       "      <td>194</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>195</th>\n",
       "      <td>195</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>196</th>\n",
       "      <td>196</td>\n",
       "      <td>16</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>197</th>\n",
       "      <td>197</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>198</th>\n",
       "      <td>198</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>199</th>\n",
       "      <td>199</td>\n",
       "      <td>0</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>2000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     feature  importance  fold\n",
       "0          0         113     1\n",
       "1          1          81     1\n",
       "2          2         121     1\n",
       "3          3          33     1\n",
       "4          4           1     1\n",
       "5          5           8     1\n",
       "6          6           0     1\n",
       "7          7           0     1\n",
       "8          8           4     1\n",
       "9          9          40     1\n",
       "10        10          28     1\n",
       "11        11          20     1\n",
       "12        12           0     1\n",
       "13        13           0     1\n",
       "14        14          13     1\n",
       "15        15           2     1\n",
       "16        16           0     1\n",
       "17        17          26     1\n",
       "18        18          12     1\n",
       "19        19          19     1\n",
       "20        20          14     1\n",
       "21        21           6     1\n",
       "22        22           3     1\n",
       "23        23           0     1\n",
       "24        24          15     1\n",
       "25        25           0     1\n",
       "26        26           4     1\n",
       "27        27           0     1\n",
       "28        28           7     1\n",
       "29        29           5     1\n",
       "..       ...         ...   ...\n",
       "170      170          15    10\n",
       "171      171           5    10\n",
       "172      172           0    10\n",
       "173      173           2    10\n",
       "174      174           0    10\n",
       "175      175           0    10\n",
       "176      176           3    10\n",
       "177      177          23    10\n",
       "178      178           2    10\n",
       "179      179           8    10\n",
       "180      180           1    10\n",
       "181      181           0    10\n",
       "182      182           9    10\n",
       "183      183          15    10\n",
       "184      184           1    10\n",
       "185      185          21    10\n",
       "186      186           0    10\n",
       "187      187           0    10\n",
       "188      188           0    10\n",
       "189      189           4    10\n",
       "190      190          15    10\n",
       "191      191           4    10\n",
       "192      192           2    10\n",
       "193      193           0    10\n",
       "194      194           0    10\n",
       "195      195           0    10\n",
       "196      196          16    10\n",
       "197      197           1    10\n",
       "198      198           1    10\n",
       "199      199           0    10\n",
       "\n",
       "[2000 rows x 3 columns]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_importance_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x5904 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "feature_importance_df[\"importance\"] /= n_fold\n",
    "\n",
    "# cols = feature_importance_df[[\"feature\", \"importance\"]].groupby(\"feature\").mean().sort_values(by=\"importance\", ascending=False).index[:50]\n",
    "# best_features = feature_importance_df.loc[feature_importance_df.feature.isin(cols)]\n",
    "\n",
    "plt.figure(figsize=(8, 82))\n",
    "sns.barplot(x=\"importance\", y=\"feature\", data=feature_importance_df.sort_values(by=\"importance\", ascending=False))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running 500 rounds of XGBoost parameter optimisation:\n",
      "100%|███████| 500/500 [3:58:53<00:00, 32.65s/it, best loss: 1.9942381999999998]\n",
      "{boosting: gblinear\n",
      "colsample_bylevel: 0.68\n",
      "colsample_bynode: 0.59\n",
      "colsample_bytree: 0.93\n",
      "eval_metric: mae\n",
      "gamma: 2.131617873803861\n",
      "learning_rate: 0.02566547625144134\n",
      "max_depth: 5\n",
      "min_child_weight: 4.574557859567123\n",
      "objective: reg:linear\n",
      "reg_alpha: 1.5426477198205795\n",
      "reg_lambda: 0.43942350713364753\n",
      "subsample: 0.75\n",
      "tree_method: approx}\n"
     ]
    }
   ],
   "source": [
    "xgb_params = quick_hyperopt(X_t, y_t, package='xgb', num_evals=500, diagnostic=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'boosting': 'gblinear',\n",
       " 'colsample_bylevel': 0.68,\n",
       " 'colsample_bynode': 0.59,\n",
       " 'colsample_bytree': 0.93,\n",
       " 'eval_metric': 'mae',\n",
       " 'gamma': 2.131617873803861,\n",
       " 'learning_rate': 0.02566547625144134,\n",
       " 'max_depth': 5,\n",
       " 'min_child_weight': 4.574557859567123,\n",
       " 'objective': 'reg:linear',\n",
       " 'reg_alpha': 1.5426477198205795,\n",
       " 'reg_lambda': 0.43942350713364753,\n",
       " 'subsample': 0.75,\n",
       " 'tree_method': 'approx'}"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_params = {'boosting': 'gblinear',\n",
    "             'colsample_bylevel': 0.68,\n",
    "             'colsample_bynode': 0.59,\n",
    "             'colsample_bytree': 0.93,\n",
    "             'eval_metric': 'mae',\n",
    "             'gamma': 2.131617873803861,\n",
    "             'learning_rate': 0.02566547625144134,\n",
    "             'max_depth': 5,\n",
    "             'min_child_weight': 4.574557859567123,\n",
    "             'objective': 'reg:linear',\n",
    "             'reg_alpha': 1.5426477198205795,\n",
    "             'reg_lambda': 0.43942350713364753,\n",
    "             'subsample': 0.75,\n",
    "             'tree_method': 'approx'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-mae:5.12214\tvalidation_1-mae:5.24421\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[179]\tvalidation_0-mae:1.39699\tvalidation_1-mae:2.00923\n",
      "\n",
      "[0]\tvalidation_0-mae:5.15828\tvalidation_1-mae:4.90576\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[77]\tvalidation_0-mae:1.73039\tvalidation_1-mae:2.02823\n",
      "\n",
      "[0]\tvalidation_0-mae:5.15411\tvalidation_1-mae:4.94336\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[85]\tvalidation_0-mae:1.68974\tvalidation_1-mae:1.91551\n",
      "\n",
      "[0]\tvalidation_0-mae:5.11914\tvalidation_1-mae:5.25781\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[89]\tvalidation_0-mae:1.66557\tvalidation_1-mae:2.01172\n",
      "\n",
      "[0]\tvalidation_0-mae:5.10454\tvalidation_1-mae:5.39465\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[281]\tvalidation_0-mae:1.14869\tvalidation_1-mae:2.02875\n",
      "\n",
      "[0]\tvalidation_0-mae:5.11374\tvalidation_1-mae:5.31245\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[125]\tvalidation_0-mae:1.56049\tvalidation_1-mae:1.94675\n",
      "\n",
      "[0]\tvalidation_0-mae:5.11165\tvalidation_1-mae:5.33411\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[442]\tvalidation_0-mae:0.85575\tvalidation_1-mae:1.98357\n",
      "\n",
      "[0]\tvalidation_0-mae:5.13574\tvalidation_1-mae:5.10865\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[264]\tvalidation_0-mae:1.18757\tvalidation_1-mae:2.0202\n",
      "\n",
      "[0]\tvalidation_0-mae:5.1519\tvalidation_1-mae:4.95722\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[69]\tvalidation_0-mae:1.79085\tvalidation_1-mae:1.98199\n",
      "\n",
      "[0]\tvalidation_0-mae:5.1607\tvalidation_1-mae:4.88567\n",
      "Multiple eval metrics have been passed: 'validation_1-mae' will be used for early stopping.\n",
      "\n",
      "Will train until validation_1-mae hasn't improved in 200 rounds.\n",
      "Stopping. Best iteration:\n",
      "[106]\tvalidation_0-mae:1.62098\tvalidation_1-mae:1.89861\n",
      "\n",
      "CV score: 1.9824544615967983\n"
     ]
    }
   ],
   "source": [
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "\n",
    "MAE = 0\n",
    "xgb_preds = np.zeros(len(X_test))\n",
    "oof_xgb = np.zeros(len(X_t))\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "#     print(train_idx)\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    model = xgb.XGBRegressor(**xgb_params, n_estimators=20000, n_jobs=3)\n",
    "    model.fit(X_train, y_train, eval_set=[(X_train, y_train), (X_valid, y_valid)],\n",
    "              verbose=10000, early_stopping_rounds=200)\n",
    "    val_preds = model.predict(X_valid)\n",
    "    oof_xgb[valid_idx] = val_preds\n",
    "    MAE += mean_absolute_error(y_valid, val_preds) / n_fold\n",
    "    xgb_preds += model.predict(X_test) / n_fold\n",
    "    \n",
    "print('CV score: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2624,)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_preds.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# GradientBoostingRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_gbm(params):\n",
    "    \n",
    "    MAE = 0\n",
    "    n_fold = 5\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "    for train_idx, valid_idx in folds.split(y_t):\n",
    "    #     print(train_idx)\n",
    "        X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "        y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "        model = GradientBoostingRegressor(**params, criterion='mse')\n",
    "        model.fit(X_train, y_train.values)\n",
    "        val_preds = model.predict(X_valid)\n",
    "        MAE += mean_absolute_error(y_valid, val_preds) / n_fold\n",
    "\n",
    "    return {'loss': MAE, 'status': STATUS_OK}\n",
    "\n",
    "space = {'loss': hp.choice('loss', ['ls', 'lad', 'huber', 'quantile']),\n",
    "         'learning_rate': hp.loguniform('learning_rate', np.log(0.005), np.log(0.2)),\n",
    "         'n_estimators': hp.choice('n_estimators', range(100, 5000)),\n",
    "         'max_depth': hp.choice('max_depth', range(3, 30)),\n",
    "         'min_samples_leaf': hp.uniform('min_samples_leaf', 0, 0.5),\n",
    "         'min_samples_split': hp.uniform('min_samples_split', 0, 1),\n",
    "         'max_features': hp.choice('max_features', range(1, 200)),\n",
    "         'alpha': hp.uniform('alpha', 0, 1)}\n",
    "\n",
    "gbm_params = fmin(fn=objective_gbm,\n",
    "                  space=space,\n",
    "                  algo=tpe.suggest,\n",
    "                  max_evals=1000)\n",
    "\n",
    "gbm_params['loss'] = ['ls', 'lad', 'huber', 'quantile'][gbm_params['loss']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbm_params = {'learning_rate': 0.01,\n",
    "              'loss': 'ls',\n",
    "              'max_depth': 20,\n",
    "              'n_estimators': 500,\n",
    "              'subsample': 0.85,\n",
    "              'n_iter_no_change': 200,\n",
    "              'validation_fraction': 0.1}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          13.0410           0.1535           15.99m\n",
      "         2          12.6233           0.1587           15.69m\n",
      "         3          12.5533           0.1283           15.60m\n",
      "         4          12.3553           0.1358           15.84m\n",
      "         5          11.8295           0.1375           15.82m\n",
      "         6          11.7957           0.1370           15.83m\n",
      "         7          11.6441           0.1198           15.74m\n",
      "         8          11.5365           0.1266           15.63m\n",
      "         9          11.2204           0.1196           15.55m\n",
      "        10          11.0034           0.1117           15.54m\n",
      "        20           9.1599           0.0957           15.18m\n",
      "        30           7.4436           0.0904           14.88m\n",
      "        40           6.3030           0.0681           14.58m\n",
      "        50           5.2279           0.0532           14.18m\n",
      "        60           4.3015           0.0477           13.85m\n",
      "        70           3.6011           0.0347           13.53m\n",
      "        80           2.9804           0.0281           13.23m\n",
      "        90           2.4681           0.0233           12.93m\n",
      "       100           2.0916           0.0181           12.59m\n",
      "       200           0.3376           0.0026            9.46m\n",
      "       300           0.0565           0.0003            6.27m\n",
      "       400           0.0095           0.0000            3.12m\n",
      "       500           0.0017           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          13.1050           0.1446           15.65m\n",
      "         2          12.9521           0.1437           15.50m\n",
      "         3          12.6945           0.1446           15.52m\n",
      "         4          12.4677           0.1363           15.34m\n",
      "         5          12.3900           0.1236           15.30m\n",
      "         6          12.0081           0.1252           15.29m\n",
      "         7          11.7783           0.1385           15.30m\n",
      "         8          11.6878           0.1244           15.28m\n",
      "         9          11.3346           0.1185           15.30m\n",
      "        10          11.1082           0.1380           15.20m\n",
      "        20           9.3575           0.1006           14.93m\n",
      "        30           7.7918           0.0844           14.69m\n",
      "        40           6.4643           0.0757           14.37m\n",
      "        50           5.3070           0.0499           14.03m\n",
      "        60           4.3828           0.0460           13.81m\n",
      "        70           3.6350           0.0353           13.56m\n",
      "        80           3.0488           0.0282           13.26m\n",
      "        90           2.5581           0.0243           13.00m\n",
      "       100           2.1580           0.0171           12.69m\n",
      "       200           0.3473           0.0023            9.52m\n",
      "       300           0.0574           0.0003            6.33m\n",
      "       400           0.0099           0.0000            3.16m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          12.9290           0.1496           15.27m\n",
      "         2          12.9529           0.1255           15.35m\n",
      "         3          12.6981           0.1270           15.37m\n",
      "         4          12.5020           0.1400           15.56m\n",
      "         5          12.2063           0.1244           15.53m\n",
      "         6          11.9158           0.1251           15.39m\n",
      "         7          11.5931           0.1330           15.28m\n",
      "         8          11.5407           0.1255           15.23m\n",
      "         9          11.2156           0.1244           15.19m\n",
      "        10          11.0964           0.1139           15.06m\n",
      "        20           9.2218           0.1115           14.68m\n",
      "        30           7.7877           0.0675           14.38m\n",
      "        40           6.3655           0.0620           14.10m\n",
      "        50           5.2602           0.0543           13.87m\n",
      "        60           4.4016           0.0490           13.58m\n",
      "        70           3.6392           0.0385           13.32m\n",
      "        80           3.0314           0.0339           13.01m\n",
      "        90           2.5218           0.0185           12.71m\n",
      "       100           2.1173           0.0204           12.42m\n",
      "       200           0.3396           0.0026            9.40m\n",
      "       300           0.0565           0.0003            6.28m\n",
      "       400           0.0097           0.0000            3.13m\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          12.9717           0.1443           16.04m\n",
      "         2          12.8245           0.1400           15.42m\n",
      "         3          12.5975           0.1332           15.26m\n",
      "         4          12.3637           0.1184           15.19m\n",
      "         5          12.2341           0.1041           15.12m\n",
      "         6          11.9340           0.1259           15.09m\n",
      "         7          11.3953           0.1302           15.12m\n",
      "         8          11.5360           0.1124           15.08m\n",
      "         9          11.2428           0.1316           15.13m\n",
      "        10          11.0932           0.1134           15.14m\n",
      "        20           9.1339           0.0990           14.83m\n",
      "        30           7.5447           0.0851           14.47m\n",
      "        40           6.2851           0.0714           14.21m\n",
      "        50           5.1963           0.0534           13.87m\n",
      "        60           4.4498           0.0363           13.62m\n",
      "        70           3.6623           0.0376           13.31m\n",
      "        80           3.0241           0.0354           13.00m\n",
      "        90           2.5034           0.0234           12.71m\n",
      "       100           2.0906           0.0209           12.45m\n",
      "       200           0.3460           0.0025            9.35m\n",
      "       300           0.0571           0.0003            6.23m\n",
      "       400           0.0099           0.0000            3.10m\n",
      "       500           0.0017           0.0000            0.00s\n",
      "      Iter       Train Loss      OOB Improve   Remaining Time \n",
      "         1          12.8975           0.1488           15.03m\n",
      "         2          12.7180           0.1371           15.19m\n",
      "         3          12.4846           0.1384           15.26m\n",
      "         4          12.1502           0.1323           15.08m\n",
      "         5          12.1373           0.1401           15.09m\n",
      "         6          11.8341           0.1292           15.06m\n",
      "         7          11.5967           0.1193           15.00m\n",
      "         8          11.1809           0.1198           15.07m\n",
      "         9          11.1615           0.1225           14.99m\n",
      "        10          10.8923           0.1103           14.99m\n",
      "        20           9.0380           0.1029           14.70m\n",
      "        30           7.5537           0.0721           14.45m\n",
      "        40           6.2610           0.0646           14.05m\n",
      "        50           5.2984           0.0507           13.73m\n",
      "        60           4.3500           0.0482           13.38m\n",
      "        70           3.6417           0.0325           13.08m\n",
      "        80           3.0316           0.0274           12.77m\n",
      "        90           2.4752           0.0232           12.51m\n",
      "       100           2.0609           0.0195           12.21m\n",
      "       200           0.3376           0.0024            9.25m\n",
      "       300           0.0569           0.0004            6.16m\n"
     ]
    }
   ],
   "source": [
    "MAE = 0\n",
    "gbm_preds = np.zeros(len(X_test))\n",
    "oof_gbm = np.zeros(len(X_t))\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    gbm = GradientBoostingRegressor(**gbm_params, verbose=1)\n",
    "    gbm.fit(X_train, y_train)\n",
    "    val_preds = gbm.predict(X_valid)\n",
    "    oof_gbm[valid_idx] = val_preds\n",
    "    MAE += mean_absolute_error(y_valid, val_preds) / n_fold\n",
    "    gbm_preds += gbm.predict(X_test) / n_fold\n",
    "    \n",
    "print('CV score: {}'.format(MAE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RandomForestRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 51%|█ | 509/1000 [15:23:06<15:15:00, 111.81s/it, best loss: 2.186292097403931]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-26-2dd441bb57ce>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     16\u001b[0m                  \u001b[0mspace\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mspace\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     17\u001b[0m                  \u001b[0malgo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtpe\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuggest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 18\u001b[1;33m                  max_evals=1000)\n\u001b[0m",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mfmin\u001b[1;34m(fn, space, algo, max_evals, trials, rstate, allow_trials_fmin, pass_expr_memo_ctrl, catch_eval_exceptions, verbose, return_argmin, points_to_evaluate, max_queue_len, show_progressbar)\u001b[0m\n\u001b[0;32m    405\u001b[0m                     show_progressbar=show_progressbar)\n\u001b[0;32m    406\u001b[0m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcatch_eval_exceptions\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcatch_eval_exceptions\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 407\u001b[1;33m     \u001b[0mrval\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    408\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mreturn_argmin\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    409\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mexhaust\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mexhaust\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[0mn_done\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrun\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_evals\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0mn_done\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mblock_until_done\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0masynchronous\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    263\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrefresh\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mrun\u001b[1;34m(self, N, block_until_done)\u001b[0m\n\u001b[0;32m    225\u001b[0m                     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    226\u001b[0m                         \u001b[1;31m# -- loop over trials and do the jobs directly\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 227\u001b[1;33m                         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mserial_evaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    228\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    229\u001b[0m                     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\hyperopt\\fmin.py\u001b[0m in \u001b[0;36mserial_evaluate\u001b[1;34m(self, N)\u001b[0m\n\u001b[0;32m    139\u001b[0m                 \u001b[0mctrl\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mCtrl\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtrials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcurrent_trial\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtrial\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    140\u001b[0m                 \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 141\u001b[1;33m                     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdomain\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mevaluate\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mspec\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mctrl\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    142\u001b[0m                 \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    143\u001b[0m                     \u001b[0mlogger\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0minfo\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'job exception: %s'\u001b[0m \u001b[1;33m%\u001b[0m \u001b[0mstr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\hyperopt\\base.py\u001b[0m in \u001b[0;36mevaluate\u001b[1;34m(self, config, ctrl, attach_attachments)\u001b[0m\n\u001b[0;32m    842\u001b[0m                 \u001b[0mmemo\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmemo\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    843\u001b[0m                 print_node_on_error=self.rec_eval_print_node_on_error)\n\u001b[1;32m--> 844\u001b[1;33m             \u001b[0mrval\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mpyll_rval\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    845\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    846\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrval\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mfloat\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mint\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mnumber\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-26-2dd441bb57ce>\u001b[0m in \u001b[0;36mobjective_rf\u001b[1;34m(params)\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      3\u001b[0m     \u001b[0mmodel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mRandomForestRegressor\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcriterion\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'mae'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m     \u001b[0mscores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcross_val_score\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m3\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'neg_mean_absolute_error'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      5\u001b[0m     \u001b[0mMAE\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m-\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmean\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;34m'loss'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mMAE\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'status'\u001b[0m\u001b[1;33m:\u001b[0m \u001b[0mSTATUS_OK\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    400\u001b[0m                                 \u001b[0mfit_params\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    401\u001b[0m                                 \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 402\u001b[1;33m                                 error_score=error_score)\n\u001b[0m\u001b[0;32m    403\u001b[0m     \u001b[1;32mreturn\u001b[0m \u001b[0mcv_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'test_score'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    404\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    238\u001b[0m             \u001b[0mreturn_times\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mreturn_estimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mreturn_estimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    239\u001b[0m             error_score=error_score)\n\u001b[1;32m--> 240\u001b[1;33m         for train, test in cv.split(X, y, groups))\n\u001b[0m\u001b[0;32m    241\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    242\u001b[0m     \u001b[0mzipped_scores\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mscores\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    526\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    527\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 528\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    529\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    530\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[0;32m    331\u001b[0m                     \u001b[0mt\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    332\u001b[0m                     verbose=self.verbose, class_weight=self.class_weight)\n\u001b[1;32m--> 333\u001b[1;33m                 for i, t in enumerate(trees))\n\u001b[0m\u001b[0;32m    334\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    335\u001b[0m             \u001b[1;31m# Collect newly grown trees\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m    918\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    919\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 920\u001b[1;33m             \u001b[1;32mwhile\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    921\u001b[0m                 \u001b[1;32mpass\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    922\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    757\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    758\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 759\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    760\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    761\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    714\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    715\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 716\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    717\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    718\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    180\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    181\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 182\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    183\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    184\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    547\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    548\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 549\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    550\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    551\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\externals\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    223\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    224\u001b[0m             return [func(*args, **kwargs)\n\u001b[1;32m--> 225\u001b[1;33m                     for func, args, kwargs in self.items]\n\u001b[0m\u001b[0;32m    226\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    227\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__len__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\ensemble\\forest.py\u001b[0m in \u001b[0;36m_parallel_build_trees\u001b[1;34m(tree, forest, X, y, sample_weight, tree_idx, n_trees, verbose, class_weight)\u001b[0m\n\u001b[0;32m    117\u001b[0m             \u001b[0mcurr_sample_weight\u001b[0m \u001b[1;33m*=\u001b[0m \u001b[0mcompute_sample_weight\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'balanced'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mindices\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    118\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 119\u001b[1;33m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcurr_sample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    120\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    121\u001b[0m         \u001b[0mtree\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mFalse\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1140\u001b[0m             \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1141\u001b[0m             \u001b[0mcheck_input\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcheck_input\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1142\u001b[1;33m             X_idx_sorted=X_idx_sorted)\n\u001b[0m\u001b[0;32m   1143\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1144\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\program files (x86)\\microsoft visual studio\\shared\\python36_64\\lib\\site-packages\\sklearn\\tree\\tree.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    364\u001b[0m                                            min_impurity_split)\n\u001b[0;32m    365\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 366\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX_idx_sorted\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    367\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    368\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def objective_rf(params):\n",
    "    \n",
    "    model = RandomForestRegressor(criterion='mae')\n",
    "    scores = cross_val_score(model, X_t, y_t, cv=3, scoring='neg_mean_absolute_error')\n",
    "    MAE = -scores.mean()\n",
    "    return {'loss': MAE, 'status': STATUS_OK}\n",
    "\n",
    "space = {'n_estimators': hp.choice('n_estimators', range(20, 2000)),\n",
    "         'max_depth': hp.choice('max_depth', range(3, 50)), \n",
    "         'min_samples_split': hp.choice('min_samples_split', range(2, 200)), \n",
    "         'min_samples_leaf': hp.choice('min_samples_leaf', range(2, 100)),\n",
    "         'max_features': hp.choice('max_features', range(3, 100)),\n",
    "         'n_jobs': -1}\n",
    "\n",
    "rf_params = fmin(fn=objective_rf,\n",
    "                 space=space,\n",
    "                 algo=tpe.suggest,\n",
    "                 max_evals=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rf_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = 0\n",
    "rf_preds = np.zeros(len(X_test))\n",
    "oof_rf = np.zeros(len(X_t))\n",
    "scores = []\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "#     print(train_idx)\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    rf = RandomForestRegressor(**rf_params, criterion='mae')\n",
    "    rf.fit(X_train, y_train)\n",
    "    val_preds = rf.predict(X_valid)\n",
    "    oof_rf[valid_idx] = val_preds\n",
    "    MSE += mean_squared_error(y_valid, val_preds) / n_fold\n",
    "    rf_preds += rf.predict(X_test) / n_fold\n",
    "    scores.append()\n",
    "    \n",
    "print('CV score: {}, std: {}'.format(MSE, np.std(scores)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# kernel ridge"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def objective_kr(params):\n",
    "    \n",
    "    MSE = 0\n",
    "    n_fold = 5\n",
    "    folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "    for train_idx, valid_idx in folds.split(y_t):\n",
    "    #     print(train_idx)\n",
    "        X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "        y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "        model = KernelRidge(**params)\n",
    "        model.fit(X_train, y_train)\n",
    "        val_preds = model.predict(X_valid)\n",
    "        MSE += mean_squared_error(y_valid, val_preds) / n_fold\n",
    "\n",
    "    return {'loss': MSE, 'status': STATUS_OK}\n",
    "\n",
    "space = {'alpha': hp.uniform('alpha', 0.01, 10),\n",
    "         'kernel': hp.choice('kernel', ['linear', 'rbf', 'poly']),\n",
    "         'gamma': hp.uniform('gamma', 0.01, 1),\n",
    "         'degree': hp.choice('degree', range(1, 5)),\n",
    "         'coef0': hp.uniform('coef0', 0, 10)}\n",
    "\n",
    "kr_params = fmin(fn=objective_kr,\n",
    "                 space=space,\n",
    "                 algo=tpe.suggest,\n",
    "                 max_evals=1000)\n",
    "\n",
    "kr_params['kernel'] = ['linear', 'rbf', 'poly'][kr_params['kernel']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kr_params"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = 0\n",
    "kr_preds = np.zeros(len(X_test))\n",
    "oof_kr = np.zeros(len(X_t))\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    kr = KernelRidge(**kr_params)\n",
    "    kr.fit(X_train, y_train)\n",
    "    val_preds = kr.predict(X_valid)\n",
    "    oof_kr[valid_idx] = val_preds\n",
    "    MSE += mean_squared_error(y_valid, val_preds) / n_fold\n",
    "    kr_preds += kr.predict(X_test) / n_fold\n",
    "    \n",
    "print('CV score: {}'.format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nusvr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params1 = {'gamma': 'scale', 'nu': 0.9, 'C': 10.0, 'tol': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = 0\n",
    "svr_preds1 = np.zeros(len(X_test))\n",
    "oof_svr1 = np.zeros(len(X_t))\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    svr1 = NuSVR(**svr_params1)\n",
    "    svr1.fit(X_train, y_train)\n",
    "    val_preds = svr1.predict(X_valid)\n",
    "    oof_svr1[valid_idx] = val_preds\n",
    "    MSE += mean_squared_error(y_valid, val_preds) / n_fold\n",
    "    svr_preds1 += svr1.predict(X_test) / n_fold\n",
    "    \n",
    "print('CV score: {}'.format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "svr_params2 = {'gamma': 'scale', 'nu': 0.7, 'C': 1.0, 'tol': 0.01}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MSE = 0\n",
    "svr_preds2 = np.zeros(len(X_test))\n",
    "oof_svr2 = np.zeros(len(X_t))\n",
    "\n",
    "n_fold = 10\n",
    "folds = KFold(n_splits=n_fold, shuffle=True, random_state=0)\n",
    "for train_idx, valid_idx in folds.split(y_t):\n",
    "    X_train, X_valid = X_t.iloc[train_idx], X_t.iloc[valid_idx]\n",
    "    y_train, y_valid = y_t.iloc[train_idx], y_t.iloc[valid_idx]\n",
    "    svr2 = NuSVR(**svr_params2)\n",
    "    svr2.fit(X_train, y_train)\n",
    "    val_preds = svr2.predict(X_valid)\n",
    "    oof_svr2[valid_idx] = val_preds\n",
    "    MSE += mean_squared_error(y_valid, val_preds) / n_fold\n",
    "    svr_preds2 += svr2.predict(X_test) / n_fold\n",
    "    \n",
    "print('CV score: {}'.format(MSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission = pd.read_csv('D:/kaggle/earthquake/sample_submission.csv', index_col='seg_id')\n",
    "submission.time_to_failure = xgb_preds\n",
    "submission.to_csv('xgboost_hyperopt3.csv', index=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
